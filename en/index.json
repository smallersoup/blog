[{"content":"I am a Cloud Native engineer based in Beijing, China. With a passion for leveraging modern technologies, I specialize in designing, developing, and managing scalable, reliable, and efficient cloud-native applications. My expertise spans across cloud services, containerization, microservices architecture, and more.\nKubeSphere Console is the web-based UI for KubeSphere Cloud Native ","date":"15 September 2021","externalUrl":null,"permalink":"/en/","section":"Advance into Cloud Native","summary":"\u003cp\u003eI am a Cloud Native engineer based in Beijing, China. With a passion for leveraging modern technologies, I specialize in designing, developing, and managing scalable, reliable, and efficient cloud-native applications. My expertise spans across cloud services, containerization, microservices architecture, and more.\u003c/p\u003e","title":"Advance into Cloud Native","type":"page"},{"content":"","date":"15 September 2021","externalUrl":null,"permalink":"/en/categories/aigc/","section":"Categories","summary":"","title":"AIGC","type":"categories"},{"content":" Build an Image Search System in 5 Minutes # Vectors and Vector Databases # In mathematics, a vector is an object that can represent multiple dimensions or characteristics. In our daily life, it can also be used to describe multiple attributes of an object.\nFor example, to describe an apple, we need to focus on its features (like variety), origin, color, size, and sweetness. We can treat these attributes as multiple dimensions of the apple and then represent the apple with a vector.\nFor instance, if we define each element of the vector to represent:\nFeature (e.g., 1 for Fuji apple, 2 for Granny Smith) Origin (e.g., 1 for Luochuan, 2 for Yantai) Color (e.g., 1 for red, 2 for green) Size (based on actual weight, e.g., 150 means the apple weighs 150 grams, 200 means 200 grams) Sweetness (e.g., 1 for very sweet, 0.5 for average, 0 for not sweet) Then a Fuji apple from Yantai, red in color, weighing 150 grams, and with sweetness 0.8, can be represented by the vector [1, 2, 1, 150, 0.8]. This vector comprehensively describes all the attributes of the apple.\nThis is the concept of vectors. In artificial intelligence and machine learning, we can vectorize and store complex data types such as audio, images, and text. Traditional databases are primarily designed for handling structured data, but they are inefficient when processing complex data types.\nIn contrast, vector databases support multiple types of indexes and similarity computation methods, efficiently storing and querying large-scale vector data.\nApplications of Vector Databases # Imagine one day you eat a delicious dish at a restaurant but don\u0026rsquo;t know its name or how to make it. You could take a photo of the dish and use an image search feature to find similar dishes and their recipes online.\nConsider an online recipe platform that stores numerous dish images and corresponding recipes. Each dish image has its features extracted and stored as an embedding vector in a vector database.\nWhen the user uploads a photo of a dish for searching, the platform first extracts features from the photo to generate an embedding vector, then searches for the most similar dish images in the vector database.\nThe search results return similar dish images along with their recipes. Users can browse these recipes to find the dish they want to make.\nThis image search feature helps users find the recipes they like and discover new dishes they might enjoy. For the recipe platform, it\u0026rsquo;s an effective way to attract and retain users.\nAdditionally, image search technology has many practical applications in daily life, such as recommending similar products or assisting law enforcement in recognizing faces in surveillance videos to improve crime-solving efficiency.\nAll these applications require a high-performance vector database. In this article, we will build an image search system to experience the entire workflow firsthand.\nTencent Cloud Vector Database # The Tencent Cloud Vector Database offers powerful capabilities for storing, retrieving, and analyzing large amounts of multi-dimensional vector data, supporting up to 1 billion single-index vectors, millions of QPS, and millisecond-level query latency. Currently, it serves thousands of customers stably, and we can create a vector database instance within minutes.\nTesting Version: Single availability zone, single node.\nThe entire creation process takes about 1-2 minutes. Refresh the instance list to see the created instance.\nRetrieve the password for username root from the key management, which will be used later:\nEnable external access: You can use the system-assigned domain name and port to access the vector database externally:\nIt takes about 10 seconds to take effect. Note down the generated domain (HOST) and port (PORT).\nConfigure the whitelist: For testing purposes, the whitelist IP range can be set to 0.0.0.0/0, meaning open to all IPs.\nTest external connectivity with the following command:\ncurl -i -X POST \\ -H \u0026#39;Content-Type: application/json\u0026#39; \\ -H \u0026#39;Authorization: Bearer account=root\u0026amp;api_key=A5VOgsMpGWJhUI0WmUbY********************\u0026#39; \\ http://10.0.X.X:80/database/create \\ -d \u0026#39;{ \u0026#34;database\u0026#34;: \u0026#34;db-test\u0026#34; }\u0026#39; It returns the result as follows. If it fails to connect or times out, the whitelist configuration is incorrect.\n{\u0026#34;code\u0026#34;:0,\u0026#34;msg\u0026#34;:\u0026#34;operation success\u0026#34;,\u0026#34;affectedCount\u0026#34;:1} Image Search Example # We will use Towhee and Tencent Cloud Vector Database to build a reverse image search system.\nTowhee is an open-source framework for building powerful data pipelines. It can efficiently handle various data transformation tasks.\nThis system takes an image as input and retrieves the most similar images based on the content of the image. The basic idea is to use a pre-trained deep learning model to extract the features from each image and represent it as an embedding vector. Then, by storing and comparing these image embedding vectors, we can implement image retrieval.\nThe workflow is as follows:\nFirst, use Towhee to preprocess the input image and extract features to obtain the image embedding vector. Then, store this embedding vector into the vector database. When an image needs to be queried, preprocess and extract features from the query image to get the query image embedding vector. Perform similarity search in the vector database using this vector, and the vector database will return the top k similar vectors.\nCreate Project # We will explain the important code parts below. The final demo code, which is available at the end of the article, can be run locally. This is very friendly for beginners.\nCreate a new project directory: mkdir -p image-search cd image-search Create a new Python virtual environment (optional but recommended): $ python -V Python 3.9.0 $ python -m venv venv Creating a new Python virtual environment can effectively isolate project dependencies and simplify dependency management.\nActivate the virtual environment:\nLinux/macOS: source venv/bin/activate Windows: .\\venv\\Scripts\\activate Install the required Python packages: python -m pip install -q towhee opencv-python pillow tcvectordb This command will install the Towhee, OpenCV, Pillow, and tcvectordb libraries into the virtual environment venv.\nPrepare Data # Here, we use a subset of the ImageNet dataset (100 categories). Sample data can be obtained on GitHub.\ncurl -L https://github.com/towhee-io/examples/releases/download/data/reverse_image_search.zip -O unzip -q -o reverse_image_search.zip The ImageNet dataset is a large-scale visual dataset widely used in deep learning for image classification and object detection tasks. In this article, we use a subset of ImageNet, which provides a suitable scale and complexity for model training and validation.\nThe directory structure is as follows:\ntrain: Contains candidate images, with 100 different categories, each category containing 10 images. test: Contains query images, with the same 100 categories as the training set, but each category has only 1 image. reverse_image_search.csv: A CSV file containing the id, path, and labels of each training image. Candidate images are the images that can be retrieved, and query images are the images used for retrieval.\nConnect to Database and Create Collection # Connecting to Tencent Vector DB is straightforward. The official SDK supports multiple languages. In this article, we use the Python SDK: tcvectordb to operate the vector database.\nFirst, use the tcvectordb SDK to write the client code for connecting to the vector database:\nclass TcvdbClient(PyOperator): def __init__(self, host: str, port: str, username: str, key: str, dbName: str, collectionName: str, timeout: int = 20): # Initialize client \u0026#34;\u0026#34;\u0026#34; self.collectionName = collectionName self.db_name = dbName self._client = tcvectordb.VectorDBClient(url=\u0026#34;http://\u0026#34; + host + \u0026#34;:\u0026#34; + port, username=username, key=key, read_consistency=ReadConsistency.EVENTUAL_CONSISTENCY, timeout=timeout) Then, call TcvdbClient to create the client:\n# tcvdb parameters HOST = \u0026#39;lb-xxxx.clb.ap-beijing.tencentclb.com\u0026#39; PORT = \u0026#39;10000\u0026#39; DB_NAME = \u0026#39;image-search\u0026#39; COLLECTION_NAME = \u0026#39;reverse_image_search\u0026#39; PASSWORD = \u0026#39;xxxx\u0026#39; USERNAME = \u0026#39;root\u0026#39; # path to csv (column_1 indicates image path) OR a pattern of image paths INSERT_SRC = \u0026#39;reverse_image_search.csv\u0026#39; test_vdb = TcvdbClient(host=HOST, port=PORT, key=\u0026#39;6qlvBkF0xAgZoN7VJbcwLCqrxoSS4J63Q7mu4RgF\u0026#39;, username=\u0026#39;root\u0026#39;, collectionName=COLLECTION_NAME, dbName=DB_NAME) The HOST, PORT, USERNAME, and PASSWORD above are obtained after applying for the vector database.\nCreate DB and Collection in the vector database:\nclass TcvdbClient(PyOperator): def create_db_and_collection(self): database = self.db_name coll_embedding_name = self.collectionName coll_alias = self.collectionName + \u0026#34;-alias\u0026#34; # Create DB db = self._client.create_database(database) # Build Collection index = Index() index.add(VectorIndex(\u0026#39;vector\u0026#39;, 2048, IndexType.HNSW, MetricType.COSINE, HNSWParams(m=16, efconstruction=200))) index.add(FilterIndex(\u0026#39;id\u0026#39;, FieldType.String, IndexType.PRIMARY_KEY)) index.add(FilterIndex(\u0026#39;path\u0026#39;, FieldType.String, IndexType.FILTER)) # Create Collection db.create_collection( name=coll_embedding_name, shard=3, replicas=0, description=\u0026#39;image embedding collection\u0026#39;, index=index, embedding=None, timeout=20 ) test_vdb.create_db_and_collection() The above code creates a Collection with three indexes. In a vector database, Collection is the primary structure for storing and retrieving vectors. Creating index fields can be used as filtering in retrieval.\nvector: The index has 2048 vector dimensions. The more dimensions, the more information the vector can represent, but it also increases computational complexity and storage requirements. IndexType.HNSW: The type of index. This is an approximate nearest neighbor search algorithm to accelerate high-dimensional vector search. MetricType.COSINE: Cosine similarity, which measures the angle between two vectors and is commonly used to measure high-dimensional vector similarity. id: The primary key index, used to uniquely identify each vector. path: The filter index to accelerate queries based on the path field. After creation, you can conveniently view and manage the vector database data through the Database Management Console (DMC):\nDMC access link: https://dms.cloud.tencent.com/\nHere is the newly created DB and Collection:\nEmbedding: Image to Vector, Insert into Database # In machine learning, embedding is the process of converting raw input data such as text, images, and audio into a form more suitable for machine learning, i.e., converting complex data structures (like images or text) into fixed-length vectors.\nBelow, we use Towhee’s pipeline to implement image feature extraction and vector storage:\nMODEL = \u0026#39;resnet50\u0026#39; DEVICE = None # if None, use default device (cuda is enabled if available) INSERT_SRC = \u0026#39;reverse_image_search.csv\u0026#39; # Embedding pipeline p_embed = ( pipe.input(\u0026#39;src\u0026#39;) .flat_map(\u0026#39;src\u0026#39;, \u0026#39;img_path\u0026#39;, load_image) .map(\u0026#39;img_path\u0026#39;, \u0026#39;img\u0026#39;, ops.image_decode()) .map(\u0026#39;img\u0026#39;, \u0026#39;vec\u0026#39;, ops.image_embedding.timm(model_name=MODEL, device=DEVICE)) ) # Display embedding result, no need for implementation p_display = p_embed.output(\u0026#39;img_path\u0026#39;, \u0026#39;img\u0026#39;, \u0026#39;vec\u0026#39;) DataCollection(p_display(\u0026#39;./test/goldfish/*.JPEG\u0026#39;)).show() # Insert pipeline p_insert = ( p_embed.map((\u0026#39;img_path\u0026#39;, \u0026#39;vec\u0026#39;), \u0026#39;mr\u0026#39;, ops.local.tcvdb_client( host=HOST, port=PORT, key=PASSWORD, username=USERNAME, collectionName=COLLECTION_NAME, dbName=DB_NAME )) .output(\u0026#39;mr\u0026#39;) ) # Insert data p_insert(INSERT_SRC) The Embedding Pipeline defines a pipeline p_embed that loads the images in reverse_image_search.csv, calls ops.image_embedding.timm(), and uses the resnet50 model to convert the image data into embedding vectors.\nTowhee provides a pre-trained ResNet50 model that can convert images into vectors. ResNet50 is a deep convolutional neural network that performs well in many image recognition tasks. This model learns important features of images and embeds these features into a high-dimensional vector referred to as an embedding vector.\nThe Display Pipeline defines a pipeline p_display used to display the results of p_embed.\nThe Insert Pipeline defines a pipeline p_insert to insert the embedding vectors into the vector database.\np_insert(INSERT_SRC) uses the p_insert pipeline to handle the image data in the reverse_image_search.csv file.\nUltimately, it calls ops.local.search_tcvdb_client to insert the generated vectors into the vector database:\ndef __call__(self, *data): path = \u0026#34;\u0026#34; vector = [] for item in data: if isinstance(item, np.ndarray): # Convert ndarray to list and float32 to float vector = list(map(float, item)) else: path = item # Generate a random UUID and convert to string document_list = [ Document( id=str(uuid.uuid4()), path=path, vector=vector), ] db = self._client.database(self.db_name) coll = db.collection(self.collectionName) coll.upsert(documents=document_list) You can use the fields with indexes created before to filter and accurately query the inserted data in DMC, for example, search: path=\u0026quot;./train/goldfish/n01443537_1903.JPEG\u0026quot;:\nSince vector data is generally large, it will not be returned by default. If you need to return the vector field, check retrieveVector.\nSearch Similar Images # Define a search pipeline p_search to search for images most similar to the input image in the vector database, then display the search results.\nThe pre-search pipeline p_search_pre uses the p_embed pipeline to generate the embedding vector vec for the query image.\n# Search pipeline p_search_pre = ( p_embed.map(\u0026#39;vec\u0026#39;, (\u0026#39;search_res\u0026#39;), ops.local.search_tcvdb_client( host=HOST, port=PORT, key=PASSWORD, username=USERNAME, collectionName=COLLECTION_NAME, dbName=DB_NAME)) .map(\u0026#39;search_res\u0026#39;, \u0026#39;pred\u0026#39;, lambda x: [str(Path(y[0]).resolve()) for y in x]) ) p_search = p_search_pre.output(\u0026#39;img_path\u0026#39;, \u0026#39;pred\u0026#39;) # Search for example query image(s) dc = p_search(\u0026#39;test/goldfish/*.JPEG\u0026#39;) DataCollection(dc).show() Then apply a lambda function to each element to convert each element to a file path and store the result in pred.\nCall the ops.local.search_tcvdb_client function to connect to the vector database and search for the vectors most similar to vec, storing the search results in search_res.\nclass SearchTcvdbClient(PyOperator): def __call__(self, query: \u0026#39;ndarray\u0026#39;): tcvdb_result = self.query_data( query, **self.kwargs ) result = [] for hit in tcvdb_result[0]: row = [] row.extend([hit[\u0026#34;path\u0026#34;], hit[\u0026#34;score\u0026#34;]]) result.append(row) return result def query_data(self, query: [], **kwargs): # Obtain Collection object db = self._client.database(self.db_name) coll = db.collection(self.collectionName) vector = query if isinstance(query, np.ndarray): # Convert ndarray to list and float32 to float vector = list(map(float, query)) # search provides the ability to search by vector # Batch similarity query, find multiple Top K similar results based on specified multiple vectors res = coll.search( vectors=[vector], # Specify search vector retrieve_vector=False, # Whether to return the vector field, False: do not return, True: return limit=10, # Specify the K value of Top K ) return res Output of the Search Pipeline p_search # img_path: Path of the query image. pred: List of paths of similar images found. We use the p_search pipeline to search for images similar to test/goldfish/*.JPEG. The results are displayed using Towhee\u0026rsquo;s DataCollection.\n+-----------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | img_path | pred | +===================================+=========================================================================================================================================================================+ | test/goldfish/n01443537_3883.JPEG | [/root/image-search/reverse_image_search/train/goldfish/n01443537_1903.JPEG,/root/image-search/reverse_image_search/train/goldfish/n01443537_2819.JPEG,...] len=10 | +-----------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ The DataCollection.show() function omits some data when displaying large datasets to prevent overwhelming the screen.\nSimilarly, if you have the vector of an image, you can use DMC to query information about similar images by vector. The results are sorted by score in descending order, with a higher score indicating higher similarity.\nIntegrating Gradio # Feel that the code demonstration above is not friendly enough for non-technical users?\nWe can use Gradio to provide a web UI to showcase the queries and results more visually and interactively. In just a few seconds, we can present the workflow in a web UI form. This allows users to search by directly uploading images and displaying similar images in the interface.\nFor demonstration purposes, the following will search and display similar images by inputting image paths.\ndef search_and_show_images(file_path): # Use `file_path` for the search and return result paths results = p_search(file_path) # Retrieve data from \u0026#39;DataQueue\u0026#39; object data = results.get() # Get result list pred = data[1] return pred iface = gr.Interface( fn=search_and_show_images, inputs=gr.inputs.Textbox(default=\u0026#39;test/goldfish/*.JPEG\u0026#39;), outputs=gr.Gallery(label=\u0026#34;Result Images\u0026#34;).style(height=\u0026#39;auto\u0026#39;, columns=4), title=\u0026#39;Tencent Vector DB Example: Image Search\u0026#39;, ) iface.launch() The search_and_show_images function will return data like the following, which eventually displays the image paths in the web UI.\n[ \u0026#39;/root/image-search/reverse_image_search/train/cuirass/n03146219_11082.JPEG\u0026#39;, \u0026#39;/root/image-search/reverse_image_search/train/loudspeaker/n03691459_40992.JPEG\u0026#39; ] Launch the project. Open your browser to http://127.0.0.1:7860 to see the final result.\nInput: test/goldfish/*.JPEG returns results containing fish.\nInput: test/Afghan_hound/n02088094_4261.JPEG returns results containing dogs.\nSummary # For building systems like image search, text-to-video, and private domain chatbots, Tencent Cloud Vector Database demonstrates remarkable advantages due to its excellent stability, performance, ease of use, and convenient maintenance. Backed by a major company, Tencent Cloud Vector Database has become a leader in the AI field.\nDemo code available at: https://github.com/smallersoup/image-search\n","date":"15 September 2021","externalUrl":null,"permalink":"/en/posts/build-an-image-search-system-in-5-minutes/","section":"Posts","summary":"\u003ch1 class=\"relative group\"\u003eBuild an Image Search System in 5 Minutes \n    \u003cdiv id=\"build-an-image-search-system-in-5-minutes\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#build-an-image-search-system-in-5-minutes\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h1\u003e\n\n\u003ch2 class=\"relative group\"\u003eVectors and Vector Databases \n    \u003cdiv id=\"vectors-and-vector-databases\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#vectors-and-vector-databases\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eIn mathematics, a vector is an object that can represent multiple dimensions or characteristics. In our daily life, it can also be used to describe multiple attributes of an object.\u003c/p\u003e","title":"Build an Image Search System in 5 Minutes","type":"posts"},{"content":"","date":"15 September 2021","externalUrl":null,"permalink":"/en/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","date":"15 September 2021","externalUrl":null,"permalink":"/en/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"","date":"15 September 2021","externalUrl":null,"permalink":"/en/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"15 September 2021","externalUrl":null,"permalink":"/en/tags/towhee/","section":"Tags","summary":"","title":"Towhee","type":"tags"},{"content":" 手把手带你 5 分钟构建以图搜图系统 # 向量和向量数据库 # 向量在数学中是一个可以表示多个维度或特性的对象。在我们日常生活中，也可以用来描述一个物体的多个属性。\n比如，我们要描述一个苹果，需要关注它的特征（如品种）、产地、颜色、大小和甜度等属性。我们可以把这些属性看作是苹果的多个维度，然后用一个向量来表示这个苹果。\n例如，设定向量的每一个元素分别代表：\n特征（如，1 代表红富士苹果，2 代表国光苹果） 产地（如，1 代表洛川，2 代表烟台） 颜色（如，1 代表红色，2 代表绿色） 大小（以实际重量为准，如，150 代表苹果重 150 克，200 代表苹果重 200 克） 甜度（如，1 代表非常甜，0.5 代表一般，0 代表不甜） 那么一个红富士苹果，产地在烟台，颜色为红色，重量为 150 克，甜度为 0.8 的向量就可以表示为 [1, 2, 1, 150, 0.8]。通过这个向量，我们就可以全面地描述这个苹果的所有属性。\n这就是向量的概念。在人工智能和机器学习中，我们可以将音频、图像、复杂的文本向量化后存储。传统的数据库主要是为处理结构化数据设计的，然而，对于复杂的数据类型，传统的数据库处理起来效率低下。\n相比之下，向量数据库支持多种索引类型和相似性计算方法，且能够高效地存储和查询大规模的向量数据。\n向量数据库的应用 # 假设有一天，你在一家餐厅吃到了一道非常美味的菜，但你并不知道它的名字或如何制作。你可以拍下这道菜的照片，然后通过以图搜图的功能，在线搜索类似的菜品和对应的菜谱。\n假设一个在线菜谱平台，存储了大量的菜品图片和对应的菜谱。每一张菜品图片都经过特征提取，生成了相应的嵌入向量，并存储在向量数据库中。\n当用户上传一张菜品照片进行搜索时，平台会先对这张照片进行同样的特征提取，生成一个嵌入向量，然后在向量数据库中搜索与之最相似的菜品图片。\n搜索结果会返回一系列相似的菜品图片以及它们对应的菜谱。用户可以浏览这些菜谱，找到他们想要的菜品，学习如何制作这道菜。\n这种以图搜图的功能不仅可以帮助用户找到他们喜欢的菜谱，还可以帮助他们发现新的、可能会喜欢的菜品。这对于菜谱平台来说，也是一种吸引用户、增加用户粘性的有效方式。\n此外，以图搜图的技术在生活中还有许多实际应用案例，如：购物推荐类似商品、公安对监控视频中的人脸进行识别，提高破案效率。\n以上这些都离不开一个高性能的向量数据库。在本文中，我们将搭建一套以图搜图的系统，来亲自体验整个工作流程。\n腾讯云向量数据库 # 腾讯云向量数据库提供了强大的存储、检索、分析大量多维向量数据的能力，可支持 10 亿级单索引向量规模、百万级 QPS 及毫秒级查询延迟。目前已稳定服务上千家客户，我们可以在分钟内创建一个向量数据库实例。\n测试版：单可用区、单节点。\n整个创建过程大概需要 1-2 分钟，刷新实例列表，即可看到创建好的实例。\n在密钥管理中获取用户名 root 的密码，下面会用到：\n开启外网访问：可以使用系统分配的域名和端口通过外网访问向量数据库：\n生效时间大概在 10s 内，请记住这里生成的 域名(HOST) 和 端口(PORT)\n配置白名单：如果出于测试目的，白名单 IP 段可以设置为 0.0.0.0/0 意味着对所有 IP 开放。\n配置白名单后，可以用下面命令测试外网连通性：\ncurl -i -X POST \\ -H \u0026#39;Content-Type: application/json\u0026#39; \\ -H \u0026#39;Authorization: Bearer account=root\u0026amp;api_key=A5VOgsMpGWJhUI0WmUbY********************\u0026#39; \\ http://10.0.X.X:80/database/create \\ -d \u0026#39;{ \u0026#34;database\u0026#34;: \u0026#34;db-test\u0026#34; }\u0026#39; 返回结果如下。如果连不上，或者超时，则是白名单配置不正确。\n{\u0026#34;code\u0026#34;:0,\u0026#34;msg\u0026#34;:\u0026#34;operation success\u0026#34;,\u0026#34;affectedCount\u0026#34;:1} 以图搜图案例 # 下面我们使用 Towhee 和 腾讯云向量数据库构建一个以图搜图（Reverse Image Search）系统。\nTowhee 是一个用于构建强大的数据流水线的开源框架，它可以有效地处理各种数据转换任务。\n该系统以图片作为输入，基于图片的内容检索出最相似的图片。其背后的基本思想是利用预训练的深度学习模型提取出每个图片的特征，并将其表示为一个嵌入向量（Embedding）。然后，通过存储和比较这些图片嵌入向量，实现图片的检索。\n工作流程如下：\n首先，使用 Towhee 对输入图片进行预处理并提取特征，得到图片的嵌入向量。然后，将这个嵌入向量存入向量数据库中。当需要检索图片时，同样先对查询图片进行预处理和特征提取，得到查询图片的嵌入向量。在向量数据库中对该向量进行相似性检索，向量数据库会返回与该向量相似的 top k 个向量。\n构建项目 # 下面会对重要的代码部分做详解，最终的 demo 代码，可以在文末获取，代码拉到本地就可以运行，对新手很友好\n创建一个新的项目目录： mkdir -p image-search cd image-search 创建一个新的 Python 虚拟环境（可选，但推荐）： $ python -V Python 3.9.0 $ python -m venv venv 创建一个新的 Python 虚拟环境能有效地隔离项目依赖，简化依赖管理\n激活这个虚拟环境：\nLinux/macOS： source venv/bin/activate Windows： .\\venv\\Scripts\\activate 安装需要的 Python 包： python -m pip install -q towhee opencv-python pillow tcvectordb 这个命令会将 Towhee，OpenCV、Pillow、tcvectordb 库安装到上面创建的虚拟目录 venv 中。\n准备数据 # 这里我们使用了 ImageNet 数据集的一个子集（100 个类别）。示例数据可在 Github 上获取。\ncurl -L https://github.com/towhee-io/examples/releases/download/data/reverse_image_search.zip -O unzip -q -o reverse_image_search.zip ImageNet 数据集是深度学习领域中广泛使用的大规模视觉数据集，用于图片分类和物体检测任务。在本文中，所使用的数据集是 ImageNet 的一个子集，这个子集为模型训练和验证提供了适当规模和复杂度的数据。\n目录结构如下：\ntrain：包含候选图片的目录，有 100 个不同的类别，每个类别包含 10 张图片 test：包含查询图片的目录，与训练集同样的 100 个类别，但每个类别只有 1 张图片 reverse_image_search.csv：一个 csv 文件，包含每个训练集图片的 id、路径和标签 候选图片是指可能会被检索的图片，查询图片是指用于检索的图片。\n连接数据库并新建 Collection # 连接 Tencent Vector DB 很简单，官方提供了多种语言的 SDK，本文使用 Python SDK： tcvectordb 操作向量数据库。\n首先利用 tcvectordb sdk 编写连接向量数据库的客户端代码：\nclass TcvdbClient(PyOperator): def __init__(self, host: str, port: str, username: str, key: str, dbName: str, collectionName: str, timeout: int = 20): \u0026#34;\u0026#34;\u0026#34; 初始化客户端 \u0026#34;\u0026#34;\u0026#34; # 创建客户端时可以指定 read_consistency，后续调用 sdk 接口的 read_consistency 将延用该值 self.collectionName = collectionName self.db_name = dbName self._client = tcvectordb.VectorDBClient(url=\u0026#34;http://\u0026#34; + host + \u0026#34;:\u0026#34; + port, username=username, key=key, read_consistency=ReadConsistency.EVENTUAL_CONSISTENCY, timeout=timeout) 然后调用 TcvdbClient 构建客户端 ：\n# tcvdb parameters HOST = \u0026#39;lb-xxxx.clb.ap-beijing.tencentclb.com\u0026#39; PORT = \u0026#39;10000\u0026#39; DB_NAME = \u0026#39;image-search\u0026#39; COLLECTION_NAME = \u0026#39;reverse_image_search\u0026#39; PASSWORD = \u0026#39;xxxx\u0026#39; USERNAME = \u0026#39;root\u0026#39; # path to csv (column_1 indicates image path) OR a pattern of image paths INSERT_SRC = \u0026#39;reverse_image_search.csv\u0026#39; test_vdb = TcvdbClient(host=HOST, port=PORT, key=\u0026#39;6qlvBkF0xAgZoN7VJbcwLCqrxoSS4J63Q7mu4RgF\u0026#39;, username=\u0026#39;root\u0026#39;, collectionName=COLLECTION_NAME, dbName=DB_NAME) 上面的 HOST 和 PORT、USERNAME 和 PASSWORD 是申请向量数据库后获取到的。\n在向量数据库中创建 DB 和 Collection：\nclass TcvdbClient(PyOperator): def create_db_and_collection(self): database = self.db_name coll_embedding_name = self.collectionName coll_alias = self.collectionName + \u0026#34;-alias\u0026#34; # 创建 DB db = self._client.create_database(database) # 构建 Collection index = Index() index.add(VectorIndex(\u0026#39;vector\u0026#39;, 2048, IndexType.HNSW, MetricType.COSINE, HNSWParams(m=16, efconstruction=200))) index.add(FilterIndex(\u0026#39;id\u0026#39;, FieldType.String, IndexType.PRIMARY_KEY)) index.add(FilterIndex(\u0026#39;path\u0026#39;, FieldType.String, IndexType.FILTER)) # 创建 Collection db.create_collection( name=coll_embedding_name, shard=3, replicas=0, description=\u0026#39;image embedding collection\u0026#39;, index=index, embedding=None, timeout=20 ) test_vdb.create_db_and_collection() 上面代码创建一个 Collection，并在这个 Collection 中添加了三个索引。在向量数据库中，Collection 是用来存储和检索向量的主要结构，创建索引的字段在检索时可以用作过滤（filter）。\nvector：索引有2048向量维度。维度越高，向量可以表达的信息越多，但同时计算复杂度也越高，存储需求也越大。 IndexType.HNSW索引的类型。这是一种近似最近邻搜索算法，用来加速高维向量的搜索。 MetricType.COSINE是余弦相似度，它可以衡量两个向量之间的角度，通常用于衡量高维向量的相似性。 id是主键索引，用来唯一标识每个向量。 path是过滤索引，用来加速基于 path 字段的查询。 新建之后，可以通过 DMC（数据库管理）方便的查看、管理向量数据库的数据：\nDMC 访问入口：https://dms.cloud.tencent.com/\n下面是刚刚创建的 DB 和集合：\nEmbedding：图片转向量、入库 # 在机器学习领域中，把文本、图片，音频等其他类型原始输入数据转换为一种更适合机器学习的形式，即将复杂的数据结构（如图片、文本等）转换为固定长度的向量的过程成为 Embedding。\n下面利用 Towhee 的 pipeline 实现图片的特征提取和向量的存储：\nMODEL = \u0026#39;resnet50\u0026#39; DEVICE = None # if None, use default device (cuda is enabled if available) INSERT_SRC = \u0026#39;reverse_image_search.csv\u0026#39; # Embedding pipeline p_embed = ( pipe.input(\u0026#39;src\u0026#39;) .flat_map(\u0026#39;src\u0026#39;, \u0026#39;img_path\u0026#39;, load_image) .map(\u0026#39;img_path\u0026#39;, \u0026#39;img\u0026#39;, ops.image_decode()) .map(\u0026#39;img\u0026#39;, \u0026#39;vec\u0026#39;, ops.image_embedding.timm(model_name=MODEL, device=DEVICE)) ) # Display embedding result, no need for implementation p_display = p_embed.output(\u0026#39;img_path\u0026#39;, \u0026#39;img\u0026#39;, \u0026#39;vec\u0026#39;) DataCollection(p_display(\u0026#39;./test/goldfish/*.JPEG\u0026#39;)).show() # Insert pipeline p_insert = ( p_embed.map((\u0026#39;img_path\u0026#39;, \u0026#39;vec\u0026#39;), \u0026#39;mr\u0026#39;, ops.local.tcvdb_client( host=HOST, port=PORT, key=PASSWORD, username=USERNAME, collectionName=COLLECTION_NAME, dbName=DB_NAME )) .output(\u0026#39;mr\u0026#39;) ) # Insert data p_insert(INSERT_SRC) Embedding Pipeline 定义了一个 p_embed 的管道，这个管道将 reverse_image_search.csv 中的图片加载后，调用 ops.image_embedding.timm()，使用 resnet50 模型将图片数据转换为嵌入向量。\nTowhee 提供了预训练的 ResNet50 模型，可以将图片转换为向量。ResNet50 是一种深度卷积神经网络，它在许多图像识别任务中表现出色。此模型通过学习图片的重要特征，并将这些特征嵌入到一个高维向量中，称为嵌入向量（embedding vector）。\nDisplay Pipeline 代码定义了 p_display 的管道，这个管道用于显示 p_embed 的结果。\nInsert Pipeline 代码定义了 p_insert 的管道，这个管道用于将嵌入向量插入到向量数据库中。\np_insert(INSERT_SRC) 使用 p_insert 管道对 reverse_image_search.csv 文件中的图片数据进行处理。\n最终会将生成的向量调用 ops.local.search_tcvdb_client，插入到向量数据库中：\ndef __call__(self, *data): path = \u0026#34;\u0026#34; vector = [] for item in data: if isinstance(item, np.ndarray): # Convert ndarray to list and float32 to float vector = list(map(float, item)) else: path = item # Generate a random UUID and convert to string document_list = [ Document( id=str(uuid.uuid4()), path=path, vector=vector), ] db = self._client.database(self.db_name) coll = db.collection(self.collectionName) coll.upsert(documents=document_list) 可以在 DMC 中，用刚刚创建了索引的字段进行过滤，精确查询到入库后的数据，例如搜索：path=\u0026quot;./train/goldfish/n01443537_1903.JPEG\u0026quot; ：\n由于向量数据一般很大，默认不会返回。如果要返回向量字段需要勾选retrieveVector。\n搜索相似图 # 定义一个搜索管道 p_search，用于在向量数据库中搜索与输入图像最相似的图像，然后显示搜索结果。\n预搜索管道 p_search_pre 使用 p_embed 管道生成 查询图片 的嵌入向量 vec。\n# Search pipeline p_search_pre = ( p_embed.map(\u0026#39;vec\u0026#39;, (\u0026#39;search_res\u0026#39;), ops.local.search_tcvdb_client( host=HOST, port=PORT, key=PASSWORD, username=USERNAME, collectionName=COLLECTION_NAME, dbName=DB_NAME)) .map(\u0026#39;search_res\u0026#39;, \u0026#39;pred\u0026#39;, lambda x: [str(Path(y[0]).resolve()) for y in x]) ) p_search = p_search_pre.output(\u0026#39;img_path\u0026#39;, \u0026#39;pred\u0026#39;) # Search for example query image(s) dc = p_search(\u0026#39;test/goldfish/*.JPEG\u0026#39;) DataCollection(dc).show() 然后对每个元素应用一个 lambda 函数，将每个元素转换为一个文件路径，并将结果存储在 pred 中。\n调用 ops.local.search_tcvdb_client 函数连接向量数据库，并搜索与 vec 最相似的向量，将搜索结果存储在 search_res 中。\nclass SearchTcvdbClient(PyOperator): def __call__(self, query: \u0026#39;ndarray\u0026#39;): tcvdb_result = self.query_data( query, **self.kwargs ) result = [] for hit in tcvdb_result[0]: row = [] row.extend([hit[\u0026#34;path\u0026#34;], hit[\u0026#34;score\u0026#34;]]) result.append(row) return result def query_data(self, query: [], **kwargs): # 获取 Collection 对象 db = self._client.database(self.db_name) coll = db.collection(self.collectionName) vector = query if isinstance(query, np.ndarray): # Convert ndarray to list and float32 to float vector = list(map(float, query)) # search 提供按照 vector 搜索的能力 # 批量相似性查询，根据指定的多个向量查找多个 Top K 个相似性结果 res = coll.search( vectors=[vector], # 指定检索向量， retrieve_vector=False, # 是否需要返回向量字段，False：不返回，True：返回 limit=10, # 指定 Top K 的 K 值 ) return res 搜索管道 p_search 的输出是：\nimg_path：查询图片 的路径。 pred：查询到的相似图片路径列表。 使用 p_search 管道对图片 test/goldfish/*.JPEG 的相似图进行搜索。用 Towhee 的 DataCollection 组件显示搜索结果。\n+-----------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | img_path | pred | +===================================+=============================================================================================================================================================================================================================================================================================================================+ | test/goldfish/n01443537_3883.JPEG | [/root/image-search/reverse_image_search/train/goldfish/n01443537_1903.JPEG,/root/image-search/reverse_image_search/train/goldfish/n01443537_2819.JPEG,/root/image-search/reverse_image_search/train/goldfish/n01443537_1415.JPEG,/root/image-search/reverse_image_search/train/goldfish/n01443537_7751.JPEG,...] len=10 | +-----------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ DataCollection.show() 函数在显示大量数据时，为了防止在屏幕上显示过多的数据，会省略部分数据。\n同样的，如果知道了一张图片的向量，可以在 DMC 中用向量检索相似的图片信息，查询到的结果默认按照 score 由高到低排序，越大表示相似度越高。\n集成 Gradio # 觉得上述示例中的代码演示对于非技术用户来说不够友好？\n我们可以使用 Gradio 提供的 Web UI，以更直观、更互动的方式来展示上述的查询和结果。几秒钟内就可以将上述工作流程以 Web UI 的形式呈现出来。这样，用户可以直接通过上传图片来进行搜索，在界面上展示出相似的图片。\n出于演示目的，下面将通过输入图片路径，查询并展示相似的图片。\ndef search_and_show_images(file_path): # 使用 `file_path` 进行搜索，返回结果的路径 results = p_search(file_path) # 从 \u0026#39;DataQueue\u0026#39; 对象中获取数据 data = results.get() # 获取结果列表 pred = data[1] return pred iface = gr.Interface( fn=search_and_show_images, # inputs=gr.inputs.File(type=\u0026#34;file\u0026#34;), inputs=gr.inputs.Textbox(default=\u0026#39;test/goldfish/*.JPEG\u0026#39;), outputs=gr.Gallery(label=\u0026#34;最终的结果图片\u0026#34;).style(height=\u0026#39;auto\u0026#39;, columns=4), --- title=\u0026#39;Tencent vector db 案例: 以图搜图\u0026#39;, ) iface.launch() search_and_show_images 会返回类似下面的数据，最终这些图片路径会被展示到 Web UI 上。\n[ \u0026#39;/root/image-search/reverse_image_search/train/cuirass/n03146219_11082.JPEG\u0026#39;, \u0026#39;/root/image-search/reverse_image_search/train/loudspeaker/n03691459_40992.JPEG\u0026#39; ] 启动项目。用浏览器打开 http://127.0.0.1:7860 即可看到成果。\n输入：test/goldfish/*.JPEG 返回的结果都包含鱼。\n输入：test/Afghan_hound/n02088094_4261.JPEG 返回的结果都包含狗。\n总结 # 对于构建以图搜图、文字搜视频、私域对话机器人等系统，腾讯云向量数据库由于其卓越的稳定性、性能、易用性和便捷的运维，都展现出了显著优势。得益于大厂的背书，腾讯云向量数据库在 AI 领域中已经成为了领军者。\n演示代码地址：https://github.com/smallersoup/image-search\n","date":"2021年9月15日","externalUrl":null,"permalink":"/posts/search-img-by-img/","section":"Posts","summary":"\u003ch1 class=\"relative group\"\u003e手把手带你 5 分钟构建以图搜图系统 \n    \u003cdiv id=\"手把手带你-5-分钟构建以图搜图系统\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%89%8b%e6%8a%8a%e6%89%8b%e5%b8%a6%e4%bd%a0-5-%e5%88%86%e9%92%9f%e6%9e%84%e5%bb%ba%e4%bb%a5%e5%9b%be%e6%90%9c%e5%9b%be%e7%b3%bb%e7%bb%9f\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h1\u003e\n\n\u003ch2 class=\"relative group\"\u003e向量和向量数据库 \n    \u003cdiv id=\"向量和向量数据库\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e5%90%91%e9%87%8f%e5%92%8c%e5%90%91%e9%87%8f%e6%95%b0%e6%8d%ae%e5%ba%93\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e向量在数学中是一个可以表示多个维度或特性的对象。在我们日常生活中，也可以用来描述一个物体的多个属性。\u003c/p\u003e","title":"手把手带你 5 分钟构建以图搜图系统...","type":"posts"},{"content":"","date":"2019年11月21日","externalUrl":null,"permalink":"/tags/cka/","section":"Tags","summary":"","title":"CKA","type":"tags"},{"content":"","date":"2019年11月21日","externalUrl":null,"permalink":"/tags/kubernetes/","section":"Tags","summary":"","title":"Kubernetes","type":"tags"},{"content":" 本活动在微信公众号【我的小碗汤】上举行，有送书活动！这里参与答题不能参与到送书活动哦！\n昨日考题 # 通过单个命令创建一个deployment并暴露Service。deployment和Service名称为cka-1120，使用nginx镜像， deployment拥有2个pod\n昨日答案 # [root@liabio ~]# kubectl run cka-1120 --replicas 2 --expose=true --port=80 --image=nginx kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead. service/cka-1120 created deployment.apps/cka-1120 created [root@liabio ~]# kubectl get all | grep cka-1120 pod/cka-1120-554b9c4798-7jcrb 1/1 Running 0 118m pod/cka-1120-554b9c4798-fpjwj 1/1 Running 0 118m service/cka-1120 ClusterIP 10.108.140.25 \u0026lt;none\u0026gt; 80/TCP 118m deployment.apps/cka-1120 2/2 2 2 118m 昨日解析 # 官网中提供了详细的kubectl使用方法，位于REFERENCE\u0026ndash;\u0026raquo;kubectl CLI\u0026ndash;\u0026raquo;kubectl Commands标签下。\n即：\nhttps://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#run\nkubectl run会创建deployment或者job来管理Pod，命令语法如下：\nkubectl run NAME --image=image [--env=\u0026#34;key=value\u0026#34;] [--port=port] [--replicas=replicas] [--dry-run=bool] [--overrides=inline-json] [--command] -- [COMMAND] [args...] NAME指定deployment和service的名称；\n\u0026ndash;replicas缩写-r，指定实例数，默认为1；\n\u0026ndash;expose如果为true，会创建有ClusterIP的service，默认为false；\n\u0026ndash;port表示容器暴露的端口，如果expose为true，该端口也是service的端口；\n\u0026ndash;image指定容器用的镜像；\n\u0026ndash;dry-run为true时，只打印将要发送的对象，而不真正发送它，默认为false。\n创建名为cka-1120-01，带环境变量的deployment\nkubectl run cka-1120-01 --image=nginx --env=\u0026#34;DNS_DOMAIN=cluster.local\u0026#34; --env=\u0026#34;POD_NAMESPACE=default\u0026#34; 创建名为cka-1120-02，带label的deployment\nkubectl run cka-1120-02 --image=nginx --labels=\u0026#34;app=nginx,env=prod\u0026#34; 还有一个\u0026ndash;restart参数，默认为Always，如果设置为OnFailure，则job会被创建；如果设置为Never，则普通Pod会被创建。\n[root@liabio ~]# kubectl run cka-1120-03 --image=nginx --restart=OnFailure kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead. job.batch/cka-1120-03 created [root@liabio ~]# [root@liabio ~]# kubectl run cka-1120-04 --image=nginx --restart=Never pod/cka-1120-04 created 参数\u0026ndash;schedule指定cronjob的定时规则，如果指定该参数，则会创建出cronjob\n[root@liabio ~]# kubectl run pi --schedule=\u0026#34;0/5 * * * ?\u0026#34; --image=perl --restart=OnFailure -- perl -Mbignum=bpi -wle \u0026#39;print bpi(2000)\u0026#39; cronjob.batch/pi created 目前不支持直接创建Statefulset、Daemonset等资源对象。\nkubectl run执行后，到底发生了什么？\n有必要看看kubectl源码，入口函数在$GOPATH\\src\\k8s.io\\kubernetes\\cmd\\clicheck\\check_cli_conventions.go中\n其中cmd.NewKubectlCommand为构建kubectl以及其子命令行参数。最终的执行业务逻辑的代码都在pkg\\kubectl包下面。\n不同的子命令：apply、run、create入口对应的在pkg\\kubectl\\cmd下面：\n最重要的o.Run(f, cmd, args)中会对kubectl run传入的参数进行一系列校验，填充默认值。\n在360行调用o.createGeneratedObject根据不同的generator生成deployment、cronjob、job、pod等资源对象，并向apiserver发送创建请求。\n如果设置了expose为true，在372行，同样的调用o.createGeneratedObject生成并创建service。\no.createGeneratedObject方法第649行，根据不同的generator实现生成不同的资源对象。\nrun命令对应的generator实现有以下几种，代码位于pkg\\kubectl\\generate\\versioned\\generator.go中的DefaultGenerators函数。\ncase \u0026#34;run\u0026#34;: generator = map[string]generate.Generator{ RunV1GeneratorName: BasicReplicationController{}, RunPodV1GeneratorName: BasicPod{}, DeploymentV1Beta1GeneratorName: DeploymentV1Beta1{}, DeploymentAppsV1Beta1GeneratorName: DeploymentAppsV1Beta1{}, DeploymentAppsV1GeneratorName: DeploymentAppsV1{}, JobV1GeneratorName: JobV1{}, CronJobV2Alpha1GeneratorName: CronJobV2Alpha1{}, CronJobV1Beta1GeneratorName: CronJobV1Beta1{}, } o.createGeneratedObject方法第689行对生成的资源对象向APIServer发送http创建请求。\n具体的kubectl run命令的代码，感兴趣的同学可以进一步深挖，我也会在后续的源码分析系列文章中进行更详细的解析。\n今日考题 # 通过命令行，使用nginx镜像创建一个pod并手动调度到节点名为node1121节点上，Pod的名称为cka-1121，答题最好附上，所用命令、创建Pod所需最精简的yaml；如果评论有限制，请把注意点列出，主要需列出手动调度怎么做？\n注意：手动调度是指不需要经过kube-scheduler去调度。\n作者简洁 # 作者：小碗汤，一位热爱、认真写作的小伙，目前维护原创公众号：『我的小碗汤』，专注于写golang、docker、kubernetes等知识等提升硬实力的文章，期待你的关注。 转载说明：务必注明来源（注明：来源于公众号：我的小碗汤， 作者：小碗汤）\n","date":"2019年11月21日","externalUrl":null,"permalink":"/posts/%E5%A4%87%E6%88%98cka%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%E7%AC%AC4%E5%A4%A9%E7%86%9F%E7%BB%83%E6%8E%8C%E6%8F%A1kubectl%E5%91%BD%E4%BB%A4%E8%BF%9B%E8%A1%8C%E5%88%9B%E5%BB%BA%E8%B5%84%E6%BA%90%E5%AF%B9%E8%B1%A1%E6%93%8D%E4%BD%9C%E5%B9%B6%E4%BB%8E%E6%BA%90%E7%A0%81%E8%BF%9B%E8%A1%8C%E8%A7%A3%E6%9E%90/","section":"Posts","summary":"\u003cblockquote\u003e\n\u003cp\u003e本活动在微信公众号【我的小碗汤】上举行，有送书活动！这里参与答题不能参与到送书活动哦！\u003c/p\u003e","title":"备战CKA每日一题——第4天 | 熟练掌握kubectl命令进行创建资源对象操作，并从源码进行解析","type":"posts"},{"content":" 本活动在微信公众号【我的小碗汤】上举行，这里参与答题无效哦！\n昨日考题 # 在Kubernetes PVC+PV体系下通过CSI实现的volume plugins动态创建pv到pv可被pod使用有哪些组件需要参与？\nA. PersistentVolumeController + CSI-Provisoner + CSI controller plugin B. AttachDetachController + CSI-Attacher + CSI controller plugin C. Kubelet + CSI node plugin 昨日答案 # ABC\n昨日解析 # k8s中，利用PVC 描述Pod 所希望使用的持久化存储的大小，可读写权限等，一般由开发人员去创建；利用PV描述具体存储类型，存储地址，挂载目录等，一般由运维人员去提前创建。而不是直接在pod里写上volume的信息。一来可以使得开发运维职责分明，二来利用PVC、PV机制，可以很好扩展支持市面上不同的存储实现，如k8s v1.10版本对Local Persistent Volume的支持。\n我们试着理一下Pod创建到volume可用的整体流程。\n用户提交请求创建pod，PersistentVolumeController发现这个pod声明使用了PVC，那就会帮它找一个PV配对。\n没有现成的PV，就去找对应的StorageClass，帮它新创建一个PV，然后和PVC完成绑定。\n新创建的PV，还只是一个API 对象，需要经过“两阶段处理”，才能变成宿主机上的“持久化 Volume”真正被使用：\n第一阶段由运行在master上的AttachDetachController负责，为这个PV完成 Attach 操作，为宿主机挂载远程磁盘；\n第二阶段是运行在每个节点上kubelet组件的内部，把第一步attach的远程磁盘 mount 到宿主机目录。这个控制循环叫VolumeManagerReconciler，运行在独立的Goroutine，不会阻塞kubelet主控制循环。\n完成这两步，PV对应的“持久化 Volume”就准备好了，POD可以正常启动，将“持久化 Volume”挂载在容器内指定的路径。\nk8s支持编写自己的存储插件FlexVolume 与 CSI。不管哪种方式，都需要经过“两阶段处理”，FlexVolume相比CSI局限性大，一般我们采用CSI方式对接存储。\nCSI 插件体系的设计思想把这个Provision阶段（动态创建PV），以及 Kubernetes 里的一部分存储管理功能，从主干代码里剥离出来，做成了几个单独的组件。这些组件会通过 Watch API 监听 Kubernetes 里与存储相关的事件变化，比如 PVC 的创建，来执行具体的存储管理动作。\n上图中CSI这套存储插件体系中三个独立的外部组件（External Components），即：Driver Registrar、External Provisioner 和 External Attacher，对应的是从 Kubernetes 项目里面剥离出来的部分存储管理功能。\n我们需要实现Custom Components这一个二进制，会以gRpc方式提供三个服务：CSI Identity、CSI Controller、CSI Node。\nDriver Registrar 组件，负责将插件注册到 kubelet 里面；Driver Registrar调用CSI Identity 服务来获取插件信息；\nExternal Provisioner 组件监听APIServer 里的 PVC 对象。当一个 PVC 被创建时，它就会调用 CSI Controller 的 CreateVolume 方法，创建对应 PV；\nExternal Attacher 组件负责Attach阶段。Mount阶段由kubelet里的VolumeManagerReconciler控制循环直接调用CSI Node服务完成。\n两阶段完成后，kubelet将mount参数传递给docker，创建、启动容器。\n整体流程如下图：\n考试体验总结 # https://www.kubernetes.org.cn/5168.html\nhttps://blog.csdn.net/deerjoe/article/details/86300826\n今日考题 # 通过单个命令创建一个deployment并暴露Service。deployment和Service名称为cka-1120，使用nginx镜像， deployment拥有2个pod\n作者简洁 # 作者：小碗汤，一位热爱、认真写作的小伙，目前维护原创公众号：『我的小碗汤』，专注于写golang、docker、kubernetes等知识等提升硬实力的文章，期待你的关注。 转载说明：务必注明来源（注明：来源于公众号：我的小碗汤， 作者：小碗汤）\n","date":"2019年11月21日","externalUrl":null,"permalink":"/posts/%E5%A4%87%E6%88%98cka%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%E7%AC%AC3%E5%A4%A9%E5%AF%B9%E6%8E%A5csi%E5%AD%98%E5%82%A8%E7%9F%A5%E8%AF%86/","section":"Posts","summary":"\u003cblockquote\u003e\n\u003cp\u003e本活动在微信公众号【我的小碗汤】上举行，这里参与答题无效哦！\u003c/p\u003e\u003c/blockquote\u003e\n\n\u003ch2 class=\"relative group\"\u003e昨日考题 \n    \u003cdiv id=\"昨日考题\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%98%a8%e6%97%a5%e8%80%83%e9%a2%98\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e在Kubernetes PVC+PV体系下通过CSI实现的volume plugins动态创建pv到pv可被pod使用有哪些组件需要参与？\u003c/p\u003e","title":"备战CKA每日一题——第3天 | 对接CSI存储知识","type":"posts"},{"content":" CKA概述 # 认证Kubernetes管理员（CKA）计划由Linux基金会和云原生计算基金会（CNCF）创建，作为他们为帮助开发Kubernetes生态系统而不断努力的一部分。作为速度最快的开源项目之一，Kubernetes的使用正在爆炸式增长。\n条件 # 此考试没有必备条件。\n考证相关 # 考试模式：线上 、考试中心 （查看考试中心地点）\n考试时间：3小时\n认证有效期：3年\n软件版本：Kubernetes v1.15\n重考政策：可接受重考\n经验水平：中级\n考生需于购买考试后，12个月内进行考试。通过认证考试的考生将获得PDF认证证书。\n线下考试中心地址 # 为了使中国考生便于进行LF认证考试，我们与PSI考试中心合作，于中国各大城市开设考试地点，因此考生在预约时间到PSI考试中心进行考试。以下为现时开设的PSI考点：\n北京考点 - 1 # 地址：ATA - 北京市朝阳区东三环中路39号建外SOHO 2号楼东门1楼\n考场查询电话：18601068015 (Zhang lu)\n北京考点 - 2 # 地址：ATA国际认证中心 - 北京市海淀区北清路103号中科产业园1B楼\n考场查询电话：18810630020 (Liu xingyuan)\n上海考点 # 地址：ATA - 上海市浦东新区博云路36号E座\n考场查询电话：17621888482 (Lu yinmin)\n南京考点 # 地址：南京光声超构材料研究院 九楼 江苏省南京市栖霞区九乡河东路与纬地路交叉路东（南京大学仙林校区内）\n考场查询电话：15895833908 (Liu dandan)\n成都考点 # 地址：四川省成都市武侯区科园三路4号火炬时代A区5层504\n考场查询电话：18980764881 (Liu xiujun)\n广州考点 # 广州市天河区体育东路108号创展中心西座1501单元\n考场查询电话：15989163312 (zhong zhiwen)\n济南考点 # 地址：济南市市中区经四路万达广场B座905室\n考场查询电话：13911251487 (li shuai)\n沈阳考点 # 地址：辽宁省沈阳市和平区青年大街286号华润大厦A座2006室\n考场查询电话：18642085483 (yu zhongbao)\n深圳考点 # 地址：深圳市福田区八卦二路616栋4楼\n考场查询电话：17507581649 (chen junhui)\n西安考点 # 地址：陕西省西安市新城区北大街55号新时代广场10D\n考场查询电话：17719529253 (cui fenle)\n大连考点 # 地址：辽宁省大连市沙河口区华北路311号\n考场查询电话：18641107099 (Fu baohui)\n合肥考点 # 地址：合肥市新站区职教城文忠路与学林路交叉口向东100米\n考场查询电话：13955138415 (Jin bao)\n长沙考点 # 地址：湖南省长沙市岳麓区王家湾立交桥洋海塘168号3楼长沙岳麓专修学院\n考场查询电话：18229631151 (Zhang yufeng)\n重庆考点 # 地址：重庆市九龙坡区渝州路长石村24号\n考场查询电话：13101380163 (Dai shuang)\n杭州考点 # 地址：浙江省杭州市下城区绍兴路焦家里1弄3号文源电商创意产业园\n考场查询电话：13675866166 (Su gutian)\n天津考点 # 地址：天津市南开区迎水道1号\n考场查询电话：13164040242 (Zhou yueyin)\n领域和能力 # CKA认证针对考核成为当业界的Kubernetes管理员所需的技能。\n考纲和权重 # CKA认证考试包括这些一般领域及其在考试中的权重：\n应用程序生命周期管理 - 8％\t安装、配置和验证 - 12％\t核心概念 - 19％\n网络 - 11％\t调度 - 5％\t安全 - 12％\n集群维护 - 11％\t记录/监控 - 5％\t存储 - 7％\n故障排除 - 10％\n详细内容： # 应用程序生命周期管理 - 8％\n• 了解部署以及如何执行滚动更新和回滚\n• 了解配置应用程序的各种方法\n• 了解如何扩展应用程序\n• 了解创建自我修复应用程序所需的原语\n安装、配置和验证 - 12％\n• 设计Kubernetes集群\n• 安装Kubernetes Masters和Nodes\n• 配置安全群集通信\n• 配置高可用性Kubernetes集群\n• 知道从哪里获取Kubernetes发布二进制文件\n• 配置底层基础架构以部署Kubernetes集群\n• 选择网络解决方案\n• 选择您的Kubernetes基础架构配置\n• 在群集上运行端到端测试\n• 分析端到端测试结果\n• 运行节点端到端测试\n• 安装并使用kubeadm来安装，配置和管理Kubernetes集群\n核心概念 - 19％\n• 了解Kubernetes API原语\n• 了解Kubernetes集群架构\n• 了解服务和其他网络原语\n网络 - 11％\n• 了解群集节点上的网络配置\n• 了解Pod网络概念\n• 了解服务网络\n• 部署和配置网络负载平衡器\n• 了解如何使用Ingress规则\n• 了解如何配置和使用群集DNS\n• 了解CNI\n调度 - 5％\n• 使用标签选择器来安排Pod\n• 了解DaemonSets的作用\n• 了解资源限制如何影响Pod调度\n• 了解如何运行多个调度程序以及如何配置Pod以使用它们\n• 手动安排没有调度程序的容器\n• 显示调度程序事件\n安全 - 12％\n• 了解如何配置身份验证和授权\n• 了解Kubernetes安全原语\n• 了解如何配置网络策略\n• 为群集组件创建和管理TLS证书\n• 安全地处理图像\n• 定义安全上下文\n• 安全持久密钥值存储\n集群维护 - 11％\n• 了解Kubernetes集群升级过程\n• 促进操作系统升级\n• 实施备份和还原方法\n记录/监控 - 5％\n• 了解如何监控所有群集组件\n• 了解如何监控应用程序\n• 管理群集组件日志\n• 管理应用程序日志\n存储 - 7％\n• 了解持久卷并了解如何创建它们\n• 了解卷的访问模式\n• 了解持久性卷声明原语\n• 了解Kubernetes存储对象\n• 了解如何使用持久存储配置应用程序\n疑难解答 - 10％\n• 解决应用程序故障\n• 排除控制平面故障\n• 解决工作节点故障\n• 排除网络故障\n","date":"2019年11月21日","externalUrl":null,"permalink":"/posts/cka%E6%A6%82%E8%BF%B0%E8%80%83%E8%AF%95%E5%BD%A2%E5%BC%8F%E8%80%83%E8%AF%95%E5%9C%B0%E5%9D%80%E8%80%83%E7%BA%B2%E5%8D%A0%E6%AF%94%E7%AD%89/","section":"Posts","summary":"\u003ch2 class=\"relative group\"\u003eCKA概述 \n    \u003cdiv id=\"cka概述\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#cka%e6%a6%82%e8%bf%b0\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e认证Kubernetes管理员（CKA）计划由Linux基金会和云原生计算基金会（CNCF）创建，作为他们为帮助开发Kubernetes生态系统而不断努力的一部分。作为速度最快的开源项目之一，Kubernetes的使用正在爆炸式增长。\u003c/p\u003e","title":"CKA概述、考试形式、考试地址、考纲占比等","type":"posts"},{"content":" 本活动在微信公众号【我的小碗汤】上举行，这里参与答题无效哦！\n接上一篇备战CKA每日一题——第1天\n昨日考题 # 以下 Daemonset yaml 中，哪些是正确的？（多选）\nA. apiVersion: apps/v1 kind: DaemonSet metadata: name: fluentd-elasticsearch namespace: default labels: k8s-app: fluentd-logging spec: selector: matchLabels: name: fluentd-elasticsearch template: metadata: labels: name: fluentd-elasticsearch spec: containers: - name: fluentd-elasticsearch image: gcr.io/fluentd-elasticsearch/fluentd:v2.5.1 restartPolicy: Never B. apiVersion: apps/v1 kind: DaemonSet metadata: name: fluentd-elasticsearch namespace: default labels: k8s-app: fluentd-logging spec: selector: matchLabels: name: fluentd-elasticsearch template: metadata: labels: name: fluentd-elasticsearch spec: containers: - name: fluentd-elasticsearch image: gcr.io/fluentd-elasticsearch/fluentd:v2.5.1 restartPolicy: Onfailure C. apiVersion: apps/v1 kind: DaemonSet metadata: name: fluentd-elasticsearch namespace: default labels: k8s-app: fluentd-logging spec: selector: matchLabels: name: fluentd-elasticsearch template: metadata: labels: name: fluentd-elasticsearch spec: containers: - name: fluentd-elasticsearch image: gcr.io/fluentd-elasticsearch/fluentd:v2.5.1 restartPolicy: Always D. apiVersion: apps/v1 kind: DaemonSet metadata: name: fluentd-elasticsearch namespace: default labels: k8s-app: fluentd-logging spec: selector: matchLabels: name: fluentd-elasticsearch template: metadata: labels: name: fluentd-elasticsearch spec: containers: - name: fluentd-elasticsearch image: gcr.io/fluentd-elasticsearch/fluentd:v2.5.1 昨日答案 # CD\n昨日解析 # 在考试时，只能用谷歌浏览器，并打开两个标签页，一个是考题的标签页，另一个是kubernetes官网标签页。https://kubernetes.io/\n查询daemonset的说明文档，见以下链接：\nhttps://kubernetes.io/docs/concepts/workloads/controllers/daemonset/\nA Pod Template in a DaemonSet must have a RestartPolicy equal to Always, or be unspecified, which defaults to Always.\nDaemonset里的pod Template下必须有RestartPolicy，如果没指定，会默认为Always\nrestartPolicy 字段，可选值为 Always、OnFailure 和 Never。默认为 Always。 一个Pod中可以有多个容器，restartPolicy适用于Pod 中的所有容器。restartPolicy作用是，让kubelet重启失败的容器。\n另外Deployment、Statefulset的restartPolicy也必须为Always，保证pod异常退出，或者健康检查livenessProbe失败后由kubelet重启容器。\nhttps://kubernetes.io/zh/docs/concepts/workloads/controllers/deployment/\nJob和CronJob是运行一次的pod，restartPolicy只能为OnFailure或Never，确保容器执行完成后不再重启。\nhttps://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/\n今日考题 # 在Kubernetes PVC+PV体系下通过CSI实现的volume plugins动态创建pv到pv可被pod使用有哪些组件需要参与？\nA. PersistentVolumeController + CSI-Provisoner + CSI controller plugin B. AttachDetachController + CSI-Attacher + CSI controller plugin C. Kubelet + CSI node plugin 作者简洁 # 作者：小碗汤，一位热爱、认真写作的小伙，目前维护原创公众号：『我的小碗汤』，专注于写golang、docker、kubernetes等知识等提升硬实力的文章，期待你的关注。 转载说明：务必注明来源（注明：来源于公众号：我的小碗汤， 作者：小碗汤）\n","date":"2019年11月19日","externalUrl":null,"permalink":"/posts/%E5%A4%87%E6%88%98cka%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%E7%AC%AC2%E5%A4%A9daemonset%E5%AF%B9%E6%8E%A5%E5%AD%98%E5%82%A8csi%E7%9F%A5%E8%AF%86%E7%82%B9/","section":"Posts","summary":"\u003cblockquote\u003e\n\u003cp\u003e本活动在微信公众号【我的小碗汤】上举行，这里参与答题无效哦！\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003e接上一篇\u003ca href=\"https://liabio.blog.csdn.net/article/details/103126903\" target=\"_blank\"\u003e备战CKA每日一题——第1天\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e","title":"备战CKA每日一题——第2天 | Daemonset、对接存储CSI知识点","type":"posts"},{"content":" 本活动在微信公众号【我的小碗汤】上举行，有送书活动！这里参与答题不能参与到送书活动哦！\n这两年 Kubernetes 已经成为容器编排的事实标准，预计未来两年内将全面普及，现在企业招这块人才需求也越来越大，工资也是很高的，未来这块的发展空间也很大。\n最近正准备备考CKA，CKA是什么？有些人可能还不知道，这里简单普及一下：\nCKA 证书是云原生计算基金会 CNCF 组织的，考察的是你是否具备足够管理 Kubernetes 集群的必备知识。考试形式是上机直接在集群上操作，限时 3 小时，非常考验个人知识的扎实程度和 Kubernetes 实践经验。考上 75 分，你就能拿到证书。考试期间只可查阅K8S官方手册。证书有效期两年，考试费用300美元（国外考试费用就是贵），一年内可有一次免费补考的机会。\nCKA证书的含金量如何？考不考这个证完全取决于个人，因为持证并不等于上岗，尤其是上心仪公司的岗。考证可以帮你获得初级职位，但高级职位需要个人经验的大量积累。而站在面试官的角度看，有这个证至少可以为你搏一个面试机会，尤其是应届生和有转岗想法的程序员。这些人可能缺乏足够经验，但 CKA 证很能体现个人技术水平，行业认可程度也很高。\n考纲如下 # 可访问https://github.com/cncf/curriculum关注最新的考纲变化！\n作为在Kubernetes技术上摸爬滚打1年多的老鸟，最近正准备备考CKA，鉴于此，我希望想证明自己kubernetes开发运维能力的小伙伴能一起从今天开始，我们一起每日一题，在留言区答题打卡。\n今日考题 # 以下 Daemonset yaml 中，哪些是正确的？（多选）\nA. apiVersion: apps/v1 kind: DaemonSet metadata: name: fluentd-elasticsearch namespace: default labels: k8s-app: fluentd-logging spec: selector: matchLabels: name: fluentd-elasticsearch template: metadata: labels: name: fluentd-elasticsearch spec: containers: - name: fluentd-elasticsearch image: gcr.io/fluentd-elasticsearch/fluentd:v2.5.1 restartPolicy: Never B. apiVersion: apps/v1 kind: DaemonSet metadata: name: fluentd-elasticsearch namespace: default labels: k8s-app: fluentd-logging spec: selector: matchLabels: name: fluentd-elasticsearch template: metadata: labels: name: fluentd-elasticsearch spec: containers: - name: fluentd-elasticsearch image: gcr.io/fluentd-elasticsearch/fluentd:v2.5.1 restartPolicy: Onfailure C. apiVersion: apps/v1 kind: DaemonSet metadata: name: fluentd-elasticsearch namespace: default labels: k8s-app: fluentd-logging spec: selector: matchLabels: name: fluentd-elasticsearch template: metadata: labels: name: fluentd-elasticsearch spec: containers: - name: fluentd-elasticsearch image: gcr.io/fluentd-elasticsearch/fluentd:v2.5.1 restartPolicy: Always D. apiVersion: apps/v1 kind: DaemonSet metadata: name: fluentd-elasticsearch namespace: default labels: k8s-app: fluentd-logging spec: selector: matchLabels: name: fluentd-elasticsearch template: metadata: labels: name: fluentd-elasticsearch spec: containers: - name: fluentd-elasticsearch image: gcr.io/fluentd-elasticsearch/fluentd:v2.5.1 每日解答 # 每日答题打卡，第二天会较详细的分析考题答案，尽量做到知其然知其所以然。最终还有电子书送给大家，欢迎参与！我们一起备考。\n作者简洁 # 作者：小碗汤，一位热爱、认真写作的小伙，目前维护原创公众号：『我的小碗汤』，专注于写golang、docker、kubernetes等知识等提升硬实力的文章，期待你的关注。 转载说明：务必注明来源（注明：来源于公众号：我的小碗汤， 作者：小碗汤）\n","date":"2019年11月19日","externalUrl":null,"permalink":"/posts/%E5%A4%87%E6%88%98cka%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98%E7%AC%AC1%E5%A4%A9cka%E7%AE%80%E4%BB%8B%E8%80%83%E7%BA%B2daemonset%E7%9F%A5%E8%AF%86%E7%9F%A5%E8%AF%86%E7%82%B9%E5%88%9D%E6%8E%A2/","section":"Posts","summary":"\u003cblockquote\u003e\n\u003cp\u003e本活动在微信公众号【我的小碗汤】上举行，有送书活动！这里参与答题不能参与到送书活动哦！\u003c/p\u003e","title":"备战CKA每日一题——第1天 | CKA简介、考纲、Daemonset知识知识点初探","type":"posts"},{"content":"","date":"2019年11月3日","externalUrl":null,"permalink":"/tags/blog/","section":"Tags","summary":"","title":"Blog","type":"tags"},{"content":"","date":"2019年11月3日","externalUrl":null,"permalink":"/tags/mysql/","section":"Tags","summary":"","title":"Mysql","type":"tags"},{"content":" 1、背景 # 前两天在阿里云服务器上搭建了自己的博客，一切都很顺利，今天在点击归档按钮时，发现是报404。于是我把solo代码在本地运行起来，用本地的mysql数据库，看是否有同样的问题，结果是可以正常访问的。那就看看服务器上的solo日志呗，结果发现了以下报错：\nCaused by: org.b3log.latke.repository.RepositoryException: java.sql.SQLSyntaxErrorException: Expression #20 of SELECT list is not in GROUP BY clause and contains nonaggregated column \u0026#39;solo.aa.oId\u0026#39; which is not functionally dependent on columns in GROUP BY clause; this is incompatible with sql_mode=only_full_group_by 原来，这个问题出现在MySQL5.7后版本上，默认的sql_mode值是这样的：\nONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION 那么sql_mode 有哪些配置？都代表什么意思？\n2、sql_mode 配置解析 # ONLY_FULL_GROUP_BY\n对于GROUP BY聚合操作，如果在SELECT中的列，没有在GROUP BY中出现，那么这个SQL是不合法的，因为列不在GROUP BY从句中。简而言之，就是SELECT后面接的列必须被GROUP BY后面接的列所包含。如：\nselect a,b from table group by a,b,c; (正确) select a,b,c from table group by a,b; (错误) 这个配置会使得GROUP BY语句环境变得十分狭窄，所以一般都不加这个配置\nNO_AUTO_VALUE_ON_ZERO 该值影响自增长列的插入。默认设置下，插入0或NULL代表生成下一个自增长值。（不信的可以试试，默认的sql_mode你在自增主键列设置为0，该字段会自动变为最新的自增值，效果和null一样），如果用户希望插入的值为0（不改变），该列又是自增长的，那么这个选项就有用了。\nSTRICT_TRANS_TABLES 在该模式下，如果一个值不能插入到一个事务表中，则中断当前的操作，对非事务表不做限制。（InnoDB默认事务表，MyISAM默认非事务表；MySQL事务表支持将批处理当做一个完整的任务统一提交或回滚，即对包含在事务中的多条语句要么全执行，要么全部不执行。非事务表则不支持此种操作，批处理中的语句如果遇到错误，在错误前的语句执行成功，之后的则不执行；MySQL事务表有表锁与行锁非事务表则只有表锁）\nNO_ZERO_IN_DATE 在严格模式下，不允许日期和月份为零\nNO_ZERO_DATE 设置该值，mysql数据库不允许插入零日期，插入零日期会抛出错误而不是警告。\nERROR_FOR_DIVISION_BY_ZERO 在INSERT或UPDATE过程中，如果数据被零除，则产生错误而非警告。如 果未给出该模式，那么数据被零除时MySQL返回NULL\nNO_AUTO_CREATE_USER 禁止GRANT创建密码为空的用户\nNO_ENGINE_SUBSTITUTION 如果需要的存储引擎被禁用或未编译，那么抛出错误。不设置此值时，用默认的存储引擎替代，并抛出一个异常\nPIPES_AS_CONCAT 将”||”视为字符串的连接操作符而非或运算符，这和Oracle数据库是一样的，也和字符串的拼接函数Concat相类似\nANSI_QUOTES 启用ANSI_QUOTES后，不能用双引号来引用字符串，因为它被解释为识别符\n3、测试 # 本地起一个数据库，先查看sql_mode模式：\nmysql\u0026gt; select @@global.sql_mode; +--------------------------------------------+ | @@global.sql_mode | +--------------------------------------------+ | STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION | +--------------------------------------------+ 1 row in set (0.00 sec) mysql\u0026gt; select @@session.sql_mode; +--------------------------------------------+ | @@session.sql_mode | +--------------------------------------------+ | STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION | +--------------------------------------------+ 1 row in set (0.00 sec) 创建一个测试的表：\nmysql\u0026gt; CREATE TABLE IF NOT EXISTS `demo`( -\u0026gt; `id` INT UNSIGNED AUTO_INCREMENT, -\u0026gt; `rank` VARCHAR(100) NOT NULL, -\u0026gt; `name` VARCHAR(40) NOT NULL, -\u0026gt; `gender` TINYINT NOT NULL, -\u0026gt; PRIMARY KEY ( `id` ) -\u0026gt; )ENGINE=InnoDB DEFAULT CHARSET=utf8; Query OK, 0 rows affected (0.02 sec) mysql\u0026gt; mysql\u0026gt; show tables; +----------------+ | Tables_in_test | +----------------+ | demo | +----------------+ 1 row in set (0.00 sec) mysql\u0026gt; desc demo; +--------+------------------+------+-----+---------+------------ | Field | Type | Null | Key | Default | Extra +--------+------------------+------+-----+---------+------------ | id | int(10) unsigned | NO | PRI | NULL | auto_increm | rank | varchar(100) | NO | | NULL | | name | varchar(40) | NO | | NULL | | gender | tinyint(4) | NO | | NULL | +--------+------------------+------+-----+---------+------------ 4 rows in set (0.01 sec) 插入测试数据：\nmysql\u0026gt; insert into demo values(1, \u0026#39;A\u0026#39;, \u0026#39;coderaction1\u0026#39;, \u0026#39;20\u0026#39;); Query OK, 1 row affected (0.01 sec) mysql\u0026gt; insert into demo values(2, \u0026#39;B\u0026#39;, \u0026#39;coderaction2\u0026#39;, \u0026#39;21\u0026#39;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into demo values(3, \u0026#39;A\u0026#39;, \u0026#39;coderaction3\u0026#39;, \u0026#39;22\u0026#39;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into demo values(4, \u0026#39;C\u0026#39;, \u0026#39;coderaction4\u0026#39;, \u0026#39;23\u0026#39;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into demo values(5, \u0026#39;A\u0026#39;, \u0026#39;coderaction5\u0026#39;, \u0026#39;21\u0026#39;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; insert into demo values(6, \u0026#39;C\u0026#39;, \u0026#39;coderaction6\u0026#39;, \u0026#39;28\u0026#39;); Query OK, 1 row affected (0.01 sec) mysql\u0026gt; mysql\u0026gt; select * from demo; +----+------+--------------+--------+ | id | rank | name | gender | +----+------+--------------+--------+ | 1 | A | coderaction1 | 20 | | 2 | B | coderaction2 | 21 | | 3 | A | coderaction3 | 22 | | 4 | C | coderaction4 | 23 | | 5 | A | coderaction5 | 21 | | 6 | C | coderaction6 | 28 | +----+------+--------------+--------+ 6 rows in set (0.00 sec) 分别执行以下sql命令：\nmysql\u0026gt; select count(id) from demo order by rank; +-----------+ | count(id) | +-----------+ | 6 | +-----------+ 1 row in set (0.01 sec) mysql\u0026gt; select count(id) from demo group by rank; +-----------+ | count(id) | +-----------+ | 3 | | 1 | | 2 | +-----------+ 3 rows in set (0.00 sec) mysql\u0026gt; select count(rank),id from demo group by rank; +-------------+----+ | count(rank) | id | +-------------+----+ | 3 | 1 | | 1 | 2 | | 2 | 4 | +-------------+----+ 3 rows in set (0.00 sec) mysql\u0026gt; select count(rank),id from demo group by id; +-------------+----+ | count(rank) | id | +-------------+----+ | 1 | 1 | | 1 | 2 | | 1 | 3 | | 1 | 4 | | 1 | 5 | | 1 | 6 | +-------------+----+ 6 rows in set (0.00 sec) mysql\u0026gt; 可以看到上面四个sql都执行成功。\n修改sql_mode，临时修改sql_mode方式有两种，一种是设置当前会话连接的session级别的sql_mode，另一个是global级别的sql_mode。\nsession级别 # 先来看看session级别的sql_mode，设置方式有两种：\nmysql\u0026gt; set session sql_mode=\u0026#39;ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION\u0026#39;; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; set @@session.sql_mode=\u0026#39;ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION\u0026#39;; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select @@session.sql_mode; +-------------------------------------------------------------------------------------------------------------------------------------------+ | @@session.sql_mode | +-------------------------------------------------------------------------------------------------------------------------------------------+ | ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION | +-------------------------------------------------------------------------------------------------------------------------------------------+ 1 row in set (0.00 sec) 设置session级别sql_mode，当前session级别查询到新的，下次重连后失效。\nglobal级别 # 再看看global级别的sql_mode，设置方式有两种：\nmysql\u0026gt; set @@global.sql_mode=\u0026#39;STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION\u0026#39;; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; set global sql_mode=\u0026#39;STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION\u0026#39;; Query OK, 0 rows affected (0.00 sec) mysql\u0026gt; select @@global.sql_mode; +------------------------------------------------------------------------------------------------------------------------+ | @@global.sql_mode | +------------------------------------------------------------------------------------------------------------------------+ | STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION | +------------------------------------------------------------------------------------------------------------------------+ 1 row in set (0.00 sec) 设置global级别sql_mode，当前session级别查询到还是旧的，所以执行命令时，还是按照旧配置。下次重连后利用新配置。\n当我们设置完上面session级别的sql_mode，在其中加ONLY_FULL_GROUP_BY后，执行测试sql语句报错：\nmysql\u0026gt; select count(rank),id from demo group by rank; ERROR 1055 (42000): Expression #2 of SELECT list is not in GROUP BY clause and contains nonaggregated column \u0026#39;test.demo.id\u0026#39; which is not functionally dependen t on columns in GROUP BY clause; this is incompatible with sql_mode=only_full_group_by mysql\u0026gt; select count(rank),id from demo group by id; +-------------+----+ | count(rank) | id | +-------------+----+ | 1 | 1 | | 1 | 2 | | 1 | 3 | | 1 | 4 | | 1 | 5 | | 1 | 6 | +-------------+----+ 6 rows in set (0.00 sec) 这也验证了：SELECT后面接的列必须被GROUP BY后面接的列所包含。\n注意：通过session和global设置临时生效的，即当mysql重启后，都会失效。需要在mysql启动配置文件中默认设置。\n4、解决办法 # 除了上面测试时用到的临时解决的两种方法。要想mysql重启后依然生效，需要在mysql的配置文件，一般是my.cnf中的[mysqld]下面加sql_mode配置。因为我使用的是k8s部署的mysql，镜像安装和在宿主机上通过软件包安装有一定差别。但最终还是更改的my.cnf。\nkubectl exec -ti mysql-75797cf796-84rdl bash root@mysql-75797cf796-84rdl:/# root@mysql-75797cf796-84rdl:/# cat /etc/mysql/my.cnf # Copyright (c) 2016, Oracle and/or its affiliates. All rights reserved. # ..... !includedir /etc/mysql/conf.d/ !includedir /etc/mysql/mysql.conf.d/ 可以看到这里包含了两个目录下的文件，查看一下，mysql.conf.d下，发现有我们需要更改的文件\ncat /etc/mysql/mysql.conf.d/mysqld.cnf 查看并将该文件用kubectl cp命令拷贝到宿主机上，修改后最终要挂载进入pod里。\nkubectl cp default/mysql-75797cf796-84rdl:/etc/mysql/mysql.conf.d/mysqld.cnf /data/blog-solo/mysql-config/mysqld.cnf 修改后文件如下，主要关注sql_mode\nroot@mysql-75797cf796-84rdl:/# cd /etc/mysql/mysql.conf.d/ root@mysql-75797cf796-84rdl:/etc/mysql/mysql.conf.d# ls -l total 4 -rw-r--r-- 1 root root 1671 Oct 26 11:40 mysqld.cnf root@mysql-75797cf796-84rdl:/etc/mysql/mysql.conf.d# cat mysqld.cnf # Copyright (c) 2014, 2016, Oracle and/or its affiliates. All rights reserved. # ... [mysqld] pid-file\t= /var/run/mysqld/mysqld.pid socket\t= /var/run/mysqld/mysqld.sock datadir\t= /var/lib/mysql sql_mode = STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION #log-error\t= /var/log/mysql/error.log # By default we only accept connections from localhost #bind-address\t= 127.0.0.1 # Disabling symbolic-links is recommended to prevent assorted security risks symbolic-links=0 root@mysql-75797cf796-84rdl:/etc/mysql/mysql.conf.d# 最后修改mysql-deployment：\napiVersion: extensions/v1beta1 kind: Deployment metadata: name: mysql spec: replicas: 1 template: metadata: labels: name: mysql spec: containers: - name: mysql image: mysql:5.7.28 imagePullPolicy: IfNotPresent ports: - containerPort: 3306 env: - name: MYSQL_ROOT_PASSWORD value: \u0026#34;password\u0026#34; volumeMounts: - name: mysql-config mountPath: /etc/mysql/mysql.conf.d - name: mysql-data mountPath: /var/lib/mysql volumes: - name: mysql-config hostPath: path: /data/blog-solo/mysql-config/ - name: mysql-data hostPath: path: /data/blog-solo/mysql-data/ 注意要把配置文件和数据都挂载到宿主机上，否则pod重启后就会丢失配置和数据。\n4、参考 # docker 下修改 mysql sql_mode和配置文件\n记一次Group by 查询时的ONLY_FULL_GROUP_BY错误以及后续\n本公众号免费 提供csdn下载服务，海量IT学习资源如果你准备入IT坑，励志成为优秀的程序猿，那么这些资源很适合你，包括但不限于java、go、python、springcloud、elk、嵌入式 、大数据、面试资料、前端 等资源。同时我们组建了一个技术交流群，里面有很多大佬，会不定时分享技术文章，如果你想来一起学习提高，可以公众号后台回复【2】，免费邀请加技术交流群互相学习提高，会不定期分享编程IT相关资源。\n扫码关注，精彩内容第一时间推给你\n","date":"2019年11月3日","externalUrl":null,"permalink":"/posts/%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E6%97%B6%E8%A2%ABmysql%E7%9A%84sqlmode%E4%B8%ADonlyfullgroupby%E5%9D%91%E5%80%92%E4%BA%86/","section":"Posts","summary":"\u003ch2 class=\"relative group\"\u003e1、背景 \n    \u003cdiv id=\"1背景\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#1%e8%83%8c%e6%99%af\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e前两天在阿里云服务器上搭建了自己的博客，一切都很顺利，今天在点击归档按钮时，发现是报404。于是我把solo代码在本地运行起来，用本地的mysql数据库，看是否有同样的问题，结果是可以正常访问的。那就看看服务器上的solo日志呗，结果发现了以下报错：\u003c/p\u003e","title":"搭建博客时，被mysql的sql_mode中ONLY_FULL_GROUP_BY坑倒了","type":"posts"},{"content":"大家都知道最近阿里云服务器很便宜火爆，于是小编也入手了一台3年的，配置：1核2G内存，40G硬盘。\n今年比去年便宜，10.24~11.11购买是1年86元，3年229元，打开以下链接参与，也可以扫描文末的海报二维码，或点击文末阅读原文\n点我参与哦哦哦哦哦哦哦哦哦哦哦哦哦哦哦哦哦哦哦哦哦哦哦哦\n买了不能闲置着，可以搭建自己的网站、博客、代码仓库等，用处广泛着呢！有很多朋友问怎么搭建网站，怎么用？应小伙伴们的需求，今天来学习一下最简单的网站搭建，只需要5分钟，就可以轻松搭建！\n可以浏览查看我的博客:\n我的博客，点我我我我我我我我我我我我我我我我我我我我我我我\n主页效果 # ​\n后台管理发布文章界面：\n自带管理功能，使用github账号登陆即可。\nSolo是一款小而美Java编写的博客系统，功能丰富，插件化，皮肤可选可定制，管理方便，社区活跃。\n本文章介绍利用Solo开源博客系统在云服务器上搭建自己的博客，让我开始吧。\n前提，把需要公网IP访问的端口，需要在阿里云控制台加到安全组里放行。\ndocker搭建 # 第一步就是安装docker\nyum install docker.x86_64 -y 安装完成后启动docker\nsystemctl start docker 安装mysql # 参考历史文章：\nmysql镜像安装\n比如用上面几行命令部署mysql，把容器内3306端口映射到宿主机的3307端口。到时候就可以用{阿里云公网IP:3307访问数据库}，mysql部署好后，先手动建库（库名 solo，字符集使用 utf8mb4，排序规则 utf8mb4_general_ci）\n启动solo容器 # 然后启动容器\ndocker run --detach --name solo --network=host \\ --env RUNTIME_DB=\u0026#34;MYSQL\u0026#34; \\ --env JDBC_USERNAME=\u0026#34;root\u0026#34; \\ --env JDBC_PASSWORD=\u0026#34;123456\u0026#34; \\ --env JDBC_DRIVER=\u0026#34;com.mysql.cj.jdbc.Driver\u0026#34; \\ --env JDBC_URL=\u0026#34;jdbc:mysql://47.91.6.217:3307/solo?useUnicode=yes\u0026amp;characterEncoding=UTF-8\u0026amp;useSSL=false\u0026amp;serverTimezone=UTC\u0026#34; \\ b3log/solo --listen_port=8080 --server_scheme=http --server_host=47.91.6.217 \u0026ndash;detach即-d参数指定后台运行， \u0026ndash;name指定容器名称， \u0026ndash;env指定solo系统运行数据库参数， \u0026ndash;listen_port：进程监听端口 \u0026ndash;server_scheme：最终访问协议，如果反代服务启用了 HTTPS 这里也需要改为 https \u0026ndash;server_host：最终访问域名或公网 IP，不要带端口 \u0026ndash;server_port：最终访问端口，使用浏览器默认的 80 或者 443 的话值留空即可 使用的镜像是b3log/solo最新版，这里比如，47.91.6.217是我阿里云公网IP，用47.91.6.217:8080访问：\nk8s集群中部署 # mysql和solo都使用pod方式部署，分别创建mysql deployment管理pod，mysql service提供service clusterIP供solo调用；创建solo deployment管理solo服务，solo service提供简单的服务发现，solo ingress提供域名配置，入口负载均衡。如果没有域名，可以直接通过NodePort service暴露端口。\nmysql的deploy，这里注意要把配置文件和数据挂载到宿主机上，便于配置文件修改，以及数据在pod重启后保留，不丢失，注意mysql5.7中要在配置文件中加修改sql_mode的值为STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION 不能有ONLY_FULL_GROUP_BY，否则执行group by语句时会报错。\n```yaml apiVersion: extensions/v1beta1 kind: Deployment metadata: name: mysql spec: replicas: 1 template: metadata: labels: name: mysql spec: containers: - name: mysql image: mysql:5.7.28 imagePullPolicy: IfNotPresent ports: - containerPort: 3306 env: - name: MYSQL_ROOT_PASSWORD value: \u0026#34;password\u0026#34; volumeMounts: - name: mysql-config mountPath: /etc/mysql/mysql.conf.d - name: mysql-data mountPath: /var/lib/mysql volumes: - name: mysql-config hostPath: path: /data/blog-solo/mysql-config/ - name: mysql-data hostPath: path: /data/blog-solo/mysql-data/ mysql的service：\napiVersion: v1 kind: Service metadata: name: mysql labels: name: mysql spec: type: ClusterIP ports: - port: 3306 protocol: TCP targetPort: 3306 name: http selector: name: mysql solo的deploy：\napiVersion: extensions/v1beta1 kind: Deployment metadata: name: solo spec: replicas: 1 template: metadata: labels: name: solo spec: containers: - name: solo image: b3log/solo imagePullPolicy: IfNotPresent args: [\u0026#34;--server_scheme=http\u0026#34;, \u0026#34;--server_host=blog.liabio.cn\u0026#34;] ports: - containerPort: 8080 env: - name: RUNTIME_DB value: MYSQL - name: JDBC_USERNAME value: solo - name: JDBC_PASSWORD value: solo-liabio - name: JDBC_DRIVER value: \u0026#34;com.mysql.cj.jdbc.Driver\u0026#34; - name: JDBC_URL value: \u0026#34;jdbc:mysql://10.100.133.125:3306/solo?useUnicode=yes\u0026amp;characterEncoding=UTF-8\u0026amp;useSSL=false\u0026amp;serverTimezone=UTC\u0026#34; solo的service：\napiVersion: v1 kind: Service metadata: name: solo labels: name: solo spec: type: ClusterIP ports: - port: 8080 protocol: TCP targetPort: 8080 name: http selector: name: solo 这里我用到的是ClusterIP的service，没有用到NodePort的service，是因为准备用ingress-nginx做负载。\ningress-nginx的部署方式可以参考历史文章：\nk8s中负载均衡器【ingress-nginx】部署\nsolo的ingress：\napiVersion: extensions/v1beta1 kind: Ingress metadata: name: solo spec: rules: - host: blog.liabio.cn http: paths: - backend: serviceName: solo servicePort: 8080 path: / 由于ingress-nginx组件使用hostNetwork方式部署，所以可以通过公网IP:80端口访问。\n备注：如果要部署k8s，1核2G可能扛不住，至少得2核4G\n需要参与本次阿里云购买的可以扫描下面的码\n本文首发于公众号【我的小碗汤】本公众号免费**提供csdn下载服务，海量IT学习资源，**如果你准备入IT坑，励志成为优秀的程序猿，那么这些资源很适合你，包括但不限于java、go、python、springcloud、elk、嵌入式 、大数据、面试资料、前端 等资源。扫码关注：\n# ","date":"2019年10月24日","externalUrl":null,"permalink":"/posts/5%E5%88%86%E9%92%9F%E6%90%AD%E5%BB%BA%E4%B8%AA%E5%8D%9A%E5%AE%A2%E7%8E%A9%E7%8E%A9/","section":"Posts","summary":"\u003cp\u003e大家都知道最近阿里云服务器很便宜火爆，于是小编也入手了一台3年的，配置：1核2G内存，40G硬盘。\u003c/p\u003e","title":"5分钟搭建个博客玩玩","type":"posts"},{"content":" kubernetes垃圾回收器GarbageCollector 源码分析 # kubernetes版本：1.13.2\n背景 # 由于operator创建的redis集群，在kubernetes apiserver重启后，redis集群被异常删除（包括redis exporter statefulset、redis statefulset）。删除后operator将其重建，重新组建集群，实例IP发生变更（中间件容器化，我们开发了固定IP，当statefulset删除后，IP会被回收），导致创建集群失败，最终集群不可用。\n经多次复现，apiserver重启后，通过查询redis operator日志，并没有发现主动去删除redis集群（redis statefulset）、监控实例（redis exporter）。进一步去查看kube-controller-manager的日志，将其日志级别设置\u0026ndash;v=5，继续复现，最终在kube-controller-manager日志中发现如下日志：\n可以看到是garbage collector触发删除操作的。这个问题在apiserver正常的时候是不存在，要想弄其究竟，就得看看kube-controller-manager内置组件garbage collector这个控制器的逻辑。\n正文 # gc整体架构 # GarbageCollector Controller源码主要分为以下几部分：\nmonitors作为生产者将变化的资源放入graphChanges队列；同时restMapper定期检测集群内资源类型，刷新monitors runProcessGraphChanges从graphChanges队列中取出变化的item，根据情况放入attemptToDelete队列； runProcessGraphChanges从graphChanges队列中取出变化的item，根据情况放入attemptToOrphan队列； runAttemptToDeleteWorker从attemptToDelete队列取出，尝试删除垃圾资源； runAttemptToOrphanWorker从attemptToOrphan队列取出，处理该孤立的资源； 想要启用GC，需要在kube-apiserver和kube-controller-manager的启动参数中都设置--enable-garbage-collector为true,1.13.2版本中默认开启GC。\n需要注意：两组件该参数必须保持同步。\ngc启动 # kube-controller-manager启动入口，app.NewControllerManagerCommand()中加载controller manager默认启动参数，创建* cobra.Command对象：\nfunc main() { rand.Seed(time.Now().UnixNano()) //加载controller manager默认启动参数，创建* cobra.Command对象 command := app.NewControllerManagerCommand() //......省略....... //执行cobra.command，并启动controller-manager if err := command.Execute(); err != nil { fmt.Fprintf(os.Stderr, \u0026#34;%v\\n\u0026#34;, err) os.Exit(1) } } 以下代码处去启动kube-controller-manager：\nNewDefaultComponentConfig(ports.InsecureKubeControllerManagerPort)加载各个控制器的配置：\n//NewKubeControllerManagerOptions使用默认配置创建一个新的KubeControllerManagerOptions func NewKubeControllerManagerOptions() (*KubeControllerManagerOptions, error) { //加载各个控制器的默认配置 componentConfig, err := NewDefaultComponentConfig(ports.InsecureKubeControllerManagerPort) if err != nil { return nil, err } s := KubeControllerManagerOptions{ Generic: cmoptions.NewGenericControllerManagerConfigurationOptions(componentConfig.Generic), //.....省略 GarbageCollectorController: \u0026amp;GarbageCollectorControllerOptions{ ConcurrentGCSyncs: componentConfig.GarbageCollectorController.ConcurrentGCSyncs, EnableGarbageCollector: componentConfig.GarbageCollectorController.EnableGarbageCollector, }, //.....省略 } //gc忽略的资源对象列表 gcIgnoredResources := make([]kubectrlmgrconfig.GroupResource, 0, len(garbagecollector.DefaultIgnoredResources())) for r := range garbagecollector.DefaultIgnoredResources() { gcIgnoredResources = append(gcIgnoredResources, kubectrlmgrconfig.GroupResource{Group: r.Group, Resource: r.Resource}) } s.GarbageCollectorController.GCIgnoredResources = gcIgnoredResources return \u0026amp;s, nil } // NewDefaultComponentConfig返回kube-controller管理器配置对象 func NewDefaultComponentConfig(insecurePort int32) (kubectrlmgrconfig.KubeControllerManagerConfiguration, error) { scheme := runtime.NewScheme() if err := kubectrlmgrschemev1alpha1.AddToScheme(scheme); err != nil { return kubectrlmgrconfig.KubeControllerManagerConfiguration{}, err } if err := kubectrlmgrconfig.AddToScheme(scheme); err != nil { return kubectrlmgrconfig.KubeControllerManagerConfiguration{}, err } versioned := kubectrlmgrconfigv1alpha1.KubeControllerManagerConfiguration{} //加载默认参数 scheme.Default(\u0026amp;versioned) internal := kubectrlmgrconfig.KubeControllerManagerConfiguration{} if err := scheme.Convert(\u0026amp;versioned, \u0026amp;internal, nil); err != nil { return internal, err } internal.Generic.Port = insecurePort return internal, nil } // 根据Object，获取提供的默认参数 func (s *Scheme) Default(src Object) { if fn, ok := s.defaulterFuncs[reflect.TypeOf(src)]; ok { fn(src) } } s.defaulterFuncs类型为map[reflect.Type]func(interface{})，用于根据指针类型获取默认值函数。该map中的数据从哪里来的呢？\n代码位于src\\k8s.io\\kubernetes\\pkg\\controller\\apis\\config\\v1alpha1\\zz_generated.defaults.go\n可以看到默认参数中garbage collector中默认开启gc（EnableGarbageCollector），并发数为20（ConcurrentGCSyncs）\nfunc SetDefaults_GarbageCollectorControllerConfiguration(obj *kubectrlmgrconfigv1alpha1.GarbageCollectorControllerConfiguration) { if obj.EnableGarbageCollector == nil { obj.EnableGarbageCollector = utilpointer.BoolPtr(true) } if obj.ConcurrentGCSyncs == 0 { obj.ConcurrentGCSyncs = 20 } } 回到Run函数，里面调用了NewControllerInitializers启动所有控制器：\n重点来到启动garbage collector的startGarbageCollectorController函数：\nfunc startGarbageCollectorController(ctx ControllerContext) (http.Handler, bool, error) { //k8s 1.13.2中默认为true,可在kube-apiserver和kube-controller-manager的启动参数中加--enable-garbage-conllector=false设置 //需保证这两个组件中参数值一致 if !ctx.ComponentConfig.GarbageCollectorController.EnableGarbageCollector { return nil, false, nil } //k8s各种原生资源对象客户端集合(默认启动参数中用SimpleControllerClientBuilder构建) gcClientset := ctx.ClientBuilder.ClientOrDie(\u0026#34;generic-garbage-collector\u0026#34;) discoveryClient := cacheddiscovery.NewMemCacheClient(gcClientset.Discovery()) //生成rest config config := ctx.ClientBuilder.ConfigOrDie(\u0026#34;generic-garbage-collector\u0026#34;) dynamicClient, err := dynamic.NewForConfig(config) if err != nil { return nil, true, err } // Get an initial set of deletable resources to prime the garbage collector. //获取一组初始可删除资源以填充垃圾收集器。 deletableResources := garbagecollector.GetDeletableResources(discoveryClient) ignoredResources := make(map[schema.GroupResource]struct{}) //忽略gc的资源类型 for _, r := range ctx.ComponentConfig.GarbageCollectorController.GCIgnoredResources { ignoredResources[schema.GroupResource{Group: r.Group, Resource: r.Resource}] = struct{}{} } garbageCollector, err := garbagecollector.NewGarbageCollector( dynamicClient, ctx.RESTMapper, deletableResources, ignoredResources, ctx.InformerFactory, ctx.InformersStarted, ) if err != nil { return nil, true, fmt.Errorf(\u0026#34;Failed to start the generic garbage collector: %v\u0026#34;, err) } // Start the garbage collector. //启动参数中默认是20个协程 workers := int(ctx.ComponentConfig.GarbageCollectorController.ConcurrentGCSyncs) //启动monitors和deleteWorkers、orphanWorkers go garbageCollector.Run(workers, ctx.Stop) // Periodically refresh the RESTMapper with new discovery information and sync // the garbage collector. //使用新的发现信息定期刷新RESTMapper并同步垃圾收集器。 go garbageCollector.Sync(gcClientset.Discovery(), 30*time.Second, ctx.Stop) //gc提供debug dot grap依赖关系图接口 return garbagecollector.NewDebugHandler(garbageCollector), true, nil } 该函数主要作用有：\n1、deletableResources := garbagecollector.GetDeletableResources(discoveryClient)获取集群内所有可删除的资源对象；排除掉忽略的资源对象。\n2、构建garbageCollector结构体对象；\n3、garbageCollector.Run(workers, ctx.Stop)启动一个monitors用来监听资源对象的变化（对应的由runProcessGraphChanges死循环处理），和默认20个deleteWorkers协程处理可删除的资源对象、20个orphanWorkers协程处理孤儿对象。\n4、garbageCollector.Sync(gcClientset.Discovery(), 30*time.Second, ctx.Stop) 定时去获取一个集群内是否有新类型的资源对象的加入，并重新刷新monitors，以监听新类型的资源对象。\n5、garbagecollector.NewDebugHandler(garbageCollector)注册debug接口，用来提供获取dot流程图接口：\ncurl http://127.0.0.1:10252/debug/controllers/garbagecollector/graph?uid=11211212edsaddkqedmk12 使用graphviz提供的dot.exe可以生成svg格式的图，可用google浏览器查看如下：\n// curl http://127.0.0.1:10252/debug/controllers/garbagecollector/graph?uid=11211212edsaddkqedmk12 func (h *debugHTTPHandler) ServeHTTP(w http.ResponseWriter, req *http.Request) { if req.URL.Path != \u0026#34;/graph\u0026#34; { http.Error(w, \u0026#34;\u0026#34;, http.StatusNotFound) return } var graph graph.Directed if uidStrings := req.URL.Query()[\u0026#34;uid\u0026#34;]; len(uidStrings) \u0026gt; 0 { uids := []types.UID{} for _, uidString := range uidStrings { uids = append(uids, types.UID(uidString)) } graph = h.controller.dependencyGraphBuilder.uidToNode.ToGonumGraphForObj(uids...) } else { graph = h.controller.dependencyGraphBuilder.uidToNode.ToGonumGraph() } //生成dot流程图数据,用graphviz工具中的dot.exe工具转换为svg图(用google浏览器打开)或者png图 //API参考:https://godoc.org/gonum.org/v1/gonum/graph //graphviz下载地址:https://graphviz.gitlab.io/_pages/Download/Download_windows.html //dot.exe test.dot -T svg -o test.svg data, err := dot.Marshal(graph, \u0026#34;full\u0026#34;, \u0026#34;\u0026#34;, \u0026#34; \u0026#34;, false) if err != nil { http.Error(w, err.Error(), http.StatusInternalServerError) return } w.Write(data) w.WriteHeader(http.StatusOK) } GarbageCollector通过restMapper定期重置可删除的资源类型，更新GraphBuilder中的monitors，monitors将创建所有资源类型的变更通知回调函数，将变化的资源对象加入到GraphBuilder的graphChanges队列，GraphBuilder的runProcessGraphChanges()会一直从队列中获取变化，构建一个缓存对象之间依赖关系的图形，以及触发dependencyGraphBuilder将可能被垃圾收集的对象排队到attemptToDelete队列，并将其依赖项需要孤立的对象排队到attemptToOrphan队列。GarbageCollector具有使用这两个队列的工作人员runAttemptToDeleteWorker和runAttemptToOrphanWorker死循环，分别从attemptToDelete队列和attemptToOrphan队列取出，向API服务器发送请求以相应地删除更新对象。\n// GarbageCollector运行反射器来监视托管API对象的更改，将结果汇总到单线程dependencyGraphBuilder， // 构建一个缓存对象之间依赖关系的图形。由图变化触发，dependencyGraphBuilder将可能被垃圾收集的对象 // 排队到`attemptToDelete`队列，并将其依赖项需要孤立的对象排队到`attemptToOrphan`队列。 // GarbageCollector具有使用这两个队列的工作人员，向API服务器发送请求以相应地删除更新对象。 // 请注意，让dependencyGraphBuilder通知垃圾收集器确保垃圾收集器使用至少与发送通知一样最新的图形进行操作。 type GarbageCollector struct { // resettableRESTMapper是一个RESTMapper，它能够在discovery资源类型时重置自己 restMapper resettableRESTMapper // dynamicClient提供操作集群内所有资源对象的接口方法,包括k8s内置、CRD生成的自定义资源 dynamicClient dynamic.Interface //垃圾收集器尝试在时间成熟时删除attemptToDelete队列中的item attemptToDelete workqueue.RateLimitingInterface //垃圾收集器尝试孤立attemptToOrphan队列中item的依赖项，然后删除item attemptToOrphan workqueue.RateLimitingInterface dependencyGraphBuilder *GraphBuilder // 有owner的资源对象,才会给absentOwnerCache填充不存在的Owner信息 absentOwnerCache *UIDCache sharedInformers informers.SharedInformerFactory workerLock sync.RWMutex } // GraphBuilder：基于informers提供的事件，GraphBuilder更新 // uidToNode，一个缓存我们所知的依赖关系的图，并将 // 项放入attemptToDelete和attemptToOrphan队列 type GraphBuilder struct { restMapper meta.RESTMapper //每个监视器列表/监视资源，结果汇集到dependencyGraphBuilder monitors monitors monitorLock sync.RWMutex // informersStarted is closed after after all of the controllers have been initialized and are running. // After that it is safe to start them here, before that it is not. // informersStarted在所有控制器初始化并运行后关闭。之后在这里启动它们是安全的，在此之前它不是。 informersStarted \u0026lt;-chan struct{} // stopCh drives shutdown. When a receive from it unblocks, monitors will shut down. // This channel is also protected by monitorLock. // stopCh驱动器关闭当来自它的接收解除阻塞时，监视器将关闭。 此channel也受monitorLock保护。 stopCh \u0026lt;-chan struct{} // running tracks whether Run() has been called. // it is protected by monitorLock. //运行轨道是否已调用Run()它受monitorLock保护。 running bool dynamicClient dynamic.Interface // monitors are the producer of the graphChanges queue, graphBuilder alters // the in-memory graph according to the changes. // monitor是graphChanges队列的生成者，graphBuilder根据更改改变了内存中的图形。 graphChanges workqueue.RateLimitingInterface // uidToNode doesn\u0026#39;t require a lock to protect, because only the // single-threaded GraphBuilder.processGraphChanges() reads/writes it. //uidToNode不需要锁保护，因为只有单线程GraphBuilder.processGraphChanges()读写它。 uidToNode *concurrentUIDToNode // GraphBuilder is the producer of attemptToDelete and attemptToOrphan, GC is the consumer. // GraphBuilder是attemptToDelete和attemptToOrphan的生产者，GC是消费者。 attemptToDelete workqueue.RateLimitingInterface attemptToOrphan workqueue.RateLimitingInterface // GraphBuilder and GC share the absentOwnerCache. Objects that are known to // be non-existent are added to the cached. // GraphBuilder和GC共享absentOwnerCache。已知不存在的对象将添加到缓存中。 absentOwnerCache *UIDCache //所有k8s资源对象集的informer sharedInformers informers.SharedInformerFactory //监视器忽略的资源对象集 ignoredResources map[schema.GroupResource]struct{} } 创建NewGarbageCollector结构体：\nfunc NewGarbageCollector( dynamicClient dynamic.Interface, mapper resettableRESTMapper, deletableResources map[schema.GroupVersionResource]struct{}, ignoredResources map[schema.GroupResource]struct{}, sharedInformers informers.SharedInformerFactory, informersStarted \u0026lt;-chan struct{}, ) (*GarbageCollector, error) { attemptToDelete := workqueue.NewNamedRateLimitingQueue(workqueue.DefaultControllerRateLimiter(), \u0026#34;garbage_collector_attempt_to_delete\u0026#34;) attemptToOrphan := workqueue.NewNamedRateLimitingQueue(workqueue.DefaultControllerRateLimiter(), \u0026#34;garbage_collector_attempt_to_orphan\u0026#34;) absentOwnerCache := NewUIDCache(500) gc := \u0026amp;GarbageCollector{ dynamicClient: dynamicClient, restMapper: mapper, attemptToDelete: attemptToDelete, attemptToOrphan: attemptToOrphan, absentOwnerCache: absentOwnerCache, } gb := \u0026amp;GraphBuilder{ dynamicClient: dynamicClient, informersStarted: informersStarted, restMapper: mapper, graphChanges: workqueue.NewNamedRateLimitingQueue(workqueue.DefaultControllerRateLimiter(), \u0026#34;garbage_collector_graph_changes\u0026#34;), uidToNode: \u0026amp;concurrentUIDToNode{ uidToNode: make(map[types.UID]*node), }, attemptToDelete: attemptToDelete, attemptToOrphan: attemptToOrphan, absentOwnerCache: absentOwnerCache, sharedInformers: sharedInformers, ignoredResources: ignoredResources, } //初始化各个资源对象的monitors，启动各资源对象的监听器，变化时触发回调，将其加入graphChanges 队列 if err := gb.syncMonitors(deletableResources); err != nil { utilruntime.HandleError(fmt.Errorf(\u0026#34;failed to sync all monitors: %v\u0026#34;, err)) } gc.dependencyGraphBuilder = gb return gc, nil } 主要功能：\n1、构建GarbageCollector结构体；\n2、构建依赖结构图维护结构体GraphBuilder，和GarbageCollector共用attemptToDelete和attemptToOrphan队列，GraphBuilder作为生产着将适当资源放到attemptToDelete或者attemptToOrphan队列，供GarbageCollector中的worker进行消费；\n3、初始化各个资源对象的monitors，启动各资源对象的监听器，变化时触发回调，将其加入graphChanges 队列。\ngb.syncMonitors(deletableResources)方法中最主要的是c, s, err := gb.controllerFor(resource, kind)\nfunc (gb *GraphBuilder) controllerFor(resource schema.GroupVersionResource, kind schema.GroupVersionKind) (cache.Controller, cache.Store, error) { handlers := cache.ResourceEventHandlerFuncs{ // add the event to the dependencyGraphBuilder\u0026#39;s graphChanges. // 将事件添加到dependencyGraphBuilder的graphChanges中。 AddFunc: func(obj interface{}) { event := \u0026amp;event{ eventType: addEvent, obj: obj, gvk: kind, } gb.graphChanges.Add(event) }, UpdateFunc: func(oldObj, newObj interface{}) { // TODO: check if there are differences in the ownerRefs, // finalizers, and DeletionTimestamp; if not, ignore the update. //TODO：检查ownerRefs， finalizers和DeletionTimestamp是否存在差异;如果没有，请忽略更新。 event := \u0026amp;event{ eventType: updateEvent, obj: newObj, oldObj: oldObj, gvk: kind, } gb.graphChanges.Add(event) }, DeleteFunc: func(obj interface{}) { // delta fifo may wrap the object in a cache.DeletedFinalStateUnknown, unwrap it // delta fifo可以将对象包装在cache.DeletedFinalStateUnknown中，解包它 if deletedFinalStateUnknown, ok := obj.(cache.DeletedFinalStateUnknown); ok { obj = deletedFinalStateUnknown.Obj } event := \u0026amp;event{ eventType: deleteEvent, obj: obj, gvk: kind, } gb.graphChanges.Add(event) }, } shared, err := gb.sharedInformers.ForResource(resource) if err == nil { klog.V(4).Infof(\u0026#34;using a shared informer for resource %q, kind %q\u0026#34;, resource.String(), kind.String()) // need to clone because it\u0026#39;s from a shared cache shared.Informer().AddEventHandlerWithResyncPeriod(handlers, ResourceResyncTime) return shared.Informer().GetController(), shared.Informer().GetStore(), nil } else { //获取资源对象时出错会到这里,比如非k8s内置RedisCluster、clusterbases、clusters、esclusters、volumeproviders、stsmasters、appapps、mysqlclusters、brokerclusters、clustertemplates; //内置的networkPolicies、apiservices、customresourcedefinitions klog.V(4).Infof(\u0026#34;unable to use a shared informer for resource %q, kind %q: %v\u0026#34;, resource.String(), kind.String(), err) } // TODO: consider store in one storage. // TODO: 考虑存储在一个存储中。 klog.V(5).Infof(\u0026#34;create storage for resource %s\u0026#34;, resource) //上面失败的资源对象的store和controller store, monitor := cache.NewInformer( listWatcher(gb.dynamicClient, resource), nil, ResourceResyncTime, // don\u0026#39;t need to clone because it\u0026#39;s not from shared cache //不需要克隆，因为它不是来自共享缓存 handlers, ) return monitor, store, nil } 该方法主要功能是：\n1、将新增、更改、删除的资源对象构建为event结构体，放入GraphBuilder的graphChanges队列里，最终被runProcessGraphChanges这个worker消费；\n2、构建大多数内置资源的SharedInformerFactory，构建失败的用cache.NewInformer构建（通过CRD定义的对象以及部分k8s内置对象）\n代码继续回到k8s.io\\kubernetes\\cmd\\kube-controller-manager\\app\\core.go中的startGarbageCollectorController中，看 garbageCollector.Run(workers, ctx.Stop)方法：\nfunc (gc *GarbageCollector) Run(workers int, stopCh \u0026lt;-chan struct{}) { defer utilruntime.HandleCrash() defer gc.attemptToDelete.ShutDown() defer gc.attemptToOrphan.ShutDown() defer gc.dependencyGraphBuilder.graphChanges.ShutDown() klog.Infof(\u0026#34;Starting garbage collector controller\u0026#34;) defer klog.Infof(\u0026#34;Shutting down garbage collector controller\u0026#34;) //协程运行生产者monitors go gc.dependencyGraphBuilder.Run(stopCh) //等待dependencyGraphBuilder缓存开始同步 if !controller.WaitForCacheSync(\u0026#34;garbage collector\u0026#34;, stopCh, gc.dependencyGraphBuilder.IsSynced) { return } //垃圾收集器：所有资源监视器都已同步。继续收集垃圾 klog.Infof(\u0026#34;Garbage collector: all resource monitors have synced. Proceeding to collect garbage\u0026#34;) // gc workers //协程运行消费者DeleteWorkers和OrphanWorkers for i := 0; i \u0026lt; workers; i++ { //默认参数为20个并发协程尝试delete worker go wait.Until(gc.runAttemptToDeleteWorker, 1*time.Second, stopCh) //默认参数为20个并发协程尝试orphan worker go wait.Until(gc.runAttemptToOrphanWorker, 1*time.Second, stopCh) } \u0026lt;-stopCh } gc.dependencyGraphBuilder.Run(stopCh)主要功能：\n1、gb.startMonitors()启动监听资源变化的informer；\n2、wait.Until(gb.runProcessGraphChanges, 1*time.Second, stopCh)开启从队列GraphBuilder.graphChanges中消费的worker\n启动20个runAttemptToDeleteWorker和20个runAttemptToOrphanWorker\nrunProcessGraphChanges处理主流程 # 来到源码k8s.io\\kubernetes\\pkg\\controller\\garbagecollector\\graph_builder.go中，runProcessGraphChanges中一直死循环处理变化的资源对象：\nfunc (gb *GraphBuilder) runProcessGraphChanges() { for gb.processGraphChanges() { } } 一个协程一直循环从graphChanges队列中获取变化的资源对象，更新图形，填充dirty_queue。(graphChanges队列里数据来源于各个资源的monitors监听资源变化回调addFunc、updateFunc、deleteFunc)\n// Dequeueing an event from graphChanges, updating graph, populating dirty_queue. //从graphChanges中获取事件，更新图形，填充dirty_queue。(graphChanges队列里数据来源于各个资源的monitors监听资源变化回调addFunc、updateFunc、deleteFunc) func (gb *GraphBuilder) processGraphChanges() bool { item, quit := gb.graphChanges.Get() if quit { return false } defer gb.graphChanges.Done(item) event, ok := item.(*event) if !ok { utilruntime.HandleError(fmt.Errorf(\u0026#34;expect a *event, got %v\u0026#34;, item)) return true } obj := event.obj //获取该变化资源obj的accessor accessor, err := meta.Accessor(obj) if err != nil { utilruntime.HandleError(fmt.Errorf(\u0026#34;cannot access obj: %v\u0026#34;, err)) return true } klog.V(5).Infof(\u0026#34;GraphBuilder process object: %s/%s, namespace %s, name %s, uid %s, event type %v\u0026#34;, event.gvk.GroupVersion().String(), event.gvk.Kind, accessor.GetNamespace(), accessor.GetName(), string(accessor.GetUID()), event.eventType) // Check if the node already exists // 检查节点是否已存在 //根据该变化资源obj的UID //uidToNode维护着资源对象依赖关系图表结构 existingNode, found := gb.uidToNode.Read(accessor.GetUID()) if found { // this marks the node as having been observed via an informer event // 1. this depends on graphChanges only containing add/update events from the actual informer // 2. this allows things tracking virtual nodes\u0026#39; existence to stop polling and rely on informer events //这标志着节点已经通过informer事件 // 1.进行了观察。这取决于仅包含来自实际informer的添加/更新事件的graphChange // 2.这允许跟踪虚拟节点的存在以停止轮询和依赖informer事件 existingNode.markObserved() } switch { //gc第一次运行时，uidToNode尚且没有初始化资源对象依赖关系图表结构，所以found为false，会新增节点 case (event.eventType == addEvent || event.eventType == updateEvent) \u0026amp;\u0026amp; !found: newNode := \u0026amp;node{ identity: objectReference{ OwnerReference: metav1.OwnerReference{ APIVersion: event.gvk.GroupVersion().String(), Kind: event.gvk.Kind, UID: accessor.GetUID(), Name: accessor.GetName(), }, Namespace: accessor.GetNamespace(), }, dependents: make(map[*node]struct{}), owners: accessor.GetOwnerReferences(), deletingDependents: beingDeleted(accessor) \u0026amp;\u0026amp; hasDeleteDependentsFinalizer(accessor), beingDeleted: beingDeleted(accessor), } gb.insertNode(newNode) // the underlying delta_fifo may combine a creation and a deletion into // one event, so we need to further process the event. //底层delta_fifo可以将创建和删除组合成一个事件，因此我们需要进一步处理事件。 gb.processTransitions(event.oldObj, accessor, newNode) //uidToNode已经初始化资源对象依赖关系图表结构，所以found为true case (event.eventType == addEvent || event.eventType == updateEvent) \u0026amp;\u0026amp; found: // handle changes in ownerReferences //处理ownerReferences中的更改 added, removed, changed := referencesDiffs(existingNode.owners, accessor.GetOwnerReferences()) if len(added) != 0 || len(removed) != 0 || len(changed) != 0 { // check if the changed dependency graph unblock owners that are // waiting for the deletion of their dependents. //检查更改的依赖关系图是否取消阻止等待删除其依赖项的所有者。 gb.addUnblockedOwnersToDeleteQueue(removed, changed) // update the node itself //更新node的owner existingNode.owners = accessor.GetOwnerReferences() // Add the node to its new owners\u0026#39; dependent lists. //给新owner添加依赖资源列表 gb.addDependentToOwners(existingNode, added) // remove the node from the dependent list of node that are no longer in // the node\u0026#39;s owners list. //从不再属于该资源owner列表中删除该节点。 gb.removeDependentFromOwners(existingNode, removed) } // 该对象正在被删除中 if beingDeleted(accessor) { existingNode.markBeingDeleted() } gb.processTransitions(event.oldObj, accessor, existingNode) //处理资源对象被删除的场景，涉及垃圾。比如，owner被删除，其依赖资源（从资源）也需要被删除掉，除非设置了Orphan case event.eventType == deleteEvent: if !found { klog.V(5).Infof(\u0026#34;%v doesn\u0026#39;t exist in the graph, this shouldn\u0026#39;t happen\u0026#34;, accessor.GetUID()) return true } // 从图标中移除item资源，同时遍历owners，移除owner下的item资源 gb.removeNode(existingNode) existingNode.dependentsLock.RLock() defer existingNode.dependentsLock.RUnlock() //如果该资源的从资源数大于0,则将该资源被删除信息加入absentOwnerCache缓存 if len(existingNode.dependents) \u0026gt; 0 { gb.absentOwnerCache.Add(accessor.GetUID()) } //遍历该资源的从资源加到删除队列里 for dep := range existingNode.dependents { gb.attemptToDelete.Add(dep) } for _, owner := range existingNode.owners { ownerNode, found := gb.uidToNode.Read(owner.UID) //owner没发现 或者 owner的从资源不是正在被删除(只有该资源对象的终结器为foregroundDeletion Finalizer时deletingDependents被设为true,因为后台删除owner直接被删除,不会被其从资源block,故这里都不需要去尝试删除owner了) if !found || !ownerNode.isDeletingDependents() { continue } // 这是让attempToDeleteItem检查是否删除了owner的依赖项，如果是，则删除所有者。 gb.attemptToDelete.Add(ownerNode) } } return true } 该方法功能主要将对象、owner、从资源加入到attemptToDelete或attemptToOrphan。\n1、 出队 # 从graphChanges队列取出资源对象，从GraphBuilder.uidToNode中读取该资源节点（uidToNode维护着资源对象依赖关系图表结构），found为true时表示图表存在该资源节点；\n2、switch的第一个case # 如果该资源是新增或者更新触发，且该资源对象不存在于图表中，gb.uidToNode.Write(n)会将其写入图标；\ngb.insertNode(newNode)中的gb.addDependentToOwners(n, n.owners)方法则会遍历该资源的owner，如果其owner不存在于图标中，则新增owner的虚拟节点到图标中，并将该资源和owner产生关联。如果owner不存在时，则尝试将owner加入到attemptToDelete队列中去；\n// addDependentToOwners将n添加到所有者的从属列表中。如果所有者不存在于gb.uidToNode中，则将创建\u0026#34;虚拟\u0026#34;节点以表示 // 所有者。 \u0026#34;虚拟\u0026#34;节点将入队到attemptToDelete，因此 // attemptToDeleteItem()将根据API服务器验证所有者是否存在。 func (gb *GraphBuilder) addDependentToOwners(n *node, owners []metav1.OwnerReference) { //遍历owner for _, owner := range owners { //获取owner node如果不存在于图中,则加虚拟owner节点 ownerNode, ok := gb.uidToNode.Read(owner.UID) if !ok { // Create a \u0026#34;virtual\u0026#34; node in the graph for the owner if it doesn\u0026#39;t // exist in the graph yet. //如果图形中尚未存在，则在图表中为所有者创建“虚拟”节点。 ownerNode = \u0026amp;node{ identity: objectReference{ OwnerReference: owner, Namespace: n.identity.Namespace, }, dependents: make(map[*node]struct{}), virtual: true, } klog.V(5).Infof(\u0026#34;add virtual node.identity: %s\\n\\n\u0026#34;, ownerNode.identity) gb.uidToNode.Write(ownerNode) } //给owner加该资源作为依赖 ownerNode.addDependent(n) //owner不存在于图中时，才往删除队列添加 if !ok { // Enqueue the virtual node into attemptToDelete. // The garbage processor will enqueue a virtual delete // event to delete it from the graph if API server confirms this // owner doesn\u0026#39;t exist. //将虚拟节点排入attemptToDelete。 // 如果API服务器确认owner不存在，垃圾处理器将排队虚拟删除事件以将其从图中删除。 gb.attemptToDelete.Add(ownerNode) } } } gb.processTransitions方法：\n新item正在被删,旧item没开始被删除,且终结器为Orphan Finalizer加入到attemptToOrphan队列；\n新item正在被删,旧item没开始被删除,且终结器为foregroundDeletion Finalizer，则加入到attemptToDelete队列。\nfunc (gb *GraphBuilder) processTransitions(oldObj interface{}, newAccessor metav1.Object, n *node) { //新的正在被删,旧的没开始被删除,且终结器为Orphan Finalizer if startsWaitingForDependentsOrphaned(oldObj, newAccessor) { klog.V(5).Infof(\u0026#34;add %s to the attemptToOrphan\u0026#34;, n.identity) //加入到Orphan队列 gb.attemptToOrphan.Add(n) return } //新的正在被删,旧的没开始被删除,且终结器为foregroundDeletion Finalizer if startsWaitingForDependentsDeleted(oldObj, newAccessor) { klog.V(2).Infof(\u0026#34;add %s to the attemptToDelete, because it\u0026#39;s waiting for its dependents to be deleted\u0026#34;, n.identity) // if the n is added as a \u0026#34;virtual\u0026#34; node, its deletingDependents field is not properly set, so always set it here. n.markDeletingDependents() for dep := range n.dependents { gb.attemptToDelete.Add(dep) } gb.attemptToDelete.Add(n) } } 3、switch的第二个case # 如果该资源是新增或者更新触发，且该资源对象存在于图表中。对比owneReferences是否有变更，referencesDiffs方法里会根据uid对比，added表示新owner里有,旧owner里没有的, removed表示旧owner里有,新owner里没有的, changed表示相同uid的owner不deepEqual的。\nfunc referencesDiffs(old []metav1.OwnerReference, new []metav1.OwnerReference) (added []metav1.OwnerReference, removed []metav1.OwnerReference, changed []ownerRefPair) { //key为uid, value为OwnerReference oldUIDToRef := make(map[string]metav1.OwnerReference) for _, value := range old { oldUIDToRef[string(value.UID)] = value } oldUIDSet := sets.StringKeySet(oldUIDToRef) //key为uid, value为OwnerReference newUIDToRef := make(map[string]metav1.OwnerReference) for _, value := range new { newUIDToRef[string(value.UID)] = value } newUIDSet := sets.StringKeySet(newUIDToRef) //新的里有,旧的里没有的为新增(根据uid判断) addedUID := newUIDSet.Difference(oldUIDSet) //旧的里有,新的里没有的为删除(根据uid判断) removedUID := oldUIDSet.Difference(newUIDSet) //取交集, 旧的和新的里都有的owner(根据uid判断) intersection := oldUIDSet.Intersection(newUIDSet) for uid := range addedUID { added = append(added, newUIDToRef[uid]) } for uid := range removedUID { removed = append(removed, oldUIDToRef[uid]) } //根据uid判断,两个uid相等的OwnerReference是否deepEqual,不等则加到changed for uid := range intersection { if !reflect.DeepEqual(oldUIDToRef[uid], newUIDToRef[uid]) { changed = append(changed, ownerRefPair{oldRef: oldUIDToRef[uid], newRef: newUIDToRef[uid]}) } } return added, removed, changed } 整体来说，owner发生变化，addUnblockedOwnersToDeleteQueue方法会判断：如果阻塞ownerReference指向某个对象被删除，或者设置为BlockOwnerDeletion=false，则将该对象添加到attemptToDelete队列；\n// if an blocking ownerReference points to an object gets removed, or gets set to // \u0026#34;BlockOwnerDeletion=false\u0026#34;, add the object to the attemptToDelete queue. //如果阻塞ownerReference指向某个对象被删除，或者设置为 // \u0026#34;BlockOwnerDeletion = false\u0026#34;，则将该对象添加到attemptToDelete队列。 func (gb *GraphBuilder) addUnblockedOwnersToDeleteQueue(removed []metav1.OwnerReference, changed []ownerRefPair) { for _, ref := range removed { //被移除的OwnersReferences,BlockOwnerDeletion为true if ref.BlockOwnerDeletion != nil \u0026amp;\u0026amp; *ref.BlockOwnerDeletion { //依赖图表中发现,则加入删除队列 node, found := gb.uidToNode.Read(ref.UID) if !found { klog.V(5).Infof(\u0026#34;cannot find %s in uidToNode\u0026#34;, ref.UID) continue } //加入尝试删除队列删除这个owner gb.attemptToDelete.Add(node) } } // Owners存在且发生变化,旧的BlockOwnerDeletion为true, 新的BlockOwnerDeletion为空或者BlockOwnerDeletion为false则删除owner(父节点) for _, c := range changed { wasBlocked := c.oldRef.BlockOwnerDeletion != nil \u0026amp;\u0026amp; *c.oldRef.BlockOwnerDeletion isUnblocked := c.newRef.BlockOwnerDeletion == nil || (c.newRef.BlockOwnerDeletion != nil \u0026amp;\u0026amp; !*c.newRef.BlockOwnerDeletion) if wasBlocked \u0026amp;\u0026amp; isUnblocked { node, found := gb.uidToNode.Read(c.newRef.UID) if !found { klog.V(5).Infof(\u0026#34;cannot find %s in uidToNode\u0026#34;, c.newRef.UID) continue } gb.attemptToDelete.Add(node) } } } 更新node的owner；\n在依赖图表中给新owner添加该node；\n在依赖图表中,被删除的owner列表下删除该节点。\ngb.processTransitions方法：\n新item正在被删,旧item没开始被删除,且终结器为Orphan Finalizer加入到attemptToOrphan队列；\n新item正在被删,旧item没开始被删除,且终结器为foregroundDeletion Finalizer，则加入到attemptToDelete队列。\n4、switch的第三个case # 如果该资源是删除时触发，从图表中移除item资源，同时遍历owners，移除owner下的item资源；\n如果该资源的从资源数大于0,则将该资源被删除信息（uid）加入absentOwnerCache缓存，这样处理该资源的从资源时，就知道owner不存在了。\n遍历该资源的从资源加到删除队列里；\n如果从图表中发现 owner或者 owner的从资源正在被删除，则尝试将owner加入到attemptToDelete队列中，去尝试删除owner。\n整理流程 # 当controllermanager重启时，会全量listwatch一遍所有对象，gc collector维护的uidToNode图表里各个资源对象node是不存在的，此时会走第一个switch case，构建完整关系图表，如果owner不存在则先构建虚拟owner节点，同时加入attemptToDelete队列，尝试去删除这个owner，其实即使加入到attemptToDelete队列，也不一定会被删除，还会进行一系列判断，这个下一节再分析；将正在删除的资源，同时Finalizer为Orphan的加入到attemptToOrphan队列；为foreground的资源以及其从资源加入到attemptToDelete队列，并将deletingDependents设置为true； 添加或者更新事件时，且图表中存在item资源对象时，会走第二个switch case，对item的owner变化进行判断，并维护更新图表；同理将正在删除的资源，同时Finalizer为Orphan的加入到attemptToOrphan队列；Finalizer为foreground的资源以及其从资源加入到attemptToDelete队列，并将deletingDependents设置为true； 如果是删除事件，则会更新图表，并处理和其相关的从资源和其owner加入到attemptToDelete队列。 终结器 # 在阅读以下代码时，有必要先了解一下终结器。\n对象的终结器是在对象删除之前需要执行的逻辑，所有的对象在删除之前，它的终结器字段必须为空，终结器提供了一个通用的 API，它的功能不只是用于阻止级联删除，还能过通过它在对象删除之前加入钩子：\ntype ObjectMeta struct { // ... Finalizers []string } 终结器在对象被删之前运行，每当终结器成功运行之后，就会将它自己从 Finalizers 数组中删除，当最后一个终结器被删除之后，API Server 就会删除该对象。\n在默认情况下，删除一个对象会删除它的全部依赖，但是我们在一些特定情况下我们只是想删除当前对象本身并不想造成复杂的级联删除，垃圾回收机制在这时引入了 OrphanFinalizer，它会在对象被删除之前向 Finalizers 数组添加或者删除 OrphanFinalizer。\n该终结器会监听对象的更新事件并将它自己从它全部依赖对象的 OwnerReferences 数组中删除，与此同时会删除所有依赖对象中已经失效的 OwnerReferences 并将 OrphanFinalizer 从 Finalizers 数组中删除。\n通过 OrphanFinalizer 我们能够在删除一个 Kubernetes 对象时保留它的全部依赖，为使用者提供一种更灵活的办法来保留和删除对象。\n同时，也希望可以看一下\u0026quot;垃圾回收\u0026quot;官网文档：\n垃圾收集\nattemptToDelete队列 # 来到代码$GOPATH\\src\\k8s.io\\kubernetes\\pkg\\controller\\garbagecollector\\garbagecollector.go中：\nfunc (gc *GarbageCollector) runAttemptToDeleteWorker() { for gc.attemptToDeleteWorker() { } } 从attemptToDelete队列中取出资源，调用gc.attemptToDeleteItem(n)处理，期间如果出现error，则通过rateLimited重新加回attemptToDelete队列。\nfunc (gc *GarbageCollector) attemptToDeleteWorker() bool { //从队列里取出需要尝试删除的资源 item, quit := gc.attemptToDelete.Get() gc.workerLock.RLock() defer gc.workerLock.RUnlock() if quit { return false } defer gc.attemptToDelete.Done(item) n, ok := item.(*node) if !ok { utilruntime.HandleError(fmt.Errorf(\u0026#34;expect *node, got %#v\u0026#34;, item)) return true } err := gc.attemptToDeleteItem(n) if err != nil { if _, ok := err.(*restMappingError); ok { // There are at least two ways this can happen: // 1. The reference is to an object of a custom type that has not yet been // recognized by gc.restMapper (this is a transient error). // 2. The reference is to an invalid group/version. We don\u0026#39;t currently // have a way to distinguish this from a valid type we will recognize // after the next discovery sync. // For now, record the error and retry. klog.V(5).Infof(\u0026#34;error syncing item %s: %v\u0026#34;, n, err) } else { utilruntime.HandleError(fmt.Errorf(\u0026#34;error syncing item %s: %v\u0026#34;, n, err)) } // retry if garbage collection of an object failed. // 如果对象的垃圾收集失败，则重试。 gc.attemptToDelete.AddRateLimited(item) } else if !n.isObserved() { // requeue if item hasn\u0026#39;t been observed via an informer event yet. // otherwise a virtual node for an item added AND removed during watch reestablishment can get stuck in the graph and never removed. // see https://issue.k8s.io/56121 klog.V(5).Infof(\u0026#34;item %s hasn\u0026#39;t been observed via informer yet\u0026#34;, n.identity) gc.attemptToDelete.AddRateLimited(item) } return true } 关键方法attemptToDeleteItem：\nfunc (gc *GarbageCollector) attemptToDeleteItem(item *node) error { klog.V(2).Infof(\u0026#34;processing item %s\u0026#34;, item.identity) // \u0026#34;being deleted\u0026#34; is an one-way trip to the final deletion. We\u0026#39;ll just wait for the final deletion, and then process the object\u0026#39;s dependents. // item资源被标记为正在删除,即deletionTimestamp不为nil;且不是正在删除从资源(这个从上一节可以看出,只有item被foreground方式删除时,deletingDependents才会被设置为true) // item在删除中,且为Orphan和Background方式删除则直接返回 if item.isBeingDeleted() \u0026amp;\u0026amp; !item.isDeletingDependents() { klog.V(5).Infof(\u0026#34;processing item %s returned at once, because its DeletionTimestamp is non-nil\u0026#34;, item.identity) return nil } // TODO: It\u0026#39;s only necessary to talk to the API server if this is a // \u0026#34;virtual\u0026#34; node. The local graph could lag behind the real status, but in // practice, the difference is small. //根据item里的信息获取object对象体 latest, err := gc.getObject(item.identity) switch { case errors.IsNotFound(err): // the GraphBuilder can add \u0026#34;virtual\u0026#34; node for an owner that doesn\u0026#39;t // exist yet, so we need to enqueue a virtual Delete event to remove // the virtual node from GraphBuilder.uidToNode. klog.V(5).Infof(\u0026#34;item %v not found, generating a virtual delete event\u0026#34;, item.identity) gc.dependencyGraphBuilder.enqueueVirtualDeleteEvent(item.identity) // since we\u0026#39;re manually inserting a delete event to remove this node, // we don\u0026#39;t need to keep tracking it as a virtual node and requeueing in attemptToDelete item.markObserved() return nil case err != nil: return err } //uid不匹配 if latest.GetUID() != item.identity.UID { klog.V(5).Infof(\u0026#34;UID doesn\u0026#39;t match, item %v not found, generating a virtual delete event\u0026#34;, item.identity) gc.dependencyGraphBuilder.enqueueVirtualDeleteEvent(item.identity) // since we\u0026#39;re manually inserting a delete event to remove this node, // we don\u0026#39;t need to keep tracking it as a virtual node and requeueing in attemptToDelete //因为我们手动插入删除事件以删除此节点，我们不需要将其作为虚拟节点跟踪并在attemptToDelete中重新排队 item.markObserved() return nil } // TODO: attemptToOrphanWorker() routine is similar. Consider merging // attemptToOrphanWorker() into attemptToDeleteItem() as well. // item的从资源正在删除中,同时删除其从资源 if item.isDeletingDependents() { return gc.processDeletingDependentsItem(item) } // compute if we should delete the item // 获取该object里metadata.ownerReference // 计算我们是否应删除该项目 ownerReferences := latest.GetOwnerReferences() if len(ownerReferences) == 0 { //没有owner的不用处理 klog.V(2).Infof(\u0026#34;object %s\u0026#39;s doesn\u0026#39;t have an owner, continue on next item\u0026#34;, item.identity) return nil } //solid(owner存在,owner没被删或者终结器不为foregroundDeletion Finalizer); dangling(owner不存在) // waitingForDependentsDeletion(owner存在,owner的deletionTimestamp为非nil，并且有foregroundDeletion Finalizer)owner列表 solid, dangling, waitingForDependentsDeletion, err := gc.classifyReferences(item, ownerReferences) if err != nil { return err } klog.V(5).Infof(\u0026#34;classify references of %s.\\nsolid: %#v\\ndangling: %#v\\nwaitingForDependentsDeletion: %#v\\n\u0026#34;, item.identity, solid, dangling, waitingForDependentsDeletion) switch { //item对象的owner存在,且不是正在删除 case len(solid) != 0: klog.V(2).Infof(\u0026#34;object %#v has at least one existing owner: %#v, will not garbage collect\u0026#34;, solid, item.identity) if len(dangling) == 0 \u0026amp;\u0026amp; len(waitingForDependentsDeletion) == 0 { return nil } klog.V(2).Infof(\u0026#34;remove dangling references %#v and waiting references %#v for object %s\u0026#34;, dangling, waitingForDependentsDeletion, item.identity) // waitingForDependentsDeletion needs to be deleted from the // ownerReferences, otherwise the referenced objects will be stuck with // the FinalizerDeletingDependents and never get deleted. // waitingForDependentsDeletion需要从 ownerReferences中删除，否则引用的对象将被 // FinalizerDeletingDependents所卡住，并且永远不会被删除。 //需要移除的ownerUids ownerUIDs := append(ownerRefsToUIDs(dangling), ownerRefsToUIDs(waitingForDependentsDeletion)...) //拼接patch请求参数 patch := deleteOwnerRefStrategicMergePatch(item.identity.UID, ownerUIDs...) //发送patch请求 _, err = gc.patch(item, patch, func(n *node) ([]byte, error) { return gc.deleteOwnerRefJSONMergePatch(n, ownerUIDs...) }) return err //item对象的owner正在被删除; 且item有从资源 case len(waitingForDependentsDeletion) != 0 \u0026amp;\u0026amp; item.dependentsLength() != 0: deps := item.getDependents() // 遍历item从资源 for _, dep := range deps { if dep.isDeletingDependents() { // this circle detection has false positives, we need to // apply a more rigorous detection if this turns out to be a // problem. // there are multiple workers run attemptToDeleteItem in // parallel, the circle detection can fail in a race condition. klog.V(2).Infof(\u0026#34;processing object %s, some of its owners and its dependent [%s] have FinalizerDeletingDependents, to prevent potential cycle, its ownerReferences are going to be modified to be non-blocking, then the object is going to be deleted with Foreground\u0026#34;, item.identity, dep.identity) // 生成一个补丁，该补丁会取消设置item所有ownerReferences的BlockOwnerDeletion字段,避免阻塞item的owner删除 patch, err := item.unblockOwnerReferencesStrategicMergePatch() if err != nil { return err } //执行patch if _, err := gc.patch(item, patch, gc.unblockOwnerReferencesJSONMergePatch); err != nil { return err } break } } //item对象的至少一个owner具有foregroundDeletion Finalizer，并且该对象本身具有依赖项，因此它将在Foreground中删除 klog.V(2).Infof(\u0026#34;at least one owner of object %s has FinalizerDeletingDependents, and the object itself has dependents, so it is going to be deleted in Foreground\u0026#34;, item.identity) // the deletion event will be observed by the graphBuilder, so the item // will be processed again in processDeletingDependentsItem. If it // doesn\u0026#39;t have dependents, the function will remove the // FinalizerDeletingDependents from the item, resulting in the final // deletion of the item. // graphBuilder将观察删除事件，因此将在processDeletingDependentsItem中再次处理该项目。 // 如果没有依赖项，该函数将从项中删除foregroundDeletion Finalizer，最终删除item。 policy := metav1.DeletePropagationForeground return gc.deleteObject(item.identity, \u0026amp;policy) default: // item doesn\u0026#39;t have any solid owner, so it needs to be garbage // collected. Also, none of item\u0026#39;s owners is waiting for the deletion of // the dependents, so set propagationPolicy based on existing finalizers. // item没有任何实体所有者，因此需要收集垃圾 。此外，项目的所有者都没有等待删除 // 依赖项，因此请根据现有的终结器设置propagationPolicy。 var policy metav1.DeletionPropagation switch { case hasOrphanFinalizer(latest): // if an existing orphan finalizer is already on the object, honor it. //如果现有的孤儿终结器已经在对象上，请尊重它。 policy = metav1.DeletePropagationOrphan case hasDeleteDependentsFinalizer(latest): // if an existing foreground finalizer is already on the object, honor it. //如果现有的前景终结器已经在对象上，请尊重它。 policy = metav1.DeletePropagationForeground default: // otherwise, default to background. //否则，默认为背景。 policy = metav1.DeletePropagationBackground } klog.V(2).Infof(\u0026#34;delete object %s with propagation policy %s\u0026#34;, item.identity, policy) //删除孤儿对象 return gc.deleteObject(item.identity, \u0026amp;policy) } } 主要做以下事情：\n1、item在删除中，且为Orphan和Background方式删除则直接返回；\n2、item是foreground方式删除时，调用processDeletingDependentsItem去处理阻塞其删除的从资源，将其放到attemptToDelete队列；\n3、获取item的owner对象集，调用classifyReferences将owner集合分为3类，分别为solid（owner存在或者终结器不为foregroundDeletion的owner集合）, dangling（已经不存在了的owner集群）, waitingForDependentsDeletion（owner的deletionTimestamp为非nil，并且为foregroundDeletion终结器的owner集合）\n4、switch第一个case：solid集合不为空，即item存在没被删除的owner。当dangling和waitingForDependentsDeletion都为空，则直接返回；当dangling或waitingForDependentsDeletion不为空，合并两个集合uid，执行patch请求，将这些uid对应的ownerReferences从item中删除\n5、switch第二个case：waitingForDependentsDeletion集合不为空，且item有从资源。即item的owner不存在，或正在被foregroundDeletion方式删除，如果item的从资源正在删除依赖项，则取消阻止item的owner删除，给item执行patch请求，最终采用foregroundDeletion方式删除item；\n6、switch第三个case：以上条件不符合时，则直接根据item中的终结器删除item，默认为Background方式删除。\n往细了说，processDeletingDependentsItem方法获取item从资源中BlockOwnerDeletion为true的ownerReferences集合，如果为空，则移除item的foregroundDeletion终结器。否则遍历，将未开始删除的依赖项的从资源dep加入到尝试删除队列attemptToDelete。\n//等待其依赖项被删除的进程项 func (gc *GarbageCollector) processDeletingDependentsItem(item *node) error { //阻塞item资源删除的从资源列表 blockingDependents := item.blockingDependents() //没有阻塞item资源删除的从资源,则移除item资源的foregroundDeletion终结器 if len(blockingDependents) == 0 { klog.V(2).Infof(\u0026#34;remove DeleteDependents finalizer for item %s\u0026#34;, item.identity) return gc.removeFinalizer(item, metav1.FinalizerDeleteDependents) } //遍历阻塞item资源删除的从资源 for _, dep := range blockingDependents { // 如果dep的从资源没有开始删除,则将dep加入到尝试删除队列中 if !dep.isDeletingDependents() { klog.V(2).Infof(\u0026#34;adding %s to attemptToDelete, because its owner %s is deletingDependents\u0026#34;, dep.identity, item.identity) //将从资源加入删除队列 gc.attemptToDelete.Add(dep) } } return nil } gc.classifyReferences(item, ownerReferences)方法：遍历了item的owner列表，调用isDangling方法将已不存在的owner加入到isDangling列表；owner正在被删除,且owner有foregroundDeletion终结器的加入到waitingForDependentsDeletion列表；owner没开始删或者终结器不为foregroundDeletion的加入到solid列表。\n// 将latestReferences分为三类： // solid：所有者存在，且不是waitingForDependentsDeletion // dangling悬空：所有者不存在 // waitingForDependentsDeletion: 所有者存在，其deletionTimestamp为非nil，并且有FinalizerDeletingDependents func (gc *GarbageCollector) classifyReferences(item *node, latestReferences []metav1.OwnerReference) ( solid, dangling, waitingForDependentsDeletion []metav1.OwnerReference, err error) { //遍历该node的owner for _, reference := range latestReferences { //获取owner是否存在;isDangling为true表示不存在,发生err则最终将该item加入AddRateLimited attemptToDelete队列 isDangling, owner, err := gc.isDangling(reference, item) if err != nil { return nil, nil, nil, err } //将不存在的owner加入dangling切片 if isDangling { dangling = append(dangling, reference) continue } //owner存在,获取accessor ownerAccessor, err := meta.Accessor(owner) if err != nil { return nil, nil, nil, err } //owner正在被删除,且owner有foregroundDeletion Finalizer if ownerAccessor.GetDeletionTimestamp() != nil \u0026amp;\u0026amp; hasDeleteDependentsFinalizer(ownerAccessor) { //owner将等待依赖删除;收集等待删除依赖的owner列表 waitingForDependentsDeletion = append(waitingForDependentsDeletion, reference) } else { //owner没被删或者终结器不为foregroundDeletion Finalizer solid = append(solid, reference) } } return solid, dangling, waitingForDependentsDeletion, nil } gc.isDangling(reference, item)方法：先从absentOwnerCache缓存中根据owner uid获取owner是否存在；如果缓存中没有，则根据ownerReferences中的参数，构建参数，调用apiserver接口获取owner对象是否能查到。查到如果uid不匹配，加入absentOwnerCache缓存，并返回false。\n// isDangling检查引用是否指向不存在的对象。 如果isDangling在API服务器上查找引用的对象，它也返回其最新状态。 func (gc *GarbageCollector) isDangling(reference metav1.OwnerReference, item *node) ( dangling bool, owner *unstructured.Unstructured, err error) { if gc.absentOwnerCache.Has(reference.UID) { klog.V(5).Infof(\u0026#34;according to the absentOwnerCache, object %s\u0026#39;s owner %s/%s, %s does not exist\u0026#34;, item.identity.UID, reference.APIVersion, reference.Kind, reference.Name) return true, nil, nil } // TODO: we need to verify the reference resource is supported by the // system. If it\u0026#39;s not a valid resource, the garbage collector should i) // ignore the reference when decide if the object should be deleted, and // ii) should update the object to remove such references. This is to // prevent objects having references to an old resource from being // deleted during a cluster upgrade. resource, namespaced, err := gc.apiResource(reference.APIVersion, reference.Kind) if err != nil { return false, nil, err } // TODO: It\u0026#39;s only necessary to talk to the API server if the owner node // is a \u0026#34;virtual\u0026#34; node. The local graph could lag behind the real // status, but in practice, the difference is small. owner, err = gc.dynamicClient.Resource(resource).Namespace(resourceDefaultNamespace(namespaced, item.identity.Namespace)).Get(reference.Name, metav1.GetOptions{}) switch { case errors.IsNotFound(err): gc.absentOwnerCache.Add(reference.UID) klog.V(5).Infof(\u0026#34;object %s\u0026#39;s owner %s/%s, %s is not found\u0026#34;, item.identity.UID, reference.APIVersion, reference.Kind, reference.Name) return true, nil, nil case err != nil: return false, nil, err } if owner.GetUID() != reference.UID { klog.V(5).Infof(\u0026#34;object %s\u0026#39;s owner %s/%s, %s is not found, UID mismatch\u0026#34;, item.identity.UID, reference.APIVersion, reference.Kind, reference.Name) gc.absentOwnerCache.Add(reference.UID) return true, nil, nil } return false, owner, nil } attemptToOrphan队列 # 来到代码：\nfunc (gc *GarbageCollector) runAttemptToOrphanWorker() { for gc.attemptToOrphanWorker() { } } 死循环一直从attemptToOrphan队列中获取item资源，调用gc.orphanDependents(owner.identity, dependents)方法，从item从资源中删掉该item的ownerReferences，期间如果发生错误，则通过rateLimited重新加回attemptToOrphan队列。最后移除item中的orphan终结器。\n// attemptToOrphanWorker将一个节点从attemptToOrphan中取出，然后根据GC维护的图找到它的依赖项，然后将其从其依赖项的 // OwnerReferences中删除，最后更新item以删除孤儿终结器。如果这些步骤中的任何一个失败，则将节点添加回attemptToOrphan。 func (gc *GarbageCollector) attemptToOrphanWorker() bool { item, quit := gc.attemptToOrphan.Get() gc.workerLock.RLock() defer gc.workerLock.RUnlock() if quit { return false } defer gc.attemptToOrphan.Done(item) owner, ok := item.(*node) if !ok { utilruntime.HandleError(fmt.Errorf(\u0026#34;expect *node, got %#v\u0026#34;, item)) return true } // we don\u0026#39;t need to lock each element, because they never get updated owner.dependentsLock.RLock() dependents := make([]*node, 0, len(owner.dependents)) for dependent := range owner.dependents { dependents = append(dependents, dependent) } owner.dependentsLock.RUnlock() // 处理孤儿 err := gc.orphanDependents(owner.identity, dependents) if err != nil { utilruntime.HandleError(fmt.Errorf(\u0026#34;orphanDependents for %s failed with %v\u0026#34;, owner.identity, err)) gc.attemptToOrphan.AddRateLimited(item) return true } // update the owner, remove \u0026#34;orphaningFinalizer\u0026#34; from its finalizers list // 移除item的orphan终结器 err = gc.removeFinalizer(owner, metav1.FinalizerOrphanDependents) if err != nil { utilruntime.HandleError(fmt.Errorf(\u0026#34;removeOrphanFinalizer for %s failed with %v\u0026#34;, owner.identity, err)) gc.attemptToOrphan.AddRateLimited(item) } return true } gc.orphanDependents(owner.identity, dependents)方法：遍历item的从资源，并发的执行patch请求，删除从资源中和item同uid的ownerReferences，将error加入到errCh channel中，最后给调用者返回error列表：\n// dependents are copies of pointers to the owner\u0026#39;s dependents, they don\u0026#39;t need to be locked. func (gc *GarbageCollector) orphanDependents(owner objectReference, dependents []*node) error { errCh := make(chan error, len(dependents)) wg := sync.WaitGroup{} wg.Add(len(dependents)) for i := range dependents { go func(dependent *node) { defer wg.Done() // the dependent.identity.UID is used as precondition patch := deleteOwnerRefStrategicMergePatch(dependent.identity.UID, owner.UID) _, err := gc.patch(dependent, patch, func(n *node) ([]byte, error) { return gc.deleteOwnerRefJSONMergePatch(n, owner.UID) }) // note that if the target ownerReference doesn\u0026#39;t exist in the // dependent, strategic merge patch will NOT return an error. if err != nil \u0026amp;\u0026amp; !errors.IsNotFound(err) { errCh \u0026lt;- fmt.Errorf(\u0026#34;orphaning %s failed, %v\u0026#34;, dependent.identity, err) } }(dependents[i]) } wg.Wait() close(errCh) var errorsSlice []error for e := range errCh { errorsSlice = append(errorsSlice, e) } if len(errorsSlice) != 0 { return fmt.Errorf(\u0026#34;failed to orphan dependents of owner %s, got errors: %s\u0026#34;, owner, utilerrors.NewAggregate(errorsSlice).Error()) } klog.V(5).Infof(\u0026#34;successfully updated all dependents of owner %s\u0026#34;, owner) return nil } deleteOwnerRefStrategicMergePatch方法：拼接patch请求参数。该方法同样的，在处理attemptToDelete死循中，第一个switch case处被调用。\nfunc deleteOwnerRefStrategicMergePatch(dependentUID types.UID, ownerUIDs ...types.UID) []byte { var pieces []string //拼接需要删除的uid for _, ownerUID := range ownerUIDs { pieces = append(pieces, fmt.Sprintf(`{\u0026#34;$patch\u0026#34;:\u0026#34;delete\u0026#34;,\u0026#34;uid\u0026#34;:\u0026#34;%s\u0026#34;}`, ownerUID)) } //拼接patch请求参数 patch := fmt.Sprintf(`{\u0026#34;metadata\u0026#34;:{\u0026#34;ownerReferences\u0026#34;:[%s],\u0026#34;uid\u0026#34;:\u0026#34;%s\u0026#34;}}`, strings.Join(pieces, \u0026#34;,\u0026#34;), dependentUID) return []byte(patch) } 回到初衷 # 中间件redis容器化后，在测试环境上部署的redis集群，在kubernetes apiserver重启后，redis集群被异常删除（包括redis exporter statefulset、redis statefulset）。\n原因定位 # 在开发环境上经多次复现，apiserver重启后，通过查询redis operator日志，并没有发现主动去删除redis集群（redis statefulset）、监控实例（redis exporter）。进一步去查看kube-controller-manager的日志，将其日志级别设置\u0026ndash;v=5，继续复现，最终在kube-controller-manager日志中发现如下日志：\n可以看到，垃圾回收器garbage collector在处理redis exporter statefulset时，发现其加了ownerReferences，在exporter所在分区（monitoring）查询其owner——redisCluster对象redis-0826，而redisCluster对象redis-0826存在于kube-system分区，所以在monitoring分区查询到的是404 Not Found，garbage collector会将该owner不存在信息（uid）存入缓存absentOwnerCache。\n因redis exporter statefulset的owner不存在，所以gc认为需要回收垃圾，故将其删除掉。同理，当处理redis statefulset时，从缓存中发现owner不存在，也会回收垃圾，将其删除掉。\n经过多次复现故障，发现重启kube-controller-manager时有概率复现。（Apiserver的重启时，kube-controller-manager在连接apiserver失败多次后，也会发生自重启），之所以是概率问题，这和garbage collector将资源对象加入attemptToDelete队列的顺序有关：\n先同步monitoring分区的exporter statefulset，后同步kube-system分区的redis statefulset，就会出现该故障；反之就不会出现故障，这取决于garbage collector启动时全量获取集群内资源（listwatch）的顺序。\n在apiserver和kube-controller-manager正常运行时不出现该故障，可以从garbage collector源码中看到以下代码逻辑：\nGarbage collector中维护一个父子关系图表，controller-manager启动时该图里节点是不存在的，会走上图switch的第一个case，之后图形成之后，会走第二个case。第二个case里只有在owner发生变化时才会触发将资源对象加入attemptToDelete队列，所以在各个组件正常运行时没有出现该故障。\n获取图表的接口地址，IP和端口都是controller-manager的，可以重定向到tmp.dot文件\ncurl http://127.0.0.1:10252/debug/controllers/garbagecollector/graph curl http://127.0.0.1:10252/debug/controllers/garbagecollector/graph?uid=11211212edsaddkqedmk12 之后用可视化工具Graphviz软件，进入到bin目录下，执行以下命令生成svg文件，用浏览器打开，Graphviz和dot的使用可以自行谷歌。\ndot -Tsvg -o graph2.svg tmp.dot 解决方法 # 在redis operator创建redis集群时，将exporter放到和redis同一分区。\n思考反思 # 1、出现该故障，主要是因进行了跨命名空间owner引用。在使用垃圾回收机制时，应该尽量参考kubernetes官方网站中的说明.\n如下，官网中说明了owner引用在设计时就不允许跨namespace使用，这意味着：\n1）命名空间范围的从属只能指定同一命名空间中的所有者，以及群集范围的所有者。\n2）群集作用域的从属只能指定群集作用域的所有者，而不能指定命名空间作用域的所有者。\n参考文档 # 详解 Kubernetes 垃圾收集器的实现原理：\nhttps://draveness.me/kubernetes-garbage-collector#\nk8s官方文档garbage-collection英文版：\nhttps://kubernetes.io/docs/concepts/workloads/controllers/garbage-collection/\n依赖图标生成库gonum Api文档：\nhttps://godoc.org/gonum.org/v1/gonum/graph\ngraphviz下载：\nhttps://graphviz.gitlab.io/_pages/Download/Download_windows.html\n","date":"2019年10月22日","externalUrl":null,"permalink":"/posts/kubernetes%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8garbagecollector%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","section":"Posts","summary":"\u003ch1 class=\"relative group\"\u003ekubernetes垃圾回收器GarbageCollector 源码分析 \n    \u003cdiv id=\"kubernetes垃圾回收器garbagecollector-源码分析\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#kubernetes%e5%9e%83%e5%9c%be%e5%9b%9e%e6%94%b6%e5%99%a8garbagecollector-%e6%ba%90%e7%a0%81%e5%88%86%e6%9e%90\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003ekubernetes版本：1.13.2\u003c/strong\u003e\u003c/p\u003e","title":"kubernetes垃圾回收器GarbageCollector源码分析","type":"posts"},{"content":" kubernetes版本：1.13.2\n接前两节：\nkubernetes垃圾回收器GarbageCollector Controller源码分析（一）\nkubernetes垃圾回收器GarbageCollector Controller源码分析（二）\n主要步骤 # GarbageCollector Controller源码主要分为以下几部分：\nmonitors作为生产者将变化的资源放入graphChanges队列；同时restMapper定期检测集群内资源类型，刷新monitors runProcessGraphChanges从graphChanges队列中取出变化的item，根据情况放入attemptToDelete队列； runProcessGraphChanges从graphChanges队列中取出变化的item，根据情况放入attemptToOrphan队列； runAttemptToDeleteWorker从attemptToDelete队列取出，尝试删除垃圾资源； runAttemptToOrphanWorker从attemptToOrphan队列取出，处理该孤立的资源；\n上一节分析了第2,3部分，本节分析第4、5部分。 终结器 # 在阅读以下代码时，有必要先了解一下终结器。\n对象的终结器是在对象删除之前需要执行的逻辑，所有的对象在删除之前，它的终结器字段必须为空，终结器提供了一个通用的 API，它的功能不只是用于阻止级联删除，还能过通过它在对象删除之前加入钩子：\ntype ObjectMeta struct { // ... Finalizers []string } 终结器在对象被删之前运行，每当终结器成功运行之后，就会将它自己从 Finalizers 数组中删除，当最后一个终结器被删除之后，API Server 就会删除该对象。\n在默认情况下，删除一个对象会删除它的全部依赖，但是我们在一些特定情况下我们只是想删除当前对象本身并不想造成复杂的级联删除，垃圾回收机制在这时引入了 OrphanFinalizer，它会在对象被删除之前向 Finalizers 数组添加或者删除 OrphanFinalizer。\n该终结器会监听对象的更新事件并将它自己从它全部依赖对象的 OwnerReferences 数组中删除，与此同时会删除所有依赖对象中已经失效的 OwnerReferences 并将 OrphanFinalizer 从 Finalizers 数组中删除。\n通过 OrphanFinalizer 我们能够在删除一个 Kubernetes 对象时保留它的全部依赖，为使用者提供一种更灵活的办法来保留和删除对象。\n同时，也希望可以看一下\u0026quot;垃圾回收\u0026quot;官网文档：\n垃圾收集\nattemptToDelete队列 # 来到代码$GOPATH\\src\\k8s.io\\kubernetes\\pkg\\controller\\garbagecollector\\garbagecollector.go中：\nfunc (gc *GarbageCollector) runAttemptToDeleteWorker() { for gc.attemptToDeleteWorker() { } } 从attemptToDelete队列中取出资源，调用gc.attemptToDeleteItem(n)处理，期间如果出现error，则通过rateLimited重新加回attemptToDelete队列。\nfunc (gc *GarbageCollector) attemptToDeleteWorker() bool { //从队列里取出需要尝试删除的资源 item, quit := gc.attemptToDelete.Get() gc.workerLock.RLock() defer gc.workerLock.RUnlock() if quit { return false } defer gc.attemptToDelete.Done(item) n, ok := item.(*node) if !ok { utilruntime.HandleError(fmt.Errorf(\u0026#34;expect *node, got %#v\u0026#34;, item)) return true } err := gc.attemptToDeleteItem(n) if err != nil { if _, ok := err.(*restMappingError); ok { // There are at least two ways this can happen: // 1. The reference is to an object of a custom type that has not yet been // recognized by gc.restMapper (this is a transient error). // 2. The reference is to an invalid group/version. We don\u0026#39;t currently // have a way to distinguish this from a valid type we will recognize // after the next discovery sync. // For now, record the error and retry. klog.V(5).Infof(\u0026#34;error syncing item %s: %v\u0026#34;, n, err) } else { utilruntime.HandleError(fmt.Errorf(\u0026#34;error syncing item %s: %v\u0026#34;, n, err)) } // retry if garbage collection of an object failed. // 如果对象的垃圾收集失败，则重试。 gc.attemptToDelete.AddRateLimited(item) } else if !n.isObserved() { // requeue if item hasn\u0026#39;t been observed via an informer event yet. // otherwise a virtual node for an item added AND removed during watch reestablishment can get stuck in the graph and never removed. // see https://issue.k8s.io/56121 klog.V(5).Infof(\u0026#34;item %s hasn\u0026#39;t been observed via informer yet\u0026#34;, n.identity) gc.attemptToDelete.AddRateLimited(item) } return true } 关键方法attemptToDeleteItem：\nfunc (gc *GarbageCollector) attemptToDeleteItem(item *node) error { klog.V(2).Infof(\u0026#34;processing item %s\u0026#34;, item.identity) // \u0026#34;being deleted\u0026#34; is an one-way trip to the final deletion. We\u0026#39;ll just wait for the final deletion, and then process the object\u0026#39;s dependents. // item资源被标记为正在删除,即deletionTimestamp不为nil;且不是正在删除从资源(这个从上一节可以看出,只有item被foreground方式删除时,deletingDependents才会被设置为true) // item在删除中,且为Orphan和Background方式删除则直接返回 if item.isBeingDeleted() \u0026amp;\u0026amp; !item.isDeletingDependents() { klog.V(5).Infof(\u0026#34;processing item %s returned at once, because its DeletionTimestamp is non-nil\u0026#34;, item.identity) return nil } // TODO: It\u0026#39;s only necessary to talk to the API server if this is a // \u0026#34;virtual\u0026#34; node. The local graph could lag behind the real status, but in // practice, the difference is small. //根据item里的信息获取object对象体 latest, err := gc.getObject(item.identity) switch { case errors.IsNotFound(err): // the GraphBuilder can add \u0026#34;virtual\u0026#34; node for an owner that doesn\u0026#39;t // exist yet, so we need to enqueue a virtual Delete event to remove // the virtual node from GraphBuilder.uidToNode. klog.V(5).Infof(\u0026#34;item %v not found, generating a virtual delete event\u0026#34;, item.identity) gc.dependencyGraphBuilder.enqueueVirtualDeleteEvent(item.identity) // since we\u0026#39;re manually inserting a delete event to remove this node, // we don\u0026#39;t need to keep tracking it as a virtual node and requeueing in attemptToDelete item.markObserved() return nil case err != nil: return err } //uid不匹配 if latest.GetUID() != item.identity.UID { klog.V(5).Infof(\u0026#34;UID doesn\u0026#39;t match, item %v not found, generating a virtual delete event\u0026#34;, item.identity) gc.dependencyGraphBuilder.enqueueVirtualDeleteEvent(item.identity) // since we\u0026#39;re manually inserting a delete event to remove this node, // we don\u0026#39;t need to keep tracking it as a virtual node and requeueing in attemptToDelete //因为我们手动插入删除事件以删除此节点，我们不需要将其作为虚拟节点跟踪并在attemptToDelete中重新排队 item.markObserved() return nil } // TODO: attemptToOrphanWorker() routine is similar. Consider merging // attemptToOrphanWorker() into attemptToDeleteItem() as well. // item的从资源正在删除中,同时删除其从资源 if item.isDeletingDependents() { return gc.processDeletingDependentsItem(item) } // compute if we should delete the item // 获取该object里metadata.ownerReference // 计算我们是否应删除该项目 ownerReferences := latest.GetOwnerReferences() if len(ownerReferences) == 0 { //没有owner的不用处理 klog.V(2).Infof(\u0026#34;object %s\u0026#39;s doesn\u0026#39;t have an owner, continue on next item\u0026#34;, item.identity) return nil } //solid(owner存在,owner没被删或者终结器不为foregroundDeletion Finalizer); dangling(owner不存在) // waitingForDependentsDeletion(owner存在,owner的deletionTimestamp为非nil，并且有foregroundDeletion Finalizer)owner列表 solid, dangling, waitingForDependentsDeletion, err := gc.classifyReferences(item, ownerReferences) if err != nil { return err } klog.V(5).Infof(\u0026#34;classify references of %s.\\nsolid: %#v\\ndangling: %#v\\nwaitingForDependentsDeletion: %#v\\n\u0026#34;, item.identity, solid, dangling, waitingForDependentsDeletion) switch { //item对象的owner存在,且不是正在删除 case len(solid) != 0: klog.V(2).Infof(\u0026#34;object %#v has at least one existing owner: %#v, will not garbage collect\u0026#34;, solid, item.identity) if len(dangling) == 0 \u0026amp;\u0026amp; len(waitingForDependentsDeletion) == 0 { return nil } klog.V(2).Infof(\u0026#34;remove dangling references %#v and waiting references %#v for object %s\u0026#34;, dangling, waitingForDependentsDeletion, item.identity) // waitingForDependentsDeletion needs to be deleted from the // ownerReferences, otherwise the referenced objects will be stuck with // the FinalizerDeletingDependents and never get deleted. // waitingForDependentsDeletion需要从 ownerReferences中删除，否则引用的对象将被 // FinalizerDeletingDependents所卡住，并且永远不会被删除。 //需要移除的ownerUids ownerUIDs := append(ownerRefsToUIDs(dangling), ownerRefsToUIDs(waitingForDependentsDeletion)...) //拼接patch请求参数 patch := deleteOwnerRefStrategicMergePatch(item.identity.UID, ownerUIDs...) //发送patch请求 _, err = gc.patch(item, patch, func(n *node) ([]byte, error) { return gc.deleteOwnerRefJSONMergePatch(n, ownerUIDs...) }) return err //item对象的owner正在被删除; 且item有从资源 case len(waitingForDependentsDeletion) != 0 \u0026amp;\u0026amp; item.dependentsLength() != 0: deps := item.getDependents() // 遍历item从资源 for _, dep := range deps { if dep.isDeletingDependents() { // this circle detection has false positives, we need to // apply a more rigorous detection if this turns out to be a // problem. // there are multiple workers run attemptToDeleteItem in // parallel, the circle detection can fail in a race condition. klog.V(2).Infof(\u0026#34;processing object %s, some of its owners and its dependent [%s] have FinalizerDeletingDependents, to prevent potential cycle, its ownerReferences are going to be modified to be non-blocking, then the object is going to be deleted with Foreground\u0026#34;, item.identity, dep.identity) // 生成一个补丁，该补丁会取消设置item所有ownerReferences的BlockOwnerDeletion字段,避免阻塞item的owner删除 patch, err := item.unblockOwnerReferencesStrategicMergePatch() if err != nil { return err } //执行patch if _, err := gc.patch(item, patch, gc.unblockOwnerReferencesJSONMergePatch); err != nil { return err } break } } //item对象的至少一个owner具有foregroundDeletion Finalizer，并且该对象本身具有依赖项，因此它将在Foreground中删除 klog.V(2).Infof(\u0026#34;at least one owner of object %s has FinalizerDeletingDependents, and the object itself has dependents, so it is going to be deleted in Foreground\u0026#34;, item.identity) // the deletion event will be observed by the graphBuilder, so the item // will be processed again in processDeletingDependentsItem. If it // doesn\u0026#39;t have dependents, the function will remove the // FinalizerDeletingDependents from the item, resulting in the final // deletion of the item. // graphBuilder将观察删除事件，因此将在processDeletingDependentsItem中再次处理该项目。 // 如果没有依赖项，该函数将从项中删除foregroundDeletion Finalizer，最终删除item。 policy := metav1.DeletePropagationForeground return gc.deleteObject(item.identity, \u0026amp;policy) default: // item doesn\u0026#39;t have any solid owner, so it needs to be garbage // collected. Also, none of item\u0026#39;s owners is waiting for the deletion of // the dependents, so set propagationPolicy based on existing finalizers. // item没有任何实体所有者，因此需要收集垃圾 。此外，项目的所有者都没有等待删除 // 依赖项，因此请根据现有的终结器设置propagationPolicy。 var policy metav1.DeletionPropagation switch { case hasOrphanFinalizer(latest): // if an existing orphan finalizer is already on the object, honor it. //如果现有的孤儿终结器已经在对象上，请尊重它。 policy = metav1.DeletePropagationOrphan case hasDeleteDependentsFinalizer(latest): // if an existing foreground finalizer is already on the object, honor it. //如果现有的前景终结器已经在对象上，请尊重它。 policy = metav1.DeletePropagationForeground default: // otherwise, default to background. //否则，默认为背景。 policy = metav1.DeletePropagationBackground } klog.V(2).Infof(\u0026#34;delete object %s with propagation policy %s\u0026#34;, item.identity, policy) //删除孤儿对象 return gc.deleteObject(item.identity, \u0026amp;policy) } } 主要做以下事情：\n1、item在删除中，且为Orphan和Background方式删除则直接返回；\n2、item是foreground方式删除时，调用processDeletingDependentsItem去处理阻塞其删除的从资源，将其放到attemptToDelete队列；\n3、获取item的owner对象集，调用classifyReferences将owner集合分为3类，分别为solid（owner存在或者终结器不为foregroundDeletion的owner集合）, dangling（已经不存在了的owner集群）, waitingForDependentsDeletion（owner的deletionTimestamp为非nil，并且为foregroundDeletion终结器的owner集合）\n4、switch第一个case：solid集合不为空，即item存在没被删除的owner。当dangling和waitingForDependentsDeletion都为空，则直接返回；当dangling或waitingForDependentsDeletion不为空，合并两个集合uid，执行patch请求，将这些uid对应的ownerReferences从item中删除\n5、switch第二个case：waitingForDependentsDeletion集合不为空，且item有从资源。即item的owner不存在，或正在被foregroundDeletion方式删除，如果item的从资源正在删除依赖项，则取消阻止item的owner删除，给item执行patch请求，最终采用foregroundDeletion方式删除item；\n6、switch第三个case：以上条件不符合时，则直接根据item中的终结器删除item，默认为Background方式删除。\n往细了说，processDeletingDependentsItem方法获取item从资源中BlockOwnerDeletion为true的ownerReferences集合，如果为空，则移除item的foregroundDeletion终结器。否则遍历，将未开始删除的依赖项的从资源dep加入到尝试删除队列attemptToDelete。\n//等待其依赖项被删除的进程项 func (gc *GarbageCollector) processDeletingDependentsItem(item *node) error { //阻塞item资源删除的从资源列表 blockingDependents := item.blockingDependents() //没有阻塞item资源删除的从资源,则移除item资源的foregroundDeletion终结器 if len(blockingDependents) == 0 { klog.V(2).Infof(\u0026#34;remove DeleteDependents finalizer for item %s\u0026#34;, item.identity) return gc.removeFinalizer(item, metav1.FinalizerDeleteDependents) } //遍历阻塞item资源删除的从资源 for _, dep := range blockingDependents { // 如果dep的从资源没有开始删除,则将dep加入到尝试删除队列中 if !dep.isDeletingDependents() { klog.V(2).Infof(\u0026#34;adding %s to attemptToDelete, because its owner %s is deletingDependents\u0026#34;, dep.identity, item.identity) //将从资源加入删除队列 gc.attemptToDelete.Add(dep) } } return nil } gc.classifyReferences(item, ownerReferences)方法：遍历了item的owner列表，调用isDangling方法将已不存在的owner加入到isDangling列表；owner正在被删除,且owner有foregroundDeletion终结器的加入到waitingForDependentsDeletion列表；owner没开始删或者终结器不为foregroundDeletion的加入到solid列表。\n// 将latestReferences分为三类： // solid：所有者存在，且不是waitingForDependentsDeletion // dangling悬空：所有者不存在 // waitingForDependentsDeletion: 所有者存在，其deletionTimestamp为非nil，并且有FinalizerDeletingDependents func (gc *GarbageCollector) classifyReferences(item *node, latestReferences []metav1.OwnerReference) ( solid, dangling, waitingForDependentsDeletion []metav1.OwnerReference, err error) { //遍历该node的owner for _, reference := range latestReferences { //获取owner是否存在;isDangling为true表示不存在,发生err则最终将该item加入AddRateLimited attemptToDelete队列 isDangling, owner, err := gc.isDangling(reference, item) if err != nil { return nil, nil, nil, err } //将不存在的owner加入dangling切片 if isDangling { dangling = append(dangling, reference) continue } //owner存在,获取accessor ownerAccessor, err := meta.Accessor(owner) if err != nil { return nil, nil, nil, err } //owner正在被删除,且owner有foregroundDeletion Finalizer if ownerAccessor.GetDeletionTimestamp() != nil \u0026amp;\u0026amp; hasDeleteDependentsFinalizer(ownerAccessor) { //owner将等待依赖删除;收集等待删除依赖的owner列表 waitingForDependentsDeletion = append(waitingForDependentsDeletion, reference) } else { //owner没被删或者终结器不为foregroundDeletion Finalizer solid = append(solid, reference) } } return solid, dangling, waitingForDependentsDeletion, nil } gc.isDangling(reference, item)方法：先从absentOwnerCache缓存中根据owner uid获取owner是否存在；如果缓存中没有，则根据ownerReferences中的参数，构建参数，调用apiserver接口获取owner对象是否能查到。查到如果uid不匹配，加入absentOwnerCache缓存，并返回false。\n// isDangling检查引用是否指向不存在的对象。 如果isDangling在API服务器上查找引用的对象，它也返回其最新状态。 func (gc *GarbageCollector) isDangling(reference metav1.OwnerReference, item *node) ( dangling bool, owner *unstructured.Unstructured, err error) { if gc.absentOwnerCache.Has(reference.UID) { klog.V(5).Infof(\u0026#34;according to the absentOwnerCache, object %s\u0026#39;s owner %s/%s, %s does not exist\u0026#34;, item.identity.UID, reference.APIVersion, reference.Kind, reference.Name) return true, nil, nil } // TODO: we need to verify the reference resource is supported by the // system. If it\u0026#39;s not a valid resource, the garbage collector should i) // ignore the reference when decide if the object should be deleted, and // ii) should update the object to remove such references. This is to // prevent objects having references to an old resource from being // deleted during a cluster upgrade. resource, namespaced, err := gc.apiResource(reference.APIVersion, reference.Kind) if err != nil { return false, nil, err } // TODO: It\u0026#39;s only necessary to talk to the API server if the owner node // is a \u0026#34;virtual\u0026#34; node. The local graph could lag behind the real // status, but in practice, the difference is small. owner, err = gc.dynamicClient.Resource(resource).Namespace(resourceDefaultNamespace(namespaced, item.identity.Namespace)).Get(reference.Name, metav1.GetOptions{}) switch { case errors.IsNotFound(err): gc.absentOwnerCache.Add(reference.UID) klog.V(5).Infof(\u0026#34;object %s\u0026#39;s owner %s/%s, %s is not found\u0026#34;, item.identity.UID, reference.APIVersion, reference.Kind, reference.Name) return true, nil, nil case err != nil: return false, nil, err } if owner.GetUID() != reference.UID { klog.V(5).Infof(\u0026#34;object %s\u0026#39;s owner %s/%s, %s is not found, UID mismatch\u0026#34;, item.identity.UID, reference.APIVersion, reference.Kind, reference.Name) gc.absentOwnerCache.Add(reference.UID) return true, nil, nil } return false, owner, nil } attemptToOrphan队列 # 来到代码：\nfunc (gc *GarbageCollector) runAttemptToOrphanWorker() { for gc.attemptToOrphanWorker() { } } 死循环一直从attemptToOrphan队列中获取item资源，调用gc.orphanDependents(owner.identity, dependents)方法，从item从资源中删掉该item的ownerReferences，期间如果发生错误，则通过rateLimited重新加回attemptToOrphan队列。最后移除item中的orphan终结器。\n// attemptToOrphanWorker将一个节点从attemptToOrphan中取出，然后根据GC维护的图找到它的依赖项，然后将其从其依赖项的 // OwnerReferences中删除，最后更新item以删除孤儿终结器。如果这些步骤中的任何一个失败，则将节点添加回attemptToOrphan。 func (gc *GarbageCollector) attemptToOrphanWorker() bool { item, quit := gc.attemptToOrphan.Get() gc.workerLock.RLock() defer gc.workerLock.RUnlock() if quit { return false } defer gc.attemptToOrphan.Done(item) owner, ok := item.(*node) if !ok { utilruntime.HandleError(fmt.Errorf(\u0026#34;expect *node, got %#v\u0026#34;, item)) return true } // we don\u0026#39;t need to lock each element, because they never get updated owner.dependentsLock.RLock() dependents := make([]*node, 0, len(owner.dependents)) for dependent := range owner.dependents { dependents = append(dependents, dependent) } owner.dependentsLock.RUnlock() // 处理孤儿 err := gc.orphanDependents(owner.identity, dependents) if err != nil { utilruntime.HandleError(fmt.Errorf(\u0026#34;orphanDependents for %s failed with %v\u0026#34;, owner.identity, err)) gc.attemptToOrphan.AddRateLimited(item) return true } // update the owner, remove \u0026#34;orphaningFinalizer\u0026#34; from its finalizers list // 移除item的orphan终结器 err = gc.removeFinalizer(owner, metav1.FinalizerOrphanDependents) if err != nil { utilruntime.HandleError(fmt.Errorf(\u0026#34;removeOrphanFinalizer for %s failed with %v\u0026#34;, owner.identity, err)) gc.attemptToOrphan.AddRateLimited(item) } return true } gc.orphanDependents(owner.identity, dependents)方法：遍历item的从资源，并发的执行patch请求，删除从资源中和item同uid的ownerReferences，将error加入到errCh channel中，最后给调用者返回error列表：\n// dependents are copies of pointers to the owner\u0026#39;s dependents, they don\u0026#39;t need to be locked. func (gc *GarbageCollector) orphanDependents(owner objectReference, dependents []*node) error { errCh := make(chan error, len(dependents)) wg := sync.WaitGroup{} wg.Add(len(dependents)) for i := range dependents { go func(dependent *node) { defer wg.Done() // the dependent.identity.UID is used as precondition patch := deleteOwnerRefStrategicMergePatch(dependent.identity.UID, owner.UID) _, err := gc.patch(dependent, patch, func(n *node) ([]byte, error) { return gc.deleteOwnerRefJSONMergePatch(n, owner.UID) }) // note that if the target ownerReference doesn\u0026#39;t exist in the // dependent, strategic merge patch will NOT return an error. if err != nil \u0026amp;\u0026amp; !errors.IsNotFound(err) { errCh \u0026lt;- fmt.Errorf(\u0026#34;orphaning %s failed, %v\u0026#34;, dependent.identity, err) } }(dependents[i]) } wg.Wait() close(errCh) var errorsSlice []error for e := range errCh { errorsSlice = append(errorsSlice, e) } if len(errorsSlice) != 0 { return fmt.Errorf(\u0026#34;failed to orphan dependents of owner %s, got errors: %s\u0026#34;, owner, utilerrors.NewAggregate(errorsSlice).Error()) } klog.V(5).Infof(\u0026#34;successfully updated all dependents of owner %s\u0026#34;, owner) return nil } deleteOwnerRefStrategicMergePatch方法：拼接patch请求参数。该方法同样的，在处理attemptToDelete死循中，第一个switch case处被调用。\nfunc deleteOwnerRefStrategicMergePatch(dependentUID types.UID, ownerUIDs ...types.UID) []byte { var pieces []string //拼接需要删除的uid for _, ownerUID := range ownerUIDs { pieces = append(pieces, fmt.Sprintf(`{\u0026#34;$patch\u0026#34;:\u0026#34;delete\u0026#34;,\u0026#34;uid\u0026#34;:\u0026#34;%s\u0026#34;}`, ownerUID)) } //拼接patch请求参数 patch := fmt.Sprintf(`{\u0026#34;metadata\u0026#34;:{\u0026#34;ownerReferences\u0026#34;:[%s],\u0026#34;uid\u0026#34;:\u0026#34;%s\u0026#34;}}`, strings.Join(pieces, \u0026#34;,\u0026#34;), dependentUID) return []byte(patch) } 回到初衷 # 中间件redis容器化后，在测试环境上部署的redis集群，在kubernetes apiserver重启后，redis集群被异常删除（包括redis exporter statefulset、redis statefulset）。\n原因定位 # 在开发环境上经多次复现，apiserver重启后，通过查询redis operator日志，并没有发现主动去删除redis集群（redis statefulset）、监控实例（redis exporter）。进一步去查看kube-controller-manager的日志，将其日志级别设置\u0026ndash;v=5，继续复现，最终在kube-controller-manager日志中发现如下日志：\n可以看到，垃圾回收器garbage collector在处理redis exporter statefulset时，发现其加了ownerReferences，在exporter所在分区（monitoring）查询其owner——redisCluster对象redis-0826，而redisCluster对象redis-0826存在于kube-system分区，所以在monitoring分区查询到的是404 Not Found，garbage collector会将该owner不存在信息（uid）存入缓存absentOwnerCache。\n因redis exporter statefulset的owner不存在，所以gc认为需要回收垃圾，故将其删除掉。同理，当处理redis statefulset时，从缓存中发现owner不存在，也会回收垃圾，将其删除掉。\n经过多次复现故障，发现重启kube-controller-manager时有概率复现。（Apiserver的重启时，kube-controller-manager在连接apiserver失败多次后，也会发生自重启），之所以是概率问题，这和garbage collector将资源对象加入attemptToDelete队列的顺序有关：\n先同步monitoring分区的exporter statefulset，后同步kube-system分区的redis statefulset，就会出现该故障；反之就不会出现故障，这取决于garbage collector启动时全量获取集群内资源（listwatch）的顺序。\n在apiserver和kube-controller-manager正常运行时不出现该故障，可以从garbage collector源码中看到以下代码逻辑：\nGarbage collector中维护一个父子关系图表，controller-manager启动时该图里节点是不存在的，会走上图switch的第一个case，之后图形成之后，会走第二个case。第二个case里只有在owner发生变化时才会触发将资源对象加入attemptToDelete队列，所以在各个组件正常运行时没有出现该故障。\n获取图表的接口地址，IP和端口都是controller-manager的，可以重定向到tmp.dot文件\ncurl http://127.0.0.1:10252/debug/controllers/garbagecollector/graph curl http://127.0.0.1:10252/debug/controllers/garbagecollector/graph?uid=11211212edsaddkqedmk12 之后用可视化工具Graphviz软件，进入到bin目录下，执行以下命令生成svg文件，用浏览器打开，Graphviz和dot的使用可以自行谷歌。\ndot -Tsvg -o graph2.svg tmp.dot 解决方法 # 在redis operator创建redis集群时，将exporter放到和redis同一分区。\n思考反思 # 1、出现该故障，主要是因进行了跨命名空间owner引用。在使用垃圾回收机制时，应该尽量参考kubernetes官方网站中的说明.\n如下，官网中说明了owner引用在设计时就不允许跨namespace使用，这意味着：\n1）命名空间范围的从属只能指定同一命名空间中的所有者，以及群集范围的所有者。\n2）群集作用域的从属只能指定群集作用域的所有者，而不能指定命名空间作用域的所有者。\n参考文档 # 垃圾回收官方文档：\nhttps://kubernetes.io/docs/concepts/workloads/controllers/garbage-collection/\n详解 Kubernetes 垃圾收集器的实现原理：\nhttps://draveness.me/kubernetes-garbage-collector#\n本公众号免费**提供csdn下载服务，海量IT学习资源，**如果你准备入IT坑，励志成为优秀的程序猿，那么这些资源很适合你，包括但不限于java、go、python、springcloud、elk、嵌入式 、大数据、面试资料、前端 等资源。同时我们组建了一个技术交流群，里面有很多大佬，会不定时分享技术文章，如果你想来一起学习提高，可以公众号后台回复【2】，免费邀请加技术交流群互相学习提高，会不定期分享编程IT相关资源。\n扫码关注，精彩内容第一时间推给你\n","date":"2019年10月21日","externalUrl":null,"permalink":"/posts/kubernetes%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8garbagecollector%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B8%89/","section":"Posts","summary":"\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003ekubernetes版本：1.13.2\u003c/strong\u003e\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e接前两节：\u003cbr /\u003e\n\u003ca href=\"https://liabio.blog.csdn.net/article/details/100081941\" target=\"_blank\"\u003ekubernetes垃圾回收器GarbageCollector Controller源码分析（一）\u003c/a\u003e\u003cbr /\u003e\n\u003ca href=\"https://liabio.blog.csdn.net/article/details/100549251\" target=\"_blank\"\u003ekubernetes垃圾回收器GarbageCollector Controller源码分析（二）\u003c/a\u003e\u003c/p\u003e","title":"kubernetes垃圾回收器GarbageCollector 源码分析（三）","type":"posts"},{"content":" 作者：严晟嘉\n链接：https://www.zhihu.com/question/31377141/answer/103056861\n1. 向你的 Github Pages 仓库添加一个CNAME(一定要大写)文件\n其中只能包含一个顶级域名，像这样：\nexample.com 如果你是用 hexo 框架搭建博客并部署到 Github Pages 上，每次\n\u0026gt; hexo g \u0026gt; hexo d 后会把你的博客所在目录下 public 文件夹里的东西都推到 Github Pages 仓库上，并且把 CNAME 文件覆盖掉，解决这个问题可以直接把 CNAME 文件添加到 source 文件夹里，这样每次推的时候就不用担心仓库里的 CNAME 文件被覆盖掉了。\n2. 向你的 DNS 配置中添加 3 条记录\n@ A 192.30.252.153 @ A 192.30.252.154 www CNAME username.github.io. 用你自己的 Github 用户名替换 username\n配置 DNS 推荐使用 DNSPOD 的服务，使用国外的 DNS 解析服务可能有被墙的风险。\n至于如何使用 DNSPOD 解析域名，参考\nhttp://jingyan.baidu.com/article/546ae1857c4ee81149f28cbe.html​jingyan.baidu.com\n3. 等待你的 DNS 配置生效\n对DNS的配置不是立即生效的，过10分钟再去访问你的域名看看有没有配置成功 : )D\n4. 启用 HTTPS\n自 2018 年 5 月 1 日，Github 支持自定义域名的 HTTPS 请求了。\n详情见：\nhttps://blog.github.com/2018-05-01-github-pages-custom-domains-https/​blog.github.com\n配置也相当简单，只需要更新 DNS 配置里的 A 记录，将其指向以下4个 IP 地址中的至少一个。\n185.199.108.153 185.199.109.153 185.199.110.153 185.199.111.153 HTTPS 让你的网站和网站访客更安全，并且 Github 提供的这些 IP 地址自动将你的站点加入了 CDN，提高了访问速度。\n你还可以在 GiHub Pages 仓库的设置里勾选 \u0026lsquo;Enforce HTTPS\u0026rsquo;，这样所有访问你站点的请求都会走 HTTPS。\n不得不说，GitHub 是真的良心。\n","date":"2019年10月20日","externalUrl":null,"permalink":"/posts/github%E6%80%8E%E4%B9%88%E7%BB%91%E5%AE%9A%E8%87%AA%E5%B7%B1%E7%9A%84%E5%9F%9F%E5%90%8D%E4%BB%A5%E5%8F%8A%E6%80%8E%E4%B9%88%E6%94%AF%E6%8C%81https/","section":"Posts","summary":"\u003cblockquote\u003e\n\u003cp\u003e作者：严晟嘉\u003cbr /\u003e\n链接：https://www.zhihu.com/question/31377141/answer/103056861\u003c/p\u003e","title":"github怎么绑定自己的域名？以及怎么支持https？","type":"posts"},{"content":"","date":"2019年10月18日","externalUrl":null,"permalink":"/tags/nginx/","section":"Tags","summary":"","title":"Nginx","type":"tags"},{"content":"","date":"2019年10月18日","externalUrl":null,"permalink":"/tags/openresty/","section":"Tags","summary":"","title":"Openresty","type":"tags"},{"content":" 正文 # 报错： # nginx: [error] CreateFile() \u0026ldquo;./logs/nginx.pid\u0026rdquo; failed (2: The system cannot find the file specified)\n博主在执行了nginx -s stop后，再次启动nginx时报错：\n这个坑主要原因就是没有nginx.pid这个文件，./logs/下找不到nginx.pid文件，看了确实找不到。\n看了网上很多方案是 需要建立nginx.pid文件，也就是要指定nginx.conf这个配置文件，然后博主很傻的这样执行了一把：\nnginx -c conf/nginx.conf 还是直接说正解吧 ：开启你的cmd（命令列） 然后你需要以你nginx.exe所在路径的绝对路径，比如博主的路径在 D:\\Program Files\\openresty-1.13.6.2-win64\n那么命令列就需要这样写\n\u0026ldquo;d:\\Program Files\\openresty-1.13.6.2-win64\\nginx.exe\u0026rdquo; -c \u0026ldquo;d:\\Program Files\\openresty-1.13.6.2-win64\\conf\\nginx.conf\u0026rdquo;\n生成了nginx.pid文件：\n里面只有一个PID号：\n","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/%E5%AD%A6%E4%B9%A0openresty%E6%97%B6nginx%E7%9A%84%E4%B8%80%E4%B8%AA%E5%9D%91/","section":"Posts","summary":"\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\n\u003ch4 class=\"relative group\"\u003e报错： \n    \u003cdiv id=\"报错\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%8a%a5%e9%94%99\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h4\u003e\n\u003cp\u003enginx: [error] CreateFile() \u0026ldquo;./logs/nginx.pid\u0026rdquo; failed (2: The system cannot find the file specified)\u003c/p\u003e","title":"学习openresty时，nginx的一个坑","type":"posts"},{"content":" 正文 # mysql数据导出为excel文件，golang实现：\n首先下载依赖到的三方库：\nSimple install the package to your $GOPATH with the go tool from shell:\n$ go get -u github.com/go-sql-driver/mysql **具体说明请看：** [库地址](https://github.com/go-sql-driver/mysql) [wiki说明](https://github.com/go-sql-driver/mysql/wiki/Examples) 代码示例如下，用到了go的flag包的能力，传入命令行参数。具体看helpInfo：\nUsage of mysqldataexport: -port int the port for mysql,default:32085 -addr string the address for mysql,default:10.146.145.67 -user string the username for login mysql,default:dbuser -pwd string the password for login mysql by the username,default:Admin@123 -db string the port for me to listen on,default:auditlogdb -tables string the tables will export data, multi tables separator by comma, default:op_log,sc_log,sys_log 代码：\npackage main // 从Mysql中导出数据到CSV文件。 import ( \u0026#34;database/sql\u0026#34; \u0026#34;encoding/csv\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; _ \u0026#34;github.com/go-sql-driver/mysql\u0026#34; \u0026#34;flag\u0026#34; \u0026#34;strings\u0026#34; ) var ( tables = make([]string, 0) dataSourceName = \u0026#34;\u0026#34; ) const ( driverNameMysql = \u0026#34;mysql\u0026#34; helpInfo = `Usage of mysqldataexport: -port int the port for mysql,default:32085 -addr string the address for mysql,default:10.146.145.67 -user string the username for login mysql,default:dbuser -pwd string the password for login mysql by the username,default:Admin@123 -db string the port for me to listen on,default:auditlogdb -tables string the tables will export data, multi tables separator by comma, default:op_log,sc_log,sys_log ` ) func init() { port := flag.Int(\u0026#34;port\u0026#34;, 32085, \u0026#34;the port for mysql,default:32085\u0026#34;) addr := flag.String(\u0026#34;addr\u0026#34;, \u0026#34;10.146.145.67\u0026#34;, \u0026#34;the address for mysql,default:10.146.145.67\u0026#34;) user := flag.String(\u0026#34;user\u0026#34;, \u0026#34;dbuser\u0026#34;, \u0026#34;the username for login mysql,default:dbuser\u0026#34;) pwd := flag.String(\u0026#34;pwd\u0026#34;, \u0026#34;Admin@123\u0026#34;, \u0026#34;the password for login mysql by the username,default:Admin@123\u0026#34;) db := flag.String(\u0026#34;db\u0026#34;, \u0026#34;auditlogdb\u0026#34;, \u0026#34;the port for me to listen on,default:auditlogdb\u0026#34;) tabs := flag.String(\u0026#34;tables\u0026#34;, \u0026#34;op_log,sc_log,sys_log\u0026#34;, \u0026#34;the tables will export data, multi tables separator by comma, default:op_log,sc_log,sys_log\u0026#34;) flag.Usage = usage flag.Parse() tables = append(tables, strings.Split(*tabs, \u0026#34;,\u0026#34;)...) dataSourceName = fmt.Sprintf(\u0026#34;%s:%s@tcp(%s:%d)/%s?charset=utf8\u0026#34;, *user, *pwd, *addr, *port, *db) } func main() { count := len(tables) ch := make(chan bool, count) db, err := sql.Open(driverNameMysql, dataSourceName) defer db.Close() if err != nil { panic(err.Error()) } // Open doesn\u0026#39;t open a connection. Validate DSN data: err = db.Ping() if err != nil { panic(err.Error()) } for _, table := range tables { go querySQL(db, table, ch) } for i := 0; i \u0026lt; count; i++ { \u0026lt;-ch } fmt.Println(\u0026#34;Done!\u0026#34;) } func querySQL(db *sql.DB, table string, ch chan bool) { fmt.Println(\u0026#34;开始处理：\u0026#34;, table) rows, err := db.Query(fmt.Sprintf(\u0026#34;SELECT * from %s\u0026#34;, table)) if err != nil { panic(err) } columns, err := rows.Columns() if err != nil { panic(err.Error()) } //values：一行的所有值,把每一行的各个字段放到values中，values长度==列数 values := make([]sql.RawBytes, len(columns)) // print(len(values)) scanArgs := make([]interface{}, len(values)) for i := range values { scanArgs[i] = \u0026amp;values[i] } //存所有行的内容totalValues totalValues := make([][]string, 0) for rows.Next() { //存每一行的内容 var s []string //把每行的内容添加到scanArgs，也添加到了values err = rows.Scan(scanArgs...) if err != nil { panic(err.Error()) } for _, v := range values { s = append(s, string(v)) // print(len(s)) } totalValues = append(totalValues, s) } if err = rows.Err(); err != nil { panic(err.Error()) } writeToCSV(table+\u0026#34;.csv\u0026#34;, columns, totalValues) ch \u0026lt;- true } //writeToCSV func writeToCSV(file string, columns []string, totalValues [][]string) { f, err := os.Create(file) // fmt.Println(columns) defer f.Close() if err != nil { panic(err) } //f.WriteString(\u0026#34;\\xEF\\xBB\\xBF\u0026#34;) w := csv.NewWriter(f) for i, row := range totalValues { //第一次写列名+第一行数据 if i == 0 { w.Write(columns) w.Write(row) } else { w.Write(row) } } w.Flush() fmt.Println(\u0026#34;处理完毕：\u0026#34;, file) } func usage() { fmt.Fprint(os.Stderr, helpInfo) flag.PrintDefaults() } 操作示例：\n编译代码生成可执行文件：\ngo build mysqldataexport.go 数据库中有test2库下的test表：\n导出其中的数据：\n.\\mysqldataexport.exe -port=3306 -addr=\u0026#34;localhost\u0026#34; -user=\u0026#34;root\u0026#34; -pwd=\u0026#34;mysql\u0026#34; -db=\u0026#34;test2\u0026#34; -tables=\u0026#34;test\u0026#34; 导出结果如下：\n","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/mysql%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BAgolang%E5%AE%9E%E7%8E%B0/","section":"Posts","summary":"\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003emysql数据导出为excel文件，golang实现：\u003c/p\u003e","title":"mysql数据导出golang实现","type":"posts"},{"content":"kubernetes自定义资源对象再极大程度提高了API Server的可扩展性，让企业能够根据业务需求通过CRD编写controller或者operator来实现生产中各种特殊场景。随着k8s的版本升级，CRD的功能也越来越完善，下面对其中几点进行说明。\n以下验证kubernetes版本为1.13.2，docker版本：18.09.5\nValidation（验证） # 在项目中用自定义资源对象时，如果创建自定义资源时某些字段不符合要求，会导致监听该资源对象的controller或者operator出现异常，解析结构体报错，所以Validation这个功能非常实用，在创建时就进行校验，减少后面的排错和异常处理的麻烦。\n可以通过 OpenAPI v3 schema验证自定义对象是否符合标准 。此外，以下限制适用于 schema：\n字段default、nullable、discriminator、readOnly、writeOnly、xml、 deprecated 和 $ref 不能设置。 该字段 uniqueItems 不能设置为 true。 该字段 additionalProperties 不能设置为 false。 可以使用 kube-apiserverCustomResourceValidation 上的功能门（feature gate）禁用此功能：\n--feature-gates=CustomResourceValidation=false 从以下特性门参数说明地址，可以看到Validation功能在k8s 1.8版本就已经有了，但是CustomResourceValidation特性门是默认false，1.9Beta之后版本默认为true\nhttps://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/\n以下示例将大概对该功能进行应用和说明，在以下示例中，CustomResourceDefinition 对自定义对象应用以下验证：\nspec.replicas 为必填项，类型为integer，值为大于等于0小于50的偶数（2的倍数）； spec.repository 为必填项； spec.version为必填项； spec.pause为boolean类型； spec.updateStrategy为object类型，该object中有type、pipeline、assignStrategies属性； spec.updateStrategy.type为string类型，而且只能为\u0026quot;AssignReceive\u0026quot;, \u0026ldquo;AutoReceive\u0026quot;两个枚举值； spec.updateStrategy.pipeline为string类型，而且为正整数的字符串，符合正则表达式^([1-9][0-9]*){1,3}$; spec.updateStrategy.assignStrategies为array类型，其元素为object类型（包含slots和fromReplicas属性）； spec.updateStrategy.assignStrategies.slots为1-16384的正整数； spec.updateStrategy.assignStrategies.fromReplicas为字符串，符合正则表达式^[a-z0-9,]{3,}$，即至少匹配3位a-z或者0-9或者逗号的字符串； spec.pod为array类型，其元素为object类型（包含configmap、monitorImage、initImage、middlewareImage字段）； spec.pod.configmap、spec.pod.monitorImage、spec.pod.initImage 、spec.pod.middlewareImage为string类型；且用required指定configmap、initImage、middlewareImage字段为必填项。 将以下内容保存到 redis-cluster-crd.yaml：\napiVersion: apiextensions.k8s.io/v1beta1 kind: CustomResourceDefinition metadata: name: redisclusters.redis.middleware.hc.cn spec: group: redis.middleware.hc.cn versions: - name: v1alpha1 # Each version can be enabled/disabled by Served flag. served: true # One and only one version must be marked as the storage version. storage: true scope: Namespaced names: kind: RedisCluster singular: rediscluster listKind: RedisClusterList plural: redisclusters shortNames: - rec # 执行kubectl get all时会查到pod、service、该crd等属于all categories的资源对象 categories: - all validation: # openAPIV3Schema 适用于验证自定义对象的 schema。 openAPIV3Schema: properties: spec: required: [\u0026#34;replicas\u0026#34;, \u0026#34;repository\u0026#34;, \u0026#34;version\u0026#34;] properties: pause: type: boolean replicas: type: integer minimum: 0 maximum: 50 # 偶数 multipleOf: 2 updateStrategy: type: object properties: type: type: string # 枚举 enum: [\u0026#34;AssignReceive\u0026#34;, \u0026#34;AutoReceive\u0026#34;] pipeline: type: string pattern: \u0026#39;^([1-9][0-9]*){1,3}$\u0026#39; assignStrategies: type: array items: type: object properties: slots: type: integer minimum: 1 maximum: 16384 fromReplicas: type: string # 至少匹配3位,a-z或者0-9或者, pattern: \u0026#39;^[a-z0-9,]{3,}$\u0026#39; pod: type: array items: type: object required: [\u0026#34;configmap\u0026#34;, \u0026#34;middlewareImage\u0026#34;, \u0026#34;initImage\u0026#34;] properties: configmap: type: string monitorImage: type: string initImage: type: string middlewareImage: type: string 创建它：\nkubectl create -f redis-cluster-crd.yaml 默认不加validation时，在创建自定义资源对象时，不会校验，有些字段没有了（如spec.replicas）都可以正常被创建，为了减少排错的难度和operator、controller的麻烦的检验，所以在创建自定义资源定义时，就把validation加上。以上的检验应该覆盖到了常见的检验场景，其他场景可以自己摸索。具体还可以参考kubernetes源码，1.13.2版本kubernetes源码位于types.go第327行CustomResourceValidation结构体：\n$GOPATH/src/k8s.io/kubernetes/staging/src/k8s.io/apiextensions-apiserver/pkg/apis/apiextensions/types.go 将以下YAML保存到redis-cluster-cr.yaml：\napiVersion: redis.middleware.hc.cn/v1alpha1 kind: RedisCluster metadata: name: example000-redis-cluster namespace: kube-system spec: # 代表redis集群的个数 replicas: 3 # 代表是否进入维修状态 pause: true repository: library/redis # 镜像版本，便于后续多版本特化支持 version: 3.2.6 #redis集群升级策略 updateStrategy: # 升级类型为AutoReceive（自动分配,不用AssignStrategies）, AssignReceive（指定值分配，需要用AssignStrategies） type: AssignReceive1 pipeline: \u0026#34;100a\u0026#34; assignStrategies: - slots: 0 fromReplicas: nodeId1 - # 从nodeId3,nodeId4一共分配1000个卡槽 slots: 1000 # 多个nodeId用逗号分隔 fromReplicas: nodeId3,nodeId4 # redis 实例配置详情 pod: # 配置文件模板名 - configmap: example000-redis-cluster-config # 监控镜像 monitorImage: redis-exporter:v1 # 初始化镜像 #initImage: redis-init:v1 # 中间件容器镜像 middlewareImage: redis-trib:3.2.6 并创建它：\nkubectl create -f redis-cluster-cr.yaml 会发现报以下错误：\n# kubectl apply -f redis-cluster-cr.yaml The RedisCluster \u0026#34;example000-redis-cluster\u0026#34; is invalid: []: Invalid value: map[string]interface {}{\u0026#34;apiVersion\u0026#34;:\u0026#34;redis.middleware.hc.cn/v1alpha1\u0026#34;, \u0026#34;kind\u0026#34;:\u0026#34;RedisCluster\u0026#34;, \u0026#34;metadata\u0026#34;:map[string]interface {}{\u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34;, \u0026#34;uid\u0026#34;:\u0026#34;b0946031-766b-11e9-b457-000c295db389\u0026#34;, \u0026#34;resourceVersion\u0026#34;:\u0026#34;44231\u0026#34;, \u0026#34;generation\u0026#34;:19, \u0026#34;creationTimestamp\u0026#34;:\u0026#34;2019-05-14T17:14:10Z\u0026#34;, \u0026#34;annotations\u0026#34;:map[string]interface {}{\u0026#34;kubectl.kubernetes.io/last-applied-configuration\u0026#34;:\u0026#34;{\\\u0026#34;apiVersion\\\u0026#34;:\\\u0026#34;redis.middleware.hc.cn/v1alpha1\\\u0026#34;,\\\u0026#34;kind\\\u0026#34;:\\\u0026#34;RedisCluster\\\u0026#34;,\\\u0026#34;metadata\\\u0026#34;:{\\\u0026#34;annotations\\\u0026#34;:{},\\\u0026#34;name\\\u0026#34;:\\\u0026#34;example000-redis-cluster\\\u0026#34;,\\\u0026#34;namespace\\\u0026#34;:\\\u0026#34;kube-system\\\u0026#34;},\\\u0026#34;spec\\\u0026#34;:{\\\u0026#34;pause\\\u0026#34;:true,\\\u0026#34;pod\\\u0026#34;:[{\\\u0026#34;configmap\\\u0026#34;:\\\u0026#34;example000-redis-cluster-config\\\u0026#34;,\\\u0026#34;middlewareImage\\\u0026#34;:\\\u0026#34;redis-trib:3.2.6\\\u0026#34;,\\\u0026#34;monitorImage\\\u0026#34;:\\\u0026#34;redis-exporter:v1\\\u0026#34;}],\\\u0026#34;replicas\\\u0026#34;:3,\\\u0026#34;repository\\\u0026#34;:\\\u0026#34;library/redis\\\u0026#34;,\\\u0026#34;updateStrategy\\\u0026#34;:{\\\u0026#34;assignStrategies\\\u0026#34;:[{\\\u0026#34;fromReplicas\\\u0026#34;:\\\u0026#34;nodeId1\\\u0026#34;,\\\u0026#34;slots\\\u0026#34;:0},{\\\u0026#34;fromReplicas\\\u0026#34;:\\\u0026#34;nodeId3,nodeId4\\\u0026#34;,\\\u0026#34;slots\\\u0026#34;:1000}],\\\u0026#34;pipeline\\\u0026#34;:\\\u0026#34;100a\\\u0026#34;,\\\u0026#34;type\\\u0026#34;:\\\u0026#34;AssignReceive1\\\u0026#34;},\\\u0026#34;version\\\u0026#34;:\\\u0026#34;3.2.6\\\u0026#34;}}\\n\u0026#34;}, \u0026#34;name\u0026#34;:\u0026#34;example000-redis-cluster\u0026#34;}, \u0026#34;spec\u0026#34;:map[string]interface {}{\u0026#34;version\u0026#34;:\u0026#34;3.2.6\u0026#34;, \u0026#34;pause\u0026#34;:true, \u0026#34;pod\u0026#34;:[]interface {}{map[string]interface {}{\u0026#34;middlewareImage\u0026#34;:\u0026#34;redis-trib:3.2.6\u0026#34;, \u0026#34;monitorImage\u0026#34;:\u0026#34;redis-exporter:v1\u0026#34;, \u0026#34;configmap\u0026#34;:\u0026#34;example000-redis-cluster-config\u0026#34;}}, \u0026#34;replicas\u0026#34;:3, \u0026#34;repository\u0026#34;:\u0026#34;library/redis\u0026#34;, \u0026#34;updateStrategy\u0026#34;:map[string]interface {}{\u0026#34;assignStrategies\u0026#34;:[]interface {}{map[string]interface {}{\u0026#34;fromReplicas\u0026#34;:\u0026#34;nodeId1\u0026#34;, \u0026#34;slots\u0026#34;:0}, map[string]interface {}{\u0026#34;fromReplicas\u0026#34;:\u0026#34;nodeId3,nodeId4\u0026#34;, \u0026#34;slots\u0026#34;:1000}}, \u0026#34;pipeline\u0026#34;:\u0026#34;100a\u0026#34;, \u0026#34;type\u0026#34;:\u0026#34;AssignReceive1\u0026#34;}}}: validation failure list: spec.updateStrategy.assignStrategies.fromReplicas in body should match \u0026#39;^[a-z0-9,]{3,}$\u0026#39; spec.updateStrategy.assignStrategies.slots in body should be greater than or equal to 1 spec.updateStrategy.pipeline in body should match \u0026#39;^([1-9][0-9]*){1,3}$\u0026#39; spec.updateStrategy.type in body should be one of [AssignReceive AutoReceive] spec.pod.initImage in body is required spec.replicas in body should be a multiple of 2 如果所有字段都符合校验逻辑，才可以创建对象。\n将以下 YAML 保存到 redis-cluster-cr.yaml：\napiVersion: redis.middleware.hc.cn/v1alpha1 kind: RedisCluster metadata: name: example000-redis-cluster namespace: kube-system spec: # 代表redis集群的个数 replicas: 6 # 代表是否进入维修状态 pause: true repository: library/redis # 镜像版本，便于后续多版本特化支持 version: 3.2.6 #redis集群升级策略 updateStrategy: # 升级类型为AutoReceive（自动分配,不用AssignStrategies）, AssignReceive（指定值分配，需要用AssignStrategies） type: AssignReceive pipeline: \u0026#34;100\u0026#34; assignStrategies: - slots: 1 fromReplicas: all - # 从nodeId3,nodeId4一共分配1000个卡槽 slots: 1000 # 多个nodeId用逗号分隔 fromReplicas: node1,node2 # redis 实例配置详情 pod: # 配置文件模板名 - configmap: example000-redis-cluster-config # 监控镜像 monitorImage: redis-exporter:v1 # 初始化镜像 initImage: redis-init:v1 # 中间件容器镜像 middlewareImage: redis-trib:3.2.6 并创建它，发现才可以创建：\n# kubectl apply -f redis-cluster-cr.yaml rediscluster.redis.middleware.hc.cn/example000-redis-cluster configured Category（分类） # 类别是自定义资源所属的分组资源的列表（例如 all）。您可以使用 kubectl get \u0026lt;category-name\u0026gt; 列出属于该类别的资源。此功能可用于 v1.10 及以上k8s版本自定义资源。\n以下示例添加 all CustomResourceDefinition 中的类别列表，并说明如何使用 kubectl get all 输出自定义资源 。\n将以下 内容保存到 redis-cluster-crd.yaml中执行kubectl apply -f redis-cluster-crd.yaml：\napiVersion: apiextensions.k8s.io/v1beta1 kind: CustomResourceDefinition metadata: name: redisclusters.redis.middleware.hc.cn spec: group: redis.middleware.hc.cn versions: - name: v1alpha1 # Each version can be enabled/disabled by Served flag. served: true # One and only one version must be marked as the storage version. storage: true scope: Namespaced names: kind: RedisCluster singular: rediscluster listKind: RedisClusterList plural: redisclusters shortNames: - rec # 执行kubectl get all时会查到pod、service、该crd等属于all categories的资源对象 categories: - all 将以下内容保存到redis-cluster-cr.yaml中执行kubectl apply -f redis-cluster-cr.yaml：\napiVersion: redis.middleware.hc.cn/v1alpha1 kind: RedisCluster metadata: name: example000-redis-cluster namespace: kube-system spec: # 代表redis集群的个数 replicas: 6 # 代表是否进入维修状态 pause: true repository: library/redis # 镜像版本，便于后续多版本特化支持 version: 3.2.6 #redis集群升级策略 updateStrategy: # 升级类型为AutoReceive（自动分配,不用AssignStrategies）, AssignReceive（指定值分配，需要用AssignStrategies） type: AssignReceive pipeline: \u0026#34;100\u0026#34; assignStrategies: - slots: 2000 fromReplicas: nodeId1 - # 从nodeId3,nodeId4一共分配1000个卡槽 slots: 1000 # 多个nodeId用逗号分隔 fromReplicas: nodeId3,nodeId4 # redis 实例配置详情 pod: # 配置文件模板名 - configmap: example000-redis-cluster-config # 监控镜像 monitorImage: redis-exporter:v1 # 初始化镜像 initImage: redis-init:v1 # 中间件容器镜像 middlewareImage: redis-trib:3.2.6 执行kubectl get all时会查到pod、service、该crd等属于all categories的资源对象。（这个可能得等几分钟才能生效）\n子资源 # status子资源 # 启用状态子资源后，将公开自定义资源的子资源 /status。\n状态和规范节分别由自定义资源内的 .status 和 .spec JSONPath 表示。 PUT /status 对子资源的请求采用自定义资源对象，并忽略除状态节之外的任何更改。 PUT /status 对子资源的请求仅验证自定义资源的状态节。 PUT/ POST/ PATCH 请求自定义资源忽略更改状态节。 对 spec 节的任何更改都会增加 .metadata.generation 的值。 在code-generator生成代码时会生成，如下方法：\n// RedisClusterInterface has methods to work with RedisCluster resources. type RedisClusterInterface interface { Create(*v1alpha1.RedisCluster) (*v1alpha1.RedisCluster, error) Update(*v1alpha1.RedisCluster) (*v1alpha1.RedisCluster, error) UpdateStatus(*v1alpha1.RedisCluster) (*v1alpha1.RedisCluster, error) ...... } scale子资源 # 启用 scale 子资源后，将公开自定义资源的子资源 /scale。该 autoscaling/v1.Scale 对象作为有效负载发送 /scale。\n要启用 scale 子资源，CustomResourceDefinition 中需要定义以下值。\nSpecReplicasPath 在与之对应的自定义资源中定义 JSONPath Scale.Spec.Replicas。这是一个必需的值。.spec 只允许使用带点符号的 JSONPaths 。如果 SpecReplicasPath 自定义资源中没有值，则 /scale 子资源将在GET上返回错误。\nStatusReplicasPath 在与之对应的自定义资源中定义 JSONPath Scale.Status.Replicas。这是一个必需的值。.stutus 只允许使用带点符号的 JSONPaths 。如果 StatusReplicasPath 自定义资源中没有值，则子资源 /scale 中的状态副本值将默认为 0。\nLabelSelectorPath在与之对应的自定义资源中定义 JSONPath Scale.Status.Selector。这是一个可选值。必须将其设置为与 HPA 一起使用。.status 只允许使用带点符号的 JSONPaths 。如果 LabelSelectorPath 自定义资源中没有值，则子资源 /scale 中的状态选择器值将默认为空字符串。\n在以下示例中，启用了status 和 scale 子资源。\n将以下内容保存到redis-cluster-crd.yaml并创建 kubectl apply -f redis-cluster-crd.yaml：\napiVersion: apiextensions.k8s.io/v1beta1 kind: CustomResourceDefinition metadata: name: redisclusters.redis.middleware.hc.cn spec: group: redis.middleware.hc.cn versions: - name: v1alpha1 # Each version can be enabled/disabled by Served flag. served: true # One and only one version must be marked as the storage version. storage: true scope: Namespaced names: kind: RedisCluster singular: rediscluster listKind: RedisClusterList plural: redisclusters shortNames: - rec # 执行kubectl get all时会查到pod、service、该crd等属于all categories的资源对象 categories: - all subresources: # status enables the status subresource. status: {} scale: # specReplicasPath defines the JSONPath inside of a custom resource that corresponds to Scale.Spec.Replicas. specReplicasPath: .spec.replicas # statusReplicasPath defines the JSONPath inside of a custom resource that corresponds to Scale.Status.Replicas. statusReplicasPath: .status.replicas # labelSelectorPath defines the JSONPath inside of a custom resource that corresponds to Scale.Status.Selector. labelSelectorPath: .status.labelSelector 创建 CustomResourceDefinition 对象后，您可以创建自定义对象。\n如果您将以下 YAML 保存到 redis-cluster-cr.yaml：\napiVersion: redis.middleware.hc.cn/v1alpha1 kind: RedisCluster metadata: name: example000-redis-cluster namespace: kube-system spec: # 代表redis集群的个数 replicas: 6 # 代表是否进入维修状态 pause: true repository: library/redis # 镜像版本，便于后续多版本特化支持 version: 3.2.6 #redis集群升级策略 updateStrategy: # 升级类型为AutoReceive（自动分配,不用AssignStrategies）, AssignReceive（指定值分配，需要用AssignStrategies） type: AssignReceive pipeline: \u0026#34;100\u0026#34; assignStrategies: - slots: 2000 fromReplicas: nodeId1 - # 从nodeId3,nodeId4一共分配1000个卡槽 slots: 1000 # 多个nodeId用逗号分隔 fromReplicas: nodeId3,nodeId4 # redis 实例配置详情 pod: # 配置文件模板名 - configmap: example000-redis-cluster-config # 监控镜像 monitorImage: redis-exporter:v1 # 初始化镜像 initImage: redis-init:v1 # 中间件容器镜像 middlewareImage: redis-trib:3.2.6 并创建它：\nkubectl create -f redis-cluster-cr.yaml 然后在以下位置创建新的命名空间 RESTful API 端点：\n/apis/redis.middleware.hc.cn/v1alpha1/namespaces/kube-system/redisclusters/example000-redis-cluster/status 和\n/apis/redis.middleware.hc.cn/v1alpha1/namespaces/kube-system/redisclusters/example000-redis-cluster/scale 可以使用该 kubectl scale 命令缩放自定义资源。例如，以上创建的自定义资源的的 .spec.replicas 设置为 10：\n# kubectl get rec --all-namespaces NAMESPACE NAME DESIRED PAUSE AGE kube-system example000-redis-cluster 6 true 10h # kubectl scale --replicas=10 rec/example000-redis-cluster -nkube-system rediscluster.redis.middleware.hc.cn/example000-redis-cluster scaled # kubectl get rec --all-namespaces NAMESPACE NAME DESIRED PAUSE AGE kube-system example000-redis-cluster 10 true 10h # kubectl get rec example000-redis-cluster -n kube-system -o jsonpath=\u0026#39;{.spec.replicas}\u0026#39; 10 打印其他列 # 从 Kubernetes 1.11 开始，kubectl 使用服务器端打印。服务器决定 kubectl get 命令显示哪些列。您可以使用 CustomResourceDefinition 自定义这些列。下面的示例将输出 Spec、Replicas 和 Age 列。\n将 CustomResourceDefinition保存到 redis-cluster-crd.yaml。\napiVersion: apiextensions.k8s.io/v1beta1 kind: CustomResourceDefinition metadata: name: redisclusters.redis.middleware.hc.cn spec: group: redis.middleware.hc.cn versions: - name: v1alpha1 # Each version can be enabled/disabled by Served flag. served: true # One and only one version must be marked as the storage version. storage: true scope: Namespaced names: kind: RedisCluster singular: rediscluster listKind: RedisClusterList plural: redisclusters shortNames: - rec # 执行kubectl get all时会查到pod、service、该crd等属于all categories的资源对象 categories: - all additionalPrinterColumns: - name: DESIRED type: integer description: The number of statefulset managed by the this redisCluster JSONPath: .spec.replicas # boolean,date,integer,number,string - name: PAUSE type: boolean description: Whether this redisCluster\u0026#39;s grandson (pod) will not be managed by statefulset JSONPath: .spec.pause 创建 CustomResourceDefinition：\nkubectl create -f redis-cluster-crd.yaml 使用上面创建的 redis-cluster-cr.yaml 实例。\n调用服务器端打印：\nkubectl get rec --all-namespaces 请注意 NAME、NAMESPACE, DESIRED、PAUSE 和 AGE 在输出列，并且都被转成了大写字母：\n[root@master-192 redis-container]# kubectl get rec --all-namespaces NAMESPACE NAME DESIRED PAUSE AGE kube-system example000-redis-cluster 6 true 10h NAME和NAMESPACE 列是隐含的，不需要在 CustomResourceDefinition 中定义。\noperator中应用该特性 # 在golang编写的operator代码中创建该结构体：\n//创建CRD func CreateRedisClusterCRD(extensionCRClient *extensionsclient.Clientset) error { //add CustomResourceValidation due to guarantee redis operator work normally labelSelectorPath := \u0026#34;.status.labelSelector\u0026#34; replicasMinimum := float64(0) replicasMaximum := float64(50) replicasMultipleOf := float64(2) slotsMinimum := float64(1) slotsMaximum := float64(16384) assignStr := \u0026#34;AssignReceive\u0026#34; autoStr := \u0026#34;AutoReceive\u0026#34; assignJson, _ := json.Marshal(assignStr) autoJson, _ := json.Marshal(autoStr) crd := \u0026amp;v1beta1.CustomResourceDefinition{ ObjectMeta: metav1.ObjectMeta{ Name: \u0026#34;redisclusters.\u0026#34; + v1alpha1.SchemeGroupVersion.Group, }, Spec: v1beta1.CustomResourceDefinitionSpec{ Group: v1alpha1.SchemeGroupVersion.Group, Versions: []v1beta1.CustomResourceDefinitionVersion { { // Served is a flag enabling/disabling this version from being served via REST APIs Served: true, Name: v1alpha1.SchemeGroupVersion.Version, // Storage flags the version as storage version. There must be exactly one flagged as storage version Storage: true, }, }, Scope: v1beta1.NamespaceScoped, Names: v1beta1.CustomResourceDefinitionNames{ Kind: \u0026#34;RedisCluster\u0026#34;, ListKind: \u0026#34;RedisClusterList\u0026#34;, Plural: \u0026#34;redisclusters\u0026#34;, Singular: \u0026#34;rediscluster\u0026#34;, ShortNames: []string{\u0026#34;rec\u0026#34;}, Categories: []string{\u0026#34;all\u0026#34;}, }, Subresources: \u0026amp;v1beta1.CustomResourceSubresources { Status: \u0026amp;v1beta1.CustomResourceSubresourceStatus {}, Scale: \u0026amp;v1beta1.CustomResourceSubresourceScale { SpecReplicasPath: \u0026#34;.spec.replicas\u0026#34;, StatusReplicasPath: \u0026#34;.status.replicas\u0026#34;, LabelSelectorPath: \u0026amp;labelSelectorPath, }, }, AdditionalPrinterColumns: []v1beta1.CustomResourceColumnDefinition{ { Name: \u0026#34;DESIRED\u0026#34;, Type: \u0026#34;integer\u0026#34;, Description: \u0026#34;The number of statefulset managed by the this redisCluster\u0026#34;, JSONPath: \u0026#34;.spec.replicas\u0026#34;, }, { Name: \u0026#34;PAUSE\u0026#34;, Type: \u0026#34;boolean\u0026#34;, Description: \u0026#34;Whether this redisCluster\u0026#39;s grandson (pod) will not be managed by statefulset\u0026#34;, JSONPath: \u0026#34;.spec.pause\u0026#34;, }, { Name: \u0026#34;AGE\u0026#34;, Type: \u0026#34;date\u0026#34;, JSONPath: \u0026#34;.metadata.creationTimestamp\u0026#34;, }, }, Validation: \u0026amp;v1beta1.CustomResourceValidation { OpenAPIV3Schema: \u0026amp;v1beta1.JSONSchemaProps { Properties: map[string]v1beta1.JSONSchemaProps { \u0026#34;spec\u0026#34;: { Required: []string{\u0026#34;replicas\u0026#34;, \u0026#34;repository\u0026#34;, \u0026#34;version\u0026#34;}, Properties: map[string]v1beta1.JSONSchemaProps{ \u0026#34;pause\u0026#34;: { Type: \u0026#34;boolean\u0026#34;, }, \u0026#34;replicas\u0026#34;: { Type: \u0026#34;integer\u0026#34;, Minimum: \u0026amp;replicasMinimum, Maximum: \u0026amp;replicasMaximum, MultipleOf: \u0026amp;replicasMultipleOf, }, \u0026#34;updateStrategy\u0026#34;: { Type: \u0026#34;object\u0026#34;, Properties: map[string]v1beta1.JSONSchemaProps{ \u0026#34;type\u0026#34;: { Type: \u0026#34;string\u0026#34;, Enum: []v1beta1.JSON { { //这里必须是JSON格式的字符串 Raw: assignJson, }, { Raw: autoJson, }, }, }, \u0026#34;pipeline\u0026#34;: { Type: \u0026#34;string\u0026#34;, Pattern: `^([1-9][0-9]*){1,3}$`, }, \u0026#34;assignStrategies\u0026#34;: { Type: \u0026#34;array\u0026#34;, Items: \u0026amp;v1beta1.JSONSchemaPropsOrArray{ Schema: \u0026amp;v1beta1.JSONSchemaProps{ Type: \u0026#34;object\u0026#34;, Properties: map[string]v1beta1.JSONSchemaProps{ \u0026#34;slots\u0026#34;: { Type: \u0026#34;integer\u0026#34;, Minimum: \u0026amp;slotsMinimum, Maximum: \u0026amp;slotsMaximum, }, \u0026#34;fromReplicas\u0026#34;: { Type: \u0026#34;string\u0026#34;, Pattern: `^[a-z0-9,]{3,}$`, }, }, }, }, }, }, }, }, }, \u0026#34;pod\u0026#34;: { Type: \u0026#34;array\u0026#34;, Items: \u0026amp;v1beta1.JSONSchemaPropsOrArray { Schema: \u0026amp;v1beta1.JSONSchemaProps { Type: \u0026#34;object\u0026#34;, Required: []string{\u0026#34;replicas\u0026#34;, \u0026#34;repository\u0026#34;, \u0026#34;version\u0026#34;}, Properties: map[string]v1beta1.JSONSchemaProps{ \u0026#34;configmap\u0026#34;: { Type: \u0026#34;string\u0026#34;, }, \u0026#34;monitorImage\u0026#34;: { Type: \u0026#34;string\u0026#34;, }, \u0026#34;initImage\u0026#34;: { Type: \u0026#34;string\u0026#34;, }, \u0026#34;middlewareImage\u0026#34;: { Type: \u0026#34;string\u0026#34;, }, }, }, }, }, }, }, }, }, } _, err := extensionCRClient.ApiextensionsV1beta1().CustomResourceDefinitions().Create(crd) return err } 参考 # 官方Extend the Kubernetes API with CustomResourceDefinitions：\nhttps://kubernetes.io/docs/tasks/access-kubernetes-api/custom-resources/custom-resource-definitions/\nfeature-gates参数说明：\nhttps://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/\nCustomResourceDefinition中文文档：\nhttps://kubernetes.feisky.xyz/cha-jian-kuo-zhan/api/customresourcedefinition\nswagger和openAPI: 数据类型：\nhttps://www.breakyizhan.com/swagger/2969.html\n正则表达式：\nhttps://www.cnblogs.com/afarmer/archive/2011/08/29/2158860.html\n","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/kubernetes%E8%87%AA%E5%AE%9A%E4%B9%89%E8%B5%84%E6%BA%90%E5%AF%B9%E8%B1%A1%E9%AB%98%E7%BA%A7%E5%8A%9F%E8%83%BD/","section":"Posts","summary":"\u003cp\u003ekubernetes自定义资源对象再极大程度提高了API Server的可扩展性，让企业能够根据业务需求通过CRD编写controller或者operator来实现生产中各种特殊场景。随着k8s的版本升级，CRD的功能也越来越完善，下面对其中几点进行说明。\u003c/p\u003e","title":"kubernetes自定义资源对象高级功能","type":"posts"},{"content":"","date":"2019年10月18日","externalUrl":null,"permalink":"/tags/shell/","section":"Tags","summary":"","title":"Shell","type":"tags"},{"content":" 本文首发于微信公众号“我的小碗汤”，扫码文末二维码即可关注，欢迎一起交流！\nredis在容器化的过程中，涉及到纵向扩pod实例cpu、内存以及redis实例的maxmemory值，statefulset管理的pod需要重启。所以把redis集群的状态检查放到了健康检查中，依赖statefulset的原生能力（pod实例ready后才重启下一个，ready后endpoints controller将pod信息更新到endpoints资源对象中）,而没有在redis operator中写逻辑去判断。\n需要用redis-cli -h {redis实例IP} ping查看redis是否正常，同时用redis-cli -c -h {redis实例IP} -a {redis密码} cluster info输出的信息解析cluster_state的值是否为ok，以及cluster_known_nodes的值是否为1，判断redis集群是否正常；\n如果redis集群刚创建，cluster_known_nodes为1，cluster_state为fail;\n如果redis集群为纵向扩容(扩CPU、内存)升级重启，cluster_known_nodes不为1，cluster_state为ok时才认为集群正常，才能重启下一个pod。\n因为涉及到字符串相等判断，所以用以下这样判断：\nif [ \u0026#34;$cluster_known_nodes\u0026#34;x = \u0026#34;1\u0026#34;x ]; then ..... fi 但是判断一直有问题，如下图，在$a后面加个x，会变为在开头覆盖式的加a，结果就是判断结果不相等。\n把redis-cli -c -h {redis实例IP} -a {redis密码} cluster info执行的结果重定向到文件里。\nvi 1.txt查看文件，在vi里用set ff命令查看文件格式为unix，但是文件每一行后面都有一个^M的特殊字符，这就是问题所在了。\n最主要是通过cat都看不出来特殊字符的存在。\n手动把^M特殊字符删掉就好了。\n网上说^M是windows格式文本文件的换行符\\r\\n，可以用dos2unix命令转为unix格式。但是执行cluster info命令全程在linux中操作，而且重定向到文件中set ff命令看到也是unix格式。这点还是很费解。\n先用sed命令将^M换掉，试了sed \u0026rsquo;s/^M//g\u0026rsquo;没有用，所以选择用sed \u0026rsquo;s?\\r??g\u0026rsquo;替换，最终脚本如下。\nif语句的[[]]需要用bash执行，用sh执行会报错[[: not found\n#!/bin/bash #需要用redis-cli -h {redis实例IP} ping查看redis是否正常 #用redis-cli -c -h {redis实例IP} -a {redis密码} cluster info输出 #的信息解析cluster_state的值是否为ok，以及cluster_known_nodes的值是 #否为1，判断redis集群是否正常；如果redis集群刚创建，cluster_known_nodes #为1，cluster_state为fail;如果redis集群为纵向扩容(扩CPU、内存)升级重启 #cluster_known_nodes不为1，cluster_state为ok时才认为集群正常，才能重启 #下一个pod，改健康检查脚本旨在维护升级时redis集群状态，不在operator中维护 # 利用好statefulset一个实例ready后重启下一个pod的特性 pingres=$(redis-cli -h $(hostname) ping) # cluster_state:ok # cluster_slots_assigned:16384 # cluster_slots_ok:16384 # cluster_slots_pfail:0 # cluster_slots_fail:0 # cluster_known_nodes:6 # cluster_size:3 # cluster_current_epoch:15 # cluster_my_epoch:12 # cluster_stats_messages_sent:270782059 # cluster_stats_messages_received:270732696 pingres=$(echo \u0026#34;${pingres}\u0026#34; | sed \u0026#39;s?\\r??g\u0026#39;) if [[ \u0026#34;$pingres\u0026#34;x = \u0026#34;PONG\u0026#34;x ]]; then clusterinfo=$(redis-cli -c -h ${PODIP} cluster info) # redis-cli -c -h ${PODIP} cluster info output info include ^M(win \\n\\r) char lead to error, so use sed \u0026#39;s?\\r??g\u0026#39; clusterknownnodes=$(echo \u0026#34;${clusterinfo}\u0026#34; | grep cluster_known_nodes | sed \u0026#39;s?\\r??g\u0026#39; | awk -F \u0026#39;:\u0026#39; \u0026#39;{print $2}\u0026#39;) clusterstate=$(echo \u0026#34;${clusterinfo}\u0026#34; | grep cluster_state | sed \u0026#39;s?\\r??g\u0026#39; | awk -F \u0026#39;:\u0026#39; \u0026#39;{print $2}\u0026#39;) echo \u0026#34;clusterknownnodes: ${clusterknownnodes} --- clusterstate: ${clusterstate}\u0026#34; # [[ need run this script use /bin/bash instead of /bin/sh # if语句的[[]]需要用bash执行，用sh执行会报错[[: not found if [[ \u0026#34;${clusterknownnodes}\u0026#34;x = \u0026#34;1\u0026#34;x \u0026amp;\u0026amp; \u0026#34;${clusterstate}\u0026#34;x = \u0026#34;ok\u0026#34;x ]]; then echo \u0026#34;--1--\u0026#34; exit 0 elif [[ \u0026#34;${clusterknownnodes}\u0026#34;x != \u0026#34;1\u0026#34;x \u0026amp;\u0026amp; \u0026#34;${clusterstate}\u0026#34;x = \u0026#34;ok\u0026#34;x ]]; then echo \u0026#34;--2--\u0026#34; exit 0 # create redis cluster elif [[ \u0026#34;${clusterknownnodes}\u0026#34;x = \u0026#34;1\u0026#34;x \u0026amp;\u0026amp; \u0026#34;${clusterstate}\u0026#34;x != \u0026#34;ok\u0026#34;x ]]; then echo \u0026#34;--3--\u0026#34; exit 0 elif [[ \u0026#34;${clusterknownnodes}\u0026#34;x != \u0026#34;1\u0026#34;x \u0026amp;\u0026amp; \u0026#34;${clusterstate}\u0026#34;x != \u0026#34;ok\u0026#34;x ]]; then echo \u0026#34;--4--\u0026#34; exit 1 else echo \u0026#34;--5--\u0026#34; exit 1 fi else exit 1 fi 一般这种怪异的问题都是脚本里有特殊字符造成的，可以在脚本中set list显示特殊字符。当然windows上编辑过的脚本在linux上运行一般dos2unix test.sh这样转换一下最好，免的遇到麻烦。\n参考： # shell中括号的特殊用法 linux if多条件判断\nhttps://www.cnblogs.com/jjzd/p/6397495.html\n运行shell脚本时报错\u0026quot;[[ : not found\u0026quot;解决方法\nhttps://www.cnblogs.com/han-1034683568/p/7211392.html\n","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/%E4%B8%80%E6%AC%A1%E5%86%99shell%E8%84%9A%E6%9C%AC%E7%9A%84%E7%BB%8F%E5%8E%86%E8%AE%B0%E5%BD%95%E7%89%B9%E6%AE%8A%E5%AD%97%E7%AC%A6%E6%83%B9%E7%9A%84%E7%A5%B8/","section":"Posts","summary":"\u003cblockquote\u003e\n\u003cp\u003e本文首发于微信公众号“我的小碗汤”，扫码文末二维码即可关注，欢迎一起交流！\u003c/p\u003e","title":"一次写shell脚本的经历记录——特殊字符惹的祸","type":"posts"},{"content":" 正文 # kube-apiserver\n对外暴露了Kubernetes API。它是的 Kubernetes 核心控制层。它被设计为水平扩展，即通过部署更多实例来横向扩展。API Server 负责和 etcd 交互（其他组件不会直接操作 etcd，只有 API Server 这么做），是整个 kubernetes 集群的数据中心，所有的交互都是以 API Server 为核心的。API Server 提供了以下的功能：\n整个集群管理的 API 接口：所有对集群进行的查询和管理都要通过 API 来进行。\n集群内部各个模块之间通信的枢纽：所有模块之间并不会互相调用，而是通过和 API Server 打交道来完成各自的工作。\n集群安全控制：API Server 提供的验证和授权保证了整个集群的安全。\nkube-controller-manager和kube-scheduler的高可用选主机制\nhttps://blog.csdn.net/weixin_39961559/article/details/81877056\n在k8s的组件中，其中有kube-scheduler和kube-controller-manager两个组件是有leader选举的，这个选举机制是k8s对于这两个组件的高可用保障。需要\u0026ndash;leader-elect=true启动参数。即正常情况下kube-scheduler或kube-manager-controller组件的多个副本只有一个是处于业务逻辑运行状态，其它副本则不断的尝试去获取锁，去竞争leader，直到自己成为leader。如果正在运行的leader因某种原因导致当前进程退出，或者锁丢失，则由其它副本去竞争新的leader，获取leader继而执行业务逻辑。\n在K8s中， 通过创建资源对象（当前的实现中实现了 ConfigMap 和 Endpoint 两种类型的资源）来维护锁的状态。这两种资源对象存在etcd里，也可以说是用etcd来实现的。\n分布式锁一般实现原理就是大家先去抢锁，抢到的成为 leader ，然后 leader 会定期更新锁的状态，声明自己的活动状态，不让其他人把锁抢走。K8s 的资源锁也类似，抢到锁的节点会将自己的标记。设为锁的持有者，其他人则需要通过对比锁的更新时间和持有者来判断自己是否能成为新的 leader ，而 leader 则可以通过更新RenewTime来确保持续保有该锁。\n主要调用client-go包中的：\nk8s.io/client-go/tools/leaderelection\n总共有7个leader选举参数：\nlock-object-namespace和lock-object-name是锁对象的命名空间和名称。\nleader-elect表示该组件运行时是否需要leader选举(如果集群中运行多副本，需要设置该选项为true，否则每个副本都将参与实际工作)。\nleader-elect-lease-duration为资源锁租约观察时间，如果其它竞争者在该时间间隔过后发现leader没更新获取锁时间，则其它副本可以认为leader已经挂掉不参与工作了，将重新选举leader。\nleader-elect-renew-deadline leader在该时间内没有更新则失去leader身份。\nleader-elect-retry-period为其它副本获取锁的时间间隔(竞争leader)和leader更新间隔。\nleader-elect-resource-lock是k8s分布式资源锁的资源对象，目前只支持endpoints和configmaps。\netcd\nEtcd使用的是raft一致性算法来实现的，是一款分布式的一致性KV存储，主要用于共享配置和服务发现。用于 Kubernetes 的后端存储。所有集群数据都存储在此处，ETCD在k8s技术栈的地位，就仿佛数据库（Mysql、Postgresql或oracle等）在Web应用中的地位，它存储了k8s集群中所有的元数据（以key-value的方式）。整个kubernetes系统需要用到etcd用来协同和存储配置的有：\n网络插件flannel、calico等网络插件也需要用到etcd存储网络的配置信息\nkubernetes本身，包括各种对象的状态和元信息配置\n**注意：**flannel操作etcd使用的是v2的API，而kubernetes操作etcd使用的v3的API，所以在下面我们执行etcdctl的时候需要设置ETCDCTL_API环境变量，该变量默认值为2。\nK8s中所有元数据的增删改查都是由kube-apiserver来执行的。ETCD中key值通过观察可以简单得出下面几个规律：\nk8s主要把自己的数据注册在/registry/前缀下面（在ETCD-v3版本后没有了目录的概念，只能一切皆前缀了）。通过观察k8s中deployment、namespace、pod等在ETCD中的表示，可以知道这部分资源的key的格式为/registry/{k8s对象}/{命名空间}/{具体实例名}。\nkube-controller-manager\nkube-controller-manager运行控制器，它们是处理集群中常规任务的后台线程。逻辑上，每个控制器是一个单独的协程。用于监视 apiserver 暴露的集群状态，并且不断地尝试把当前状态向集群的目标状态迁移。为了避免频繁查询 apiserver，apiserver 提供了 watch 接口用于监视资源的增加删除和更新，client-go 对此作了抽象，封装一层 informer 来表示本地 apiserver 状态的 cache 。\n参考:\nhttps://blog.csdn.net/huwh_/article/details/75675761\n这些控制器包括:\n节点控制器（node-controller）: kubelet在启动时会通过API Server注册自身的节点信息，并定时向API Server汇报状态信息，API Server接收到信息后将信息更新到etcd中。Node Controller通过API Server实时获取Node的相关信息，实现管理和监控集群中的各个Node节点的相关控制功能。\n副本控制器（Replication Controller）: 负责维护系统中每个副本控制器对象正确数量的 Pod。副本控制器的作用即保证集群中一个RC所关联的Pod副本数始终保持预设值。只有当Pod的重启策略是Always的时候（RestartPolicy=Always），副本控制器才会管理该Pod的操作（创建、销毁、重启等）。\n**服务帐户和令牌控制器（ServiceAccount Controller ）: **为新的命名空间创建默认帐户和 API 访问令牌。\n**资源配额管理控制器ResourceQuota Controller：**资源配额管理确保指定的资源对象在任何时候都不会超量占用系统物理资源。支持三个层次的资源配置管理：\n容器级别：对CPU和Memory进行限制;\nPod级别：对一个Pod内所有容器的可用资源进行限制;\nNamespace级别：包括Pod数量、Replication Controller数量、Service数量、ResourceQuota数量、Secret数量、可持有的PV（Persistent Volume）数量\nNamespace Controller：用户通过API Server可以创建新的Namespace并保存在etcd中，NamespaceController定时通过API Server读取这些Namespace信息。如果Namespace被API标记为优雅删除（即设置删除期限，DeletionTimestamp）,则将该Namespace状态设置为“Terminating”,并保存到etcd中。同时Namespace Controller删除该Namespace下的ServiceAccount、RC、Pod等资源对象。\nService Controller：属于kubernetes集群与外部的云平台之间的一个接口控制器。Service Controller监听Service变化，如果是一个LoadBalancer类型的Service，则确保外部的云平台上对该Service对应的LoadBalancer实例被相应地创建、删除及更新路由转发表。\ndeployment controller：用来替代以前的ReplicationController来方便的管理应用。只需要在 Deployment 中描述您想要的目标状态是什么，Deployment controller 就会帮您将 Pod 和ReplicaSet 的实际状态改变到您的目标状态。您可以定义一个全新的 Deployment 来创建 ReplicaSet 或者删除已有的 Deployment 并创建一个新的来替换。\n定义Deployment来创建Pod和ReplicaSet\n滚动升级和回滚应用\n扩容和缩容\n暂停和运行Deployment\nstatefulset controller：StatefulSet是为了解决有状态服务的问题（对应Deployments和ReplicaSets是为无状态服务而设计），其应用场景包括：\n稳定的持久化存储，即Pod重新调度后还是能访问到相同的持久化数据，基于PVC来实现;\n稳定的网络标志，即Pod重新调度后其PodName和HostName不变，基于Headless Service（即没有Cluster IP的Service）来实现。StatefulSet中每个Pod的DNS格式为：\nstatefulSetPodName-{0..N-1}.serviceName.namespace.svc.cluster.local 有序部署，有序扩展，即Pod是有顺序的，在部署或者扩展的时候要依据定义的顺序依次依次进行（即从0到N-1，在下一个Pod运行之前所有之前的Pod必须都是Running和Ready状态），基于init containers来实现；\n有序收缩，有序删除（即从N-1到0）\ndaemonset controller：DaemonSet确保全部（或者一些）Node 上运行一个 Pod 的副本。当有 Node 加入集群时，也会为他们新增一个 Pod 。当有 Node 从集群移除时，这些 Pod 也会被回收。删除 DaemonSet 将会删除它创建的所有 Pod。\nHorizontal Pod Autoscaling：仅适用于Deployment和ReplicaSet，在V1版本中仅支持根据Pod的CPU利用率扩所容，在v1alpha版本中，支持根据内存和用户自定义的metric扩缩容。\npersistentvolume-binder：定期同步磁盘卷挂载信息，负责pv和pvc的绑定。\nEndpoints controller：表示了一个Service对应的所有Pod副本的访问地址，而EndpointsController负责生成和维护所有Endpoints对象的控制器。它负责监听Service和对应的Pod副本的变化。\n如果监测到Service被删除，则删除和该Service同名的Endpoints对象；\n如果监测到新的Service被创建或修改，则根据该Service信息获得相关的Pod列表，然后创建或更新Service对应的Endpoints对象;\n如果监测到Pod的事件，则更新它对应的Service的Endpoints对象。\nkube-proxy进程获取每个Service的Endpoints，实现Service的负载均衡功能。\n以上只是部分控制器，都是一个独立的协程，被controller-manager这个进程所管理。\nStatefulset和Deployment的区别\nDeployment用于部署无状态服务，StatefulSet用来部署有状态服务。\n如果部署的应用满足以下一个或多个部署需求，则建议使用StatefulSet。\n稳定的、唯一的网络标识;\n稳定的、持久的存储;\n有序的、优雅的部署和伸缩;\n有序的、优雅的删除和停止;\n有序的、自动的滚动更新;\n实现固定的Pod IP方案, 可以优先考虑基于StatefulSet\n**稳定的：**主要是针对Pod发生re-schedule后仍然要保持之前的网络标识和持久化存储。这里所说的网络标识包括hostname、集群内DNS中该Pod对应的A Record，并不能保证Pod re-schedule之后IP不变。要想保持Pod IP不变，我们可以借助稳定的Pod hostname定制IPAM获取固定的Pod IP。借助StatefulSet的稳定的唯一的网络标识特性，我们能比较轻松的实现Pod的固定IP需求，然后如果使用Deployment，那么将会复杂的多，你需要考虑滚动更新的过程中的参数控制(maxSurge、maxUnavailable)、每个应用的IP池预留造成的IP浪费等等问题。\n**存储：**StatefulSet对应Pod的存储最好通过StorageClass来动态创建：每个Pod都会根据StatefulSet中定义的VolumeClaimTemplate来创建一个对应的PVC，然后PVS通过StorageClass自动创建对应的PV，并挂载给Pod。所以这种方式，需要事先创建好对应的StorageClass。当然，你也可以通过预先由管理员手动创建好对应的PV，只要能保证自动创建的PVC能和这些PV匹配上。\n为了数据安全，当删除StatefulSet中Pods或者对StatefulSet进行缩容时，Kubernetes并不会自动删除StatefulSet对应的PV，而且这些PV默认也不能被其他PVC Bound。当你确认数据无用之后再手动去删除PV的时候，数据是否删除取决于PV的ReclaimPolicy配置。Reclaim Policy支持以下三种：\nRetain，意味着需要你手动清理；\nRecycle，等同于rm -rf /thevolume/*\nDelete，默认值，依赖于后端的存储系统自己实现。\n部署和伸缩时与Deployment的区别\n当部署有N个副本的StatefulSet应用时，严格按照index从0到N-1的递增顺序创建，下一个Pod创建必须是前一个Pod Ready为前提。\n当删除有N个副本的StatefulSet应用时，严格按照index从N-1到0的递减顺序删除，下一个Pod删除必须是前一个Pod shutdown并完全删除为前提。\n当扩容StatefulSet应用时，每新增一个Pod必须是前一个Pod Ready为前提。\n当缩容StatefulSet应用时，没删除一个Pod必须是前一个Pod shutdown并成功删除为前提。\nkube-scheduler\nkube-scheduler监视没有分配节点的新创建的 Pod，选择一个节点供他们运行。调度节点分配主要可以分为预选（Predicates）与优选（Priorities）两个环节：\n预选\n根据配置的PredicatesPolicies（默认为DefaultProvider中定义的default predicates policies集合）过滤掉那些不满足这些Policies 的 Node，预选的输出作为优选的输入；\n优选\n根据配置的PrioritiesPolicies（默认为DefaultProvider中定义的default priorities policies集合）给预选后的 Node 进行打分排名，得分最高的 Node 即作为最适合的 Node ，该 Pod 就绑定（Bind）到这个 Node 。\n**注：**如果经过优选将 Node 打分排名后，有多个 Node 并列得分最高，那么kube-scheduler将随机从中选择一个 Node 作为目标 Node 。\n预选阶段算法\nNoDiskConflict：评估是否存在volume冲突。如果该 volume 已经 mount 过了，k8s可能会不允许重复mount(取决于volume类型)；\nNoVolumeZoneConflict：评估该节点上是否存在 Pod 请求的 volume；\nPodFitsResources：检查节点剩余资源(CPU、内存)是否能满足 Pod 的需求。剩余资源=总容量-所有 Pod 请求的资源；\nMatchNodeSelector：判断是否满足 Pod 设置的 NodeSelector；\nCheckNodeMemoryPressure：检查 Pod 是否可以调度到存在内存压力的节点；\nCheckNodeDiskPressure：检查 Pod 是否可以调度到存在硬盘压力的节点；\n优选阶段算法\n依次计算该 Pod 运行在每一个 Node 上的得分。主要算法有：\nLeastRequestedPriority：最低请求优先级，即 Node 使用率越低，得分越高；\nBalancedResourceAllocation：资源平衡分配，即CPU/内存配比合适的 Node 得分更高；\nSelectorSpreadPriority：尽量将同一 RC/Replica 的多个 Pod 分配到不同的 Node 上；\nCalculateAntiAffinityPriority：尽量将同一 Service 下的多个相同 Label 的 Pod 分配到不同的 Node；\nImageLocalityPriority：Image本地优先，Node 上如果已经存在 Pod 需要的镜像，并且镜像越大，得分越高，从而减少 Pod 拉取镜像的开销(时间)；\nNodeAffinityPriority：根据亲和性标签进行选择；\n默认的预选、优选调度算法远不止以上这些。可以通过kube-scheduler的启动参数中加policy-config-file文件、configmaps（过时）、或者\u0026ndash;config指定调度器用哪些预选、优选算法。\n调度算法的扩展\n如果kube-scheduler提供的调度算法不满足调度要求，也可以自己开发扩展调度器，在kube-scheduler启动参数的policy-config中指定扩展调度器的地址，包括（预选接口、优选接口、优先级抢占，pod和node绑定的Bind接口）。\n扩展调度器示例代码：\nhttps://github.com/liabio/k8s-scheduler-extender-example\n由于默认调度器kube-scheduler需要调用扩展调度程序kube-scheduler-extender，故需要在kube-scheduler的启动参数里配置扩展调度器的地址。需要在master节点主机的/etc/kubernetes目录下的scheduler.yaml中配置如下内容：（static pod方式部署的kube-scheduler不能用configmaps的方式挂载配置文件）\napiVersion: kubescheduler.config.k8s.io/v1alpha1 kind: KubeSchedulerConfiguration algorithmSource: policy: file: path: /etc/kubernetes/scheduler-policy.json clientConnection: kubeconfig: /etc/kubernetes/scheduler.conf leaderElection: leaderElect: true 主要配置是否启用选举机制，以及与API Server交互时认证用的scheduler.conf文件地址，调度策略选择用的scheduler-policy.json：\n{ \u0026#34;kind\u0026#34;: \u0026#34;Policy\u0026#34;, \u0026#34;apiVersion\u0026#34;: \u0026#34;v1\u0026#34;, \u0026#34;predicates\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;NoVolumeZoneConflict\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;MatchInterPodAffinity\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;NoDiskConflict\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;GeneralPredicates\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;PodToleratesNodeTaints\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;CheckVolumeBinding\u0026#34; } ], \u0026#34;priorities\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;SelectorSpreadPriority\u0026#34;, \u0026#34;weight\u0026#34;: 1 }, { \u0026#34;name\u0026#34;: \u0026#34;InterPodAffinityPriority\u0026#34;, \u0026#34;weight\u0026#34;: 1 }, { \u0026#34;name\u0026#34;: \u0026#34;LeastRequestedPriority\u0026#34;, \u0026#34;weight\u0026#34;: 1 }, { \u0026#34;name\u0026#34;: \u0026#34;NodeAffinityPriority\u0026#34;, \u0026#34;weight\u0026#34;: 1 }, { \u0026#34;name\u0026#34;: \u0026#34;BalancedResourceAllocation\u0026#34;, \u0026#34;weight\u0026#34;: 1 }, { \u0026#34;name\u0026#34;: \u0026#34;NodePreferAvoidPodsPriority\u0026#34;, \u0026#34;weight\u0026#34;: 10000 }, { \u0026#34;name\u0026#34;: \u0026#34;TaintTolerationPriority\u0026#34;, \u0026#34;weight\u0026#34;: 1 } ], \u0026#34;extenders\u0026#34;: [ { \u0026#34;urlPrefix\u0026#34;: \u0026#34;http://kube-scheduler-extender:80/scheduler\u0026#34;, \u0026#34;filterVerb\u0026#34;: \u0026#34;predicates/middleware_predicate\u0026#34;, \u0026#34;prioritizeVerb\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;preemptVerb\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;bindVerb\u0026#34;: \u0026#34;bind\u0026#34;, \u0026#34;weight\u0026#34;: 1, \u0026#34;enableHttps\u0026#34;: false, \u0026#34;nodeCacheCapable\u0026#34;: false } ], \u0026#34;hardPodAffinitySymmetricWeight\u0026#34;: 10, \u0026#34;alwaysCheckAllPredicates\u0026#34;: false } 里面指定了默认调度器用到的预选、优选算法，以及调用扩展调度器的service地址，预选和Bind接口URI。\n在/etc/kubernetes/manifests目录下的kube-scheduler.yaml中启动参数中加\u0026ndash;config=/etc/kubernetes/scheduler.yaml，该文件通过hostPath的方式挂载到容器内。\nDNS\nkube-dns这个插件是官方推荐安装的。通过将 Service 注册到 DNS 中，k8s 可以为我们提供一种简单的服务注册发现与负载均衡方式。\nkube-dns内部通过监听services和endpoints的变更事件将域名和IP对应信息同步到本地缓存。比如服务 a 访问服务 b，dns解析依赖a容器内 /etc/resolv.conf 文件的配置\ncat/etc/resolv.conf nameserver 10.233.0.3 search default.svc.cluster.local svc.cluster.localcluster.local 这个文件中，配置的 DNS Server，一般就是 K8S 中，kubedns 的 Service 的 ClusterIP，这个IP是虚拟IP，无法ping。\n[root@node4 user1]#kubectl get svc -n kube-system NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kube-dns ClusterIP 10.233.0.3 53/UDP,53/TCP 270d kubernetes-dashboard ClusterIP 10.233.22.223 443/TCP 124d 所有域名的解析，其实都要经过 kubedns 的虚拟IP 10.233.0.3 ，负载到某一个kube-dns pod上去解析。如果不能解析，则会去kube-dns pod所在的主机上的dns服务（/etc/resolv.conf）做解析。Kubernetes 启动的容器自动将 DNS 服务器包含在容器内的/etc/resolv.conf 中。\n域名格式如下：\nstatefulset一般使用Headless Service，如statefulset名为test，创建2个pod，则域名为test-0.test.kube-system.svc.cluster.local和test-1.test.kube-system.svc.cluster.local\n节点组件\n节点组件在每个节点上运行，维护运行的 Pod 并提供Kubernetes 运行时环境。kubelet一般作为二进制运行到每个k8s节点；kube-proxy作为daemonset pod运行到每个k8s节点。\nkubelet\n在kubernetes集群中，每个Node节点都会启动kubelet进程，用来处理Master节点下发到本节点的任务，管理Pod和其中的容器。kubelet会在API Server上注册节点信息，定期向Master汇报节点资源使用情况，并通过cAdvisor监控容器和节点资源。\npod被调度到kubelet所在节点时，调用CNI（Docker 运行或通过 rkt)运行 Pod 的容器;\n周期性的对容器生命周期进行探测。（健康检查readness-隔离、liveness-重启）;\n检查节点状态，将节点的状态报告给kube-apiserver;\n容器监控所在节点的资源使用情况，并定时向 kube-apiserver报告。知道整个集群所有节点的资源情况，对于 pod 的调度和正常运行至关重要。kubelet 使用cAdvisor进行资源使用率的监控。\nkube-proxy\nhttps://blog.csdn.net/qq_21816375/article/details/86310844\nservice是一组pod的服务抽象，相当于一组pod的负载均衡器，负责将请求分发给对应的pod。service会提供一个clusterIP。kube-proxy的作用主要是负责service的实现，具体来说，就是实现了内部请求到service和外部的从node port向service的访问，转发到后端某个pod。\n举个例子，现在有podA，podB，podC和serviceAB。serviceAB是podA，podB的服务抽象(service)。那么kube-proxy的作用就是可以将某一个发往（如podC发起的请求）向serviceAB的请求，进行转发到service所代表的一个具体pod(podA或者podB)上。请求的分配方法一般分配是采用轮询方法进行分配。\nkube-proxy提供了三种负载均衡器（LB）模式: 一种是基于用户态的模式userspace, 一种是iptables模式，一种是ipvs模式。\nuserspace：是以socket的方式实现代理的，userspace这种模式最大的问题是，service的请求会先从用户空间进入内核iptables，然后再回到用户空间，由kube-proxy完成后端Endpoints的选择和代理工作，这样流量从用户空间进出内核带来的性能损耗是不可接受的；\niptables mode：因为使用iptable NAT来完成转发，也存在不可忽视的性能损耗。另外，如果集群中存在上万的Service/Endpoint，那么Node上的iptables rules将会非常庞大，性能还会再打折扣；\nIPVS 模式：工作原理其实跟 iptables 模式类似，当我们创建了前面的Service 之后，kube-proxy首先会在宿主机上创建一个虚拟网卡（kube-ipvs0）并为他分配service VIP作为IP地址，kube-proxy会通过linux的IPVS模块为这个IP设置三个虚拟主机（后端的三个POD IP），使用轮询作为LB策略（ipvsadm命令查看），IPVS模块会负责请求的转发。\n以下截图来自于极客时间张磊的课程描述：\niptables模式和ipvs模式的对比\n服务暴露方式\nhttp://dockone.io/article/4884\nNodePort\nNodePort服务是引导外部流量到你的服务的最原始方式。可以通过访问集群内的每个NodeIP:NodePort的方式，访问到对应Service后端的Endpoint。在所有节点（虚拟机）上开放一个特定端口，任何发送到该端口的流量都被转发到对应服务。\nNodePort 服务的 YAML 文件类似如下：\napiVersion: v1 kind: Service metadata: name: my-nodeport-service selector: app: my-app spec: type: NodePort ports: - name: http port: 80 targetPort: 80 nodePort: 30036 protocol: TCP NodePort 服务主要有两点区别于普通的“ClusterIP”服务。第一，它的类型是“NodePort”。有一个额外的端口，称为 nodePort，它指定节点上开放的端口值。如果你不指定这个端口，系统将选择一个随机端口。\n何时使用这种方式？\n这种方法有许多缺点：\n每个端口只能是一种服务\n端口范围只能是 30000-32767\n如果节点/VM 的 IP 地址发生变化，你需要能处理这种情况。\n基于以上原因，我不建议在生产环境上用这种方式暴露服务。如果你运行的服务不要求一直可用，或者对成本比较敏感，你可以使用这种方法。这样的应用的最佳例子是 demo 应用，或者某些临时应用。\nhostNetwork # 这种方式在创建pod时的yaml中spec.hostNetwork: true指定走主机网络，这种方式pod使用的端口必须是宿主机上没有被占用的端口。外部可以直接通过pod所在宿主机IP:Pod端口访问。\nLoadBalancer\n这也是用来对集群外暴露服务的，不同的是这需要云服务商的支持，比如亚马逊等。这个方式的最大缺点是每一个用 LoadBalancer 暴露的服务都会有它自己的 IP 地址，每个用到的 LoadBalancer 都需要付费，这是非常昂贵的。\nIngress\ningress配置一种路由转发规则，ingress controller会根据ingress中的规则，生成路由转发配置。如nginx-ingress-controller，控制循环会检测ingress对象的添加，通过其规则和service、pod信息生成nginx的配置，通过nginx实现对外服务和负载均衡。\npod创建流程\n1、客户端提交创建请求，通过API Server的Restful API，或者用kubectl命令行工具。支持的数据类型包括JSON和YAML。\n2、API Server处理用户请求，存储Pod数据到etcd。\n3、kube-scheduler通过API Server查看未绑定的Pod。尝试为Pod分配主机。\n4、kube-scheduler通过预选算法过滤掉不符合要求的主机。比如Pod指定了所需要的资源量，那么可用资源比Pod需要的资源量少的主机会被过滤掉，端口被占用的也被过滤掉；\n5、kube-scheduler通过优选算法给主机打分，对预选筛选出的符合要求的主机进行打分，在主机打分阶段，调度器会考虑一些整体优化策略，比如把一个deployment类型的pod分布到不同的主机上，使得资源均衡；或者将两个亲和的服务分配到同一个主机上。\n6、选择主机：选择打分最高的主机，进行binding（调用apiserver将pod和node绑定）操作，结果存储到etcd中。\n7、kubelet监听Api Server，根据调度结果执行Pod创建操作：绑定成功后，scheduler会调用API Server的API在etcd中创建一个bound pod对象，描述在一个工作节点上绑定运行的所有pod信息。运行在每个工作节点上的kubelet也会定期与etcd同步bound pod信息，一旦发现应该在该工作节点上运行的bound pod对象没有更新，则调用Docker API创建并启动pod内的容器。\n8、kubelet调用CNI（Docker 运行或通过 rkt)运行 Pod 的容器。并周期性的对容器生命周期进行探测。（健康检查readness-隔离、liveness-重启）\n各组件基本都是通过API Server提供的list-watch API进行监听资源对象变化，进行自己的控制循环，这些核心功能都被封装到了client-go包中。我们可以根据自己的需求，通过CRD编写controller、operator进行自己的控制循环逻辑、运维自动化部署，很轻松的扩展k8s能力。\n","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8k8s%E5%BF%85%E5%AD%A6%E5%BF%85%E4%BC%9A%E7%9F%A5%E8%AF%86%E6%A2%B3%E7%90%86/","section":"Posts","summary":"\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003ekube-apiserver\u003c/strong\u003e\u003c/p\u003e","title":"史上最全k8s必学必会知识梳理","type":"posts"},{"content":" 正文 # Kubernetes 自带了一个默认调度器kube-scheduler，其内置了很多节点预选和优选的调度算法，一般调度场景下可以满足要求。但是在一些特殊场景下，默认调度器不能满足我们复杂的调度需求。我们就需要对调度器进行扩展，以达到调度适合业务场景的目的。\n背景 # 中间件redis容器化后，需要两主不能在同一个节点上，一对主从不能在同一节点上；elasticsearch容器化后，两个data实例不能在同一节点上。在这类场景下，默认调度器内置的预选、优选算法不能满足需求，我们有以下三种选择：\n将新的调度算法添加到默认调度程序中，并重新编译镜像，最终该镜像运行的实例作为kubernetes集群调度器；\n参考kube-scheduler实现满足自己业务场景的调度程序，并编译镜像，将该程序作为独立的调度器运行到kubernetes集群内，需要用该调度器调度的pod实例，在spec.schedulerName里指定该调度器；\n实现“调度扩展程序“：默认调度器kube-scheduler在进行预选时会调用该扩展程序进行过滤节点；在优选时会调用该扩展程序进行给节点打分，或者在bind操作时，调用该扩展器进行bind操作。\n对上述三种方式进行评估：\n第一种：将自己的调度算法添加到默认调度器kube-scheduler中，对原生代码侵入性较高，而且随着kubernetes版本升级，维护成本也较高；\n第二种：默认调度器里内置了很多优秀调度算法，如：检查节点资源是否充足；端口是否占用；volume是否被其他pod挂载；亲和性；均衡节点资源利用等，如果完全使用自己开发的调度器程序，可能在达到了实际场景调度需求同时，失去更佳的调度方案，除非集成默认调度器中的算法到自己独立调度程序中，但这无疑是不现实的；\n第三种：通过启动参数的policy配置，选用某些默认调度器中的预选、优选调度算法的同时，也可以调用外部扩展调度程序的算法，计算得到最优的调度节点，无需修改kube-scheduler代码，只需要在启动参数中增加配置文件即可将默认调度程序和扩展调度程序相互关联。\n可以参考：\nhttps://github.com/kubernetes/community/blob/master/contributors/design-proposals/scheduling/scheduler_extender.md\n故采用第三种：实现扩展调度程序的方案。\n整体架构 # kube-scheduler在调度pod实例时，首先获取到Node1、Node2、Node3三个节点信息，进行默认的预选阶段，筛选满足要求的节点，其次再调用扩展程序中的预选算法，选出剩下的节点，假设预选阶段Node3上资源不足被过滤掉，预选结束后只剩Node1和Node2；Node1和Node2进入kube-scheduler默认的优选阶段进行节点打分，其次再调用扩展调度程序中的优选算法进行打分，kube-scheduler会将所有算法的打分结果进行加权求和，获得分数最高的节点作为pod最终bind节点，然后kube-scheduler调用apiserver进行bind操作。\n实现步骤 # 实现扩展调度程序代码 # 编写扩展调度器程序代码，根据实际业务调度场景编写预选逻辑、优选逻辑：\n实现预选接口，入参为schedulerapi.ExtenderArgs，出参为schedulerapi.ExtenderFilterResult：\n实现优选接口，入参为schedulerapi.ExtenderArgs，出参为schedulerapi.HostPriorityList：\n暴露http接口：\n参考：\nhttps://github.com/ll837448792/k8s-scheduler-extender-example\n默认调度器部署 # 由于kubernetes集群内已经有了一个名为default-scheduler的默认调度器，为了不影响集群正常调度功能，下面会创建一个名为my-kube-scheduler的调度器，这个调度器和default-scheduler除了启动参数不一样外，镜像无差别。\n1、创建一个名为my-scheduler-config的configmaps，data下的config.yaml文件指定了调度器的一些参数，包括leader选举，调度算法策略的选择（指定另一个configmaps），以及指定调度器的名称为my-kube-scheduler。\n相应的创建一个my-scheduler-policy的configmaps，里面指定了选择哪些预选、优选策略，以及外部扩展调度程序的urlPrefix、扩展预选URI、扩展优选URI、扩展pod优先级抢占URI、扩展bind URI、扩展优选算法的权重等。\n以保证my-kube-scheduler和扩展调度程序的通信。\napiVersion: v1 kind: ConfigMap metadata: name: my-scheduler-config namespace: kube-system data: config.yaml: | apiVersion: kubescheduler.config.k8s.io/v1alpha1 kind: KubeSchedulerConfiguration schedulerName: my-kube-scheduler algorithmSource: policy: configMap: namespace: kube-system name: my-scheduler-policy leaderElection: leaderElect: false lockObjectName: my-kube-scheduler lockObjectNamespace: kube-system --- apiVersion: v1 kind: ConfigMap metadata: name: my-scheduler-policy namespace: kube-system data: policy.cfg : | { \u0026#34;kind\u0026#34; : \u0026#34;Policy\u0026#34;, \u0026#34;apiVersion\u0026#34; : \u0026#34;v1\u0026#34;, \u0026#34;predicates\u0026#34; : [ {\u0026#34;name\u0026#34; : \u0026#34;PodFitsHostPorts\u0026#34;}, {\u0026#34;name\u0026#34; : \u0026#34;PodFitsResources\u0026#34;}, {\u0026#34;name\u0026#34; : \u0026#34;NoDiskConflict\u0026#34;}, {\u0026#34;name\u0026#34; : \u0026#34;MatchNodeSelector\u0026#34;}, {\u0026#34;name\u0026#34; : \u0026#34;HostName\u0026#34;} ], \u0026#34;priorities\u0026#34; : [ {\u0026#34;name\u0026#34; : \u0026#34;LeastRequestedPriority\u0026#34;, \u0026#34;weight\u0026#34; : 1}, {\u0026#34;name\u0026#34; : \u0026#34;BalancedResourceAllocation\u0026#34;, \u0026#34;weight\u0026#34; : 1}, {\u0026#34;name\u0026#34; : \u0026#34;ServiceSpreadingPriority\u0026#34;, \u0026#34;weight\u0026#34; : 1}, {\u0026#34;name\u0026#34; : \u0026#34;EqualPriority\u0026#34;, \u0026#34;weight\u0026#34; : 1} ], \u0026#34;extenders\u0026#34; : [{ \u0026#34;urlPrefix\u0026#34;: \u0026#34;http://10.168.107.12:80/scheduler\u0026#34;, \u0026#34;filterVerb\u0026#34;: \u0026#34;predicates/always_true\u0026#34;, \u0026#34;prioritizeVerb\u0026#34;: \u0026#34;priorities/zero_score\u0026#34;, \u0026#34;preemptVerb\u0026#34;: \u0026#34;preemption\u0026#34;, \u0026#34;bindVerb\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;weight\u0026#34;: 1, \u0026#34;enableHttps\u0026#34;: false, \u0026#34;nodeCacheCapable\u0026#34;: false }], \u0026#34;hardPodAffinitySymmetricWeight\u0026#34; : 10 } 2、在my-kube-scheduler yaml文件中将configmaps：my-scheduler-config以文件的形式挂载到容器内/my-scheduler目录下，并在启动参数中指定\u0026ndash;config=/my-scheduler/config.yaml，使用和默认调度器一样的镜像。\n增加挂载：\n扩展调度器镜像制作和部署 # 1、编译扩展调度程序my-scheduler-extender镜像，以下为Dockerfile：\n推送my-scheduler-extender镜像到harbor：\n2、创建外部扩展程序my-scheduler-extender的deployment，如下为yaml描述：\napiVersion: apps/v1 kind: Deployment metadata: name: my-scheduler-extender namespace: kube-system labels: app: my-scheduler-extender spec: replicas: 1 selector: matchLabels: app: my-scheduler-extender template: metadata: labels: app: my-scheduler-extender spec: containers: - name: my-scheduler-extender image: 192.168.26.46/k8s-deploy/my-scheduler-extender:v1.0 imagePullPolicy: Always livenessProbe: httpGet: path: /version port: 80 readinessProbe: httpGet: path: /version port: 80 ports: - containerPort: 80 验证 # 查看my-kube-scheduler pod日志，加载到了policy里的extender信息，获取到了扩展调度器的接口地址：\n创建一个nginx的pod，指定schedulerName为my-kube-scheduler：\n查看扩展调度器pod日志，发现默认调度器会调用extender扩展调度器，如下为extender日志打印的入参、出参：\n从而可以通过编写扩展调度程序，对默认调度器的预选和优选算法进行扩展。\n参考\nhttps://github.com/kubernetes/community/blob/master/contributors/design-proposals/scheduling/scheduler_extender.md\nhttps://github.com/ll837448792/k8s-scheduler-extender-example\n","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/kubescheduler%E8%B0%83%E5%BA%A6%E6%89%A9%E5%B1%95/","section":"Posts","summary":"\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eKubernetes 自带了一个默认调度器kube-scheduler，其内置了很多节点预选和优选的调度算法，一般调度场景下可以满足要求。但是在一些特殊场景下，默认调度器不能满足我们复杂的调度需求。我们就需要对调度器进行扩展，以达到调度适合业务场景的目的。\u003c/p\u003e","title":"kube-scheduler调度扩展","type":"posts"},{"content":" 正文 # Operator 是 CoreOS 推出的旨在简化复杂有状态应用管理，它是一个感知应用状态的控制器，通过扩展 Kubernetes API 来自动创建、管理和配置应用实例。 Operator 基于 CRD 扩展资源对象，并通过控制器来保证应用处于预期状态。\n通过 Kubernetes API 观察集群的当前状态； 分析当前状态与期望状态的差别； 调用k8s API消除这些差别。 为什么使用crd # Kubernetes 目前已经成为了集群调度领域最炙手可热的开源项目之一 。其内置的 controller一般可以满足大多数使用场景，但对于很多定制化需求，其表达能力还是有限的。因此 Kubernetes 支持 Custom Resource Definition，也就是我们一直提到的 CRD。通过这一特性，用户可以自己定义资源类型，Kubernetes 会将其视为资源的一种，对其提供像内置资源对象一样的支持，这样的实现更加原生。CRD可以大大提高 Kubernetes 的扩展能力 ，以更原生的方式实现定制化要求。\noperator设计初衷 # 我们在管理应用时，会遇到无状态和有状态的应用。管理无状态的应用是相对来说比较简单的，但是有状态的应用则比较复杂。Operator 的设计旨在简化复杂有状态应用管理，其通过CRD扩展 Kubernetes API 来自动创建、管理和配置应用实例。其本质上是针对特定的场景去做有状态服务，或者说针对复杂应用场景去简化其运维管理的工具。\nOperator以deployment的形式部署到K8S中。部署完这个Operator之后，想要部署一个集群，其实很方便。因为不需要再去管理这个集群的配置信息了，只需要创建一个CRD，指定创建多少个节点，需要什么版本，Operator会监听该资源对象，创建出符合配置要求的集群，从而大大简化运维的难度和成本。\n开发不同中间件operator流程大体相同，下面以redis operator进行说明：\n首先准备 # 需要一个资源对象定义（CRD）yaml，operator代码中会根据该yaml去组装并创建CRD。 apiVersion: apiextensions.k8s.io/v1beta1 kind: CustomResourceDefinition metadata: name: redisclusters.redis.middleware.hc.cn spec: group: redis.middleware.hc.cn version: v1alpha1 scope: Namespaced names: kind: RedisCluster singular: rediscluster listKind: RedisClusterList plural: redisclusters shortNames: - rec 后面创建的该CRD类型的资源对象（CR），其kind为该yaml描述中spec.names.kind的值。CR相当于CRD的具体实现。（不同的operator，CRD、CR定义不同）；\n准备一个CR yaml文件，后面operator代码要根据该yaml结构在types.go中定义结构体。redis的CR yaml如下。operator最终会监听该CR，解析里面定义的节点数、版本号等参数，驱动做一些事情。 apiVersion: redis.middleware.hc.cn/v1alpha1 kind: RedisCluster metadata: name: example000-redis-cluster namespace: kube-system spec: # 代表redis集群的个数 replicas: 7 # 代表是否进入维修状态 pause: true # 是否删除crd以及redis集群 finalizers: foreground # 镜像地址 repository: library/redis # 镜像版本，便于后续多版本特化支持 version: 3.2.8 #redis集群升级策略 updateStrategy: # 升级类型为AutoReceive（自动分配,不用AssignStrategies）, AssignReceive（指定值分配，需要用AssignStrategies） type: AssignReceive pipeline: \u0026#34;100\u0026#34; assignStrategies: - slots: 2000 fromReplicas: nodeId1 - # 从nodeId3,nodeId4一共分配1000个卡槽 slots: 1000 # 多个nodeId用逗号分隔 fromReplicas: nodeId3,nodeId4 # redis 实例配置详情 pod: # 标签管理：map[string][string] - labels: key: value # 备注管理：map[string][string] annotations: key: value # 环境变量管理 env: - name: tony value: aa - name: MAXMEMORY value: 2gb # 亲和性管理 affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: HC_Status operator: In values: - C podAntiAffinity: {} # 资源管理 resources: limits: #cpu, memory, storage,ephemeral-storage cpu: \u0026#34;2\u0026#34; memory: 4Gi requests: cpu: \u0026#34;1\u0026#34; memory: 2Gi #statefulset更新模式 updateStrategy: type: RollingUpdate # 支持挂载形式： hostPath(不需要persistentVolumeClaimName)，nfs(需要persistentVolumeClaimName) volumes: type: nfs persistentVolumeClaimName: pvcName # 配置文件模板名 configmap: name # 监控镜像 monitorImage: string # 初始化镜像 initImage: string # 中间件容器镜像 middlewareImage: string status: #当前statefulset replicas情况 replicas: 6 # 集群阶段,None,Creating,Running,Failed,Scaling # None 或 “”， 就是代表该CRD刚创建 # Creating 代表等待redis资源对象创建完毕（operator 发现CRD创建，创建资源对象，更新状态） # Running 代表已进行初始化操作（在Creating之后，发现实例起来完毕，初始化操作） # Failed 代表着某异常故障 # --------------------- # Scaling 代表着实例不一致(用户修改实例，operator发现实例不一致，更新statefulset，更新状态) # Upgrading 代表着升级中 # --------------------- phase: Creating # 异常问题解释 reason: \u0026#34;异常问题\u0026#34; conditions: - name: redis-cluster-0 instance: 10.168.78.90:6379 type: master masterNodeId: allkk111snknkcs nodeId: allkk111snknkcs domainName: redis-cluster-0.redis-cluster.kube-system.svc.cluster.local slots: 1024-2048 hostname: docker-vm-3 hostIP: 192.168.26.122 # true or flase status: \u0026#34;True\u0026#34; reason: xxxx message: xxxx lastTransitionTime: 2019-03-25T03:10:29Z 代码生成 # 主要生成符合k8s风格的代码：\n生成风格统一的DeepCopy（CustomResources必须实现runtime.Object接口——必须实现DeepCopy方法）； clientset（自定义资源对象的客户端）； listers（用来提供对于 GET/List 资源对象的请求提供只读缓存层）； informers（List/Get 资源对象，还可以监听事件并触发回调函数。 结构体定义到$ProjectName/pkg/apis/{中间件名称}/{版本号}/types.go里：\ntypes.go中结构体定义根据上面准备的CR yaml定义。如下，其中需要注意的是，必须要给结构体加以下两个注解：\n// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object注解表示：为该类型生成 func (t* T) DeepCopy() *T方法。API类型都需要实现深拷贝； // +genclient注解表示为当前类型生成客户端。\n3、编写$ProjectName/pkg/apis/{中间件名称}/{版本号}/doc.go，其中定义全局tag：// +k8s:deepcopy-gen=package，表示为包中任何类型生成深拷贝方法。package指定版本。\n4、编写$ProjectName/pkg/apis/{中间件名称}/{版本号}/register.go，通过scheme注册自定义CR类型，这样当和API Server通信的时候就能够处理该类型；（不同operator需要修改SchemeGroupVersion的Group和Version以及addKnownTypes中注册的结构体）\npackage v1alpha1 import ( \u0026#34;harmonycloud.cn/middleware-operator-manager/pkg/apis/redis\u0026#34; v1 \u0026#34;k8s.io/apimachinery/pkg/apis/meta/v1\u0026#34; \u0026#34;k8s.io/apimachinery/pkg/runtime\u0026#34; \u0026#34;k8s.io/apimachinery/pkg/runtime/schema\u0026#34; ) // SchemeGroupVersion is group version used to register these objects var SchemeGroupVersion = schema.GroupVersion {Group: redis.GroupName, Version: \u0026#34;v1alpha1\u0026#34;} // Kind takes an unqualified kind and returns back a Group qualified GroupKind func Kind(kind string) schema.GroupKind { return SchemeGroupVersion.WithKind(kind).GroupKind() } // Resource takes an unqualified resource and returns a Group qualified GroupResource func Resource(resource string) schema.GroupResource { return SchemeGroupVersion.WithResource(resource).GroupResource() } var ( SchemeBuilder = runtime.NewSchemeBuilder(addKnownTypes) AddToScheme = SchemeBuilder.AddToScheme ) //注册CR对象 // Adds the list of known types to Scheme. func addKnownTypes(scheme *runtime.Scheme) error { scheme.AddKnownTypes(SchemeGroupVersion, \u0026amp;RedisCluster{}, \u0026amp;RedisClusterList{}, ) v1.AddToGroupVersion(scheme, SchemeGroupVersion) return nil } 5、编写$ProjectName/pkg/apis/{中间件名称}/register.go，其中定义了上一步用到的GroupName；\n6、使用kubernetes提供的code-generator代码生成器工具，根据定义好的CR结构体对象生成风格统一的DeepCopy（CustomResources必须实现runtime.Object接口——必须实现DeepCopy方法）、clientset（自定义资源对象的客户端）、listers（用来提供对于 GET/List 资源对象的请求提供只读缓存层）、informers（List/Get 资源对象，还可以监听事件并触发回调函数）代码。\ncode-generator地址如下，下载后放到$GOPATH/src/k8s.io/目录下：\nhttps://github.com/kubernetes/code-generator\n然后执行以下命令，harmonycloud.cn/middleware-operator-manager/pkg/clients表示最终生成的clientset、informers、listers代码目录，最后的redis:v1alpha1需要改成{中间件名称}:{版本}\n./generate-groups.sh all \u0026#34;harmonycloud.cn/middleware-operator-manager/pkg/clients\u0026#34; \u0026#34;harmonycloud.cn/middleware-operator-manager/pkg/apis\u0026#34; \u0026#34;redis:v1alpha1\u0026#34; 执行后将生成以下代码：\n生成代码时可能遇到的坑，请参考：\nk8s自定义资源类型代码自动生成：https://www.jianshu.com/p/cbeb513250d0\n参考：\n通过自定义资源扩展Kubernetes\nExtending Kubernetes: Create Controllers for Core and Custom Resources\noperator主流程代码开发 # 首先operator的入口为operator-manager.go里的main函数。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/spf13/pflag\u0026#34; \u0026#34;harmonycloud.cn/middleware-operator-manager/cmd/operator-manager/app\u0026#34; \u0026#34;harmonycloud.cn/middleware-operator-manager/cmd/operator-manager/app/options\u0026#34; \u0026#34;k8s.io/apiserver/pkg/util/flag\u0026#34; \u0026#34;k8s.io/apiserver/pkg/util/logs\u0026#34; \u0026#34;k8s.io/kubernetes/pkg/version/verflag\u0026#34; \u0026#34;os\u0026#34; ) func main() { //参数初始化配置 s := options.NewOMServer() s.AddFlags(pflag.CommandLine, app.KnownOperators()) flag.InitFlags() //日志初始化 logs.InitLogs() defer logs.FlushLogs() verflag.PrintAndExitIfRequested() //进行operator初始化 if err := app.Run(s); err != nil { fmt.Fprintf(os.Stderr, \u0026#34;%v\\n\u0026#34;, err) os.Exit(1) } } main函数中首先进行对参数的初始化，其中主要包括：operator多实例时的选主配置；事件同步时间；集群创建、升级超时时间；是否启用leader功能；是否开启pprof分析功能等，代码在options.go中。\napp.Run(s)根据参数配置进行operator初始化：\n首先根据参数配置，构建默认客户端（操作k8s已有资源对象）、leader选举客户端、操作扩展资源客户端等； 之后创建CRD资源对象定义，后续创建的CR对象都是该CRD的实例； 注册健康检查接口、根据启动参数配置决定是否开启pprof分析接口功能； 创建recorder，主要用于记录events（k8s资源），用于操作审计； 定义Run函数，进行启动operator，选举结果的leader执行该函数； 判断是否开启leader选举功能； 创建leader选举的资源锁，目前资源锁实现了configmaps和endpoints方式，具体代码在client-go下，默认使用endpoints方式； 启动leader选举机制，争抢到锁，选举为leader的实例执行OnStartedLeading，即上面定义的Run函数；失去锁的实例执行OnStoppedLeading函数。 // Run runs the OMServer. This should never exit. func Run(s *options.OperatorManagerServer) error { // To help debugging, immediately log version glog.Infof(\u0026#34;Version: %+v\u0026#34;, version.Get()) //根据参数配置，构建默认客户端（操作k8s已有资源对象）、leader选举客户端、操作扩展资源客户端等 kubeClient, leaderElectionClient, extensionCRClient, kubeconfig, err := createClients(s) if err != nil { return err } //根据提前准备好的CRD yaml文件，构建并创建CRD err = CreateRedisClusterCRD(extensionCRClient) if err != nil { if errors.IsAlreadyExists(err) { glog.Infof(\u0026#34;redis cluster crd is already created.\u0026#34;) } else { fmt.Fprint(os.Stderr, err) return err } } //注册健康检查接口、根据启动参数配置决定是否开启pprof分析接口功能 go startHTTP(s) //创建recorder，主要用于记录events（k8s资源） recorder := createRecorder(kubeClient) //定义Run函数，进行启动operator，选举结果的leader执行该函数 run := func(stop \u0026lt;-chan struct{}) { operatorClientBuilder := operator.SimpleOperatorClientBuilder{ ClientConfig: kubeconfig, } rootClientBuilder := controller.SimpleControllerClientBuilder{ ClientConfig: kubeconfig, } otx, err := CreateOperatorContext(s, kubeconfig, operatorClientBuilder, rootClientBuilder, stop) if err != nil { glog.Fatalf(\u0026#34;error building controller context: %v\u0026#34;, err) } otx.InformerFactory = informers.NewSharedInformerFactory(kubeClient, time.Duration(s.ResyncPeriod)*time.Second) if err := StartOperators(otx, NewOperatorInitializers()); err != nil { glog.Fatalf(\u0026#34;error starting operators: %v\u0026#34;, err) } otx.RedisInformerFactory.Start(otx.Stop) otx.InformerFactory.Start(otx.Stop) close(otx.InformersStarted) select {} } //判断是否开启leader选举功能 if !s.LeaderElection.LeaderElect { run(nil) panic(\u0026#34;unreachable\u0026#34;) } id, err := os.Hostname() if err != nil { return err } //创建leader选举的资源锁，目前资源锁实现了configmaps和endpoints方式，具体代码在client-go下，默认使用endpoints方式 rl, err := resourcelock.New(s.LeaderElection.ResourceLock, \u0026#34;kube-system\u0026#34;, \u0026#34;middleware-operator-manager\u0026#34;, leaderElectionClient.CoreV1(), resourcelock.ResourceLockConfig{ Identity: id, EventRecorder: recorder, }) if err != nil { glog.Fatalf(\u0026#34;error creating lock: %v\u0026#34;, err) } //启动leader选举机制，争抢到锁，选举为leader的实例执行OnStartedLeading，即上面定义的Run函数；失去锁的实例执行OnStoppedLeading函数 leaderelection.RunOrDie(leaderelection.LeaderElectionConfig{ Lock: rl, LeaseDuration: s.LeaderElection.LeaseDuration.Duration, RenewDeadline: s.LeaderElection.RenewDeadline.Duration, RetryPeriod: s.LeaderElection.RetryPeriod.Duration, Callbacks: leaderelection.LeaderCallbacks{ OnStartedLeading: run, OnStoppedLeading: func() { glog.Fatalf(\u0026#34;leaderelection lost\u0026#34;) }, }, }) panic(\u0026#34;unreachable\u0026#34;) } CreateRedisClusterCRD方法根据上面准备的CRD yaml文件构建并创建CRD，只有创建了该CRD，redisCluster资源对象才可以被创建。\nfunc CreateRedisClusterCRD(extensionCRClient *extensionsclient.Clientset) error { //TODO add CustomResourceValidation due to guarantee redis operator work normally,k8s1.12 crd := \u0026amp;v1beta1.CustomResourceDefinition{ ObjectMeta: metav1.ObjectMeta{ Name: \u0026#34;redisclusters.\u0026#34; + v1alpha1.SchemeGroupVersion.Group, }, Spec: v1beta1.CustomResourceDefinitionSpec{ Group: v1alpha1.SchemeGroupVersion.Group, Version: v1alpha1.SchemeGroupVersion.Version, Scope: v1beta1.NamespaceScoped, Names: v1beta1.CustomResourceDefinitionNames{ Kind: \u0026#34;RedisCluster\u0026#34;, ListKind: \u0026#34;RedisClusterList\u0026#34;, Plural: \u0026#34;redisclusters\u0026#34;, Singular: \u0026#34;rediscluster\u0026#34;, ShortNames: []string{\u0026#34;rec\u0026#34;}, }, }, } _, err := extensionCRClient.ApiextensionsV1beta1().CustomResourceDefinitions().Create(crd) return err } CR的apiVersion为CRD的spec.Group/spec.Version即生成代码时register.go中的GroupName和doc.go中的版本号：\napiVersion: redis.middleware.hc.cn/v1alpha1 kind: RedisCluster metadata: name: example000-redis-cluster namespace: kube-system Run函数中主要创建context对象，context里包含启动参数options，kubeconfig配置、RedisInformerFactory（监听CR变化）、InformerFactory（监听statefulsetset变化）等，进行启动operator、启动informer。\nrun := func(stop \u0026lt;-chan struct{}) { operatorClientBuilder := operator.SimpleOperatorClientBuilder{ ClientConfig: kubeconfig, } rootClientBuilder := controller.SimpleControllerClientBuilder{ ClientConfig: kubeconfig, } //创建context对象，context里包含启动参数options，kubeconfig配置、RedisInformerFactory（监听CR变化）、InformerFactory（监听statefulsetset变化）等 otx, err := CreateOperatorContext(s, kubeconfig, operatorClientBuilder, rootClientBuilder, stop) if err != nil { glog.Fatalf(\u0026#34;error building controller context: %v\u0026#34;, err) } //创建InformerFactory otx.InformerFactory = informers.NewSharedInformerFactory(kubeClient, time.Duration(s.ResyncPeriod)*time.Second) //启动operator，NewOperatorInitializers()中定义了启动哪些operator if err := StartOperators(otx, NewOperatorInitializers()); err != nil { glog.Fatalf(\u0026#34;error starting operators: %v\u0026#34;, err) } //启动RedisInformerFactory otx.RedisInformerFactory.Start(otx.Stop) //启动InformerFactory otx.InformerFactory.Start(otx.Stop) close(otx.InformersStarted) //阻塞 select {} } NewOperatorInitializers()中定义了启动哪些operator（新加operator直接在该方法中加）：\nfunc NewOperatorInitializers() map[string]InitFunc { controllers := map[string]InitFunc{} controllers[\u0026#34;rediscluster\u0026#34;] = startRedisClusterController return controllers } CreateOperatorContext函数里根据代码生成器生成的redis客户端versionedClient创建了RedisInformerFactory；（根据不同operator生成不同的客户端，这里需要修改client_builder.go中ClientOrDie的返回值类型），最终创建context对象。\nfunc CreateOperatorContext(s *options.OperatorManagerServer, kubeConfig *restclient.Config, operatorClientBuilder operator.OperatorClientBuilder, rootClientBuilder controller.ControllerClientBuilder, stop \u0026lt;-chan struct{}) (OperatorContext, error) { versionedClient := operatorClientBuilder.ClientOrDie(\u0026#34;middleware-shared-informers\u0026#34;) sharedInformers := redisInformerFactory.NewSharedInformerFactory(versionedClient, time.Duration(s.ResyncPeriod)*time.Second) /*availableResources, err := GetAvailableResources(rootClientBuilder) if err != nil { return OperatorContext{}, err }*/ otx := OperatorContext{ kubeConfig: kubeConfig, OperatorClientBuilder: operatorClientBuilder, DefaultClientBuilder: rootClientBuilder, RedisInformerFactory: sharedInformers, Options: *s, //AvailableResources: availableResources, Stop: stop, InformersStarted: make(chan struct{}), } return otx, nil } StartOperators函数启动所有NewOperatorInitializers中定义的operator，执行startRedisClusterController函数。（不同operator执行不同的启动函数）。\nstartRedisClusterController定义在extensions.go中，用于创建operator、启动worker协程从队列中取出（用于处理informer监听变化的资源对象）进行业务逻辑处理。（新增operator需要在extensions.go中增加对应的start函数）\nfunc startRedisClusterController(otx OperatorContext) (bool, error) { //创建redisOperator rco, err := redis.NewRedisClusterOperator( //注册RedisInformer回调函数 otx.RedisInformerFactory.Cr().V1alpha1().RedisClusters(), //注册statefulsetInformer回调函数 otx.InformerFactory.Apps().V1().StatefulSets(), //默认客户端，用于操作k8s自身资源对象 otx.DefaultClientBuilder.ClientOrDie(\u0026#34;default-kube-client\u0026#34;), //代码生成器生成的客户端，用于操作CR otx.OperatorClientBuilder.ClientOrDie(\u0026#34;rediscluster-operator\u0026#34;), //kubeconfig配置 otx.kubeConfig, //启动参数配置 otx.Options, ) if err != nil { return true, fmt.Errorf(\u0026#34;error creating rediscluster operator: %v\u0026#34;, err) } //启动ConcurrentRedisClusterSyncs个worker协程处理变化的资源对象 go rco.Run(int(otx.Options.ConcurrentRedisClusterSyncs), otx.Stop) return true, nil } NewRedisClusterOperator方法如下，主要创建该operator的结构体，队列，redisInformer注册回调函数，statefulsetInformer回调函数的注册。（不同的operator，需要不同的Informer、处理业务逻辑的方法）\nfunc NewRedisClusterOperator(redisInformer custominfomer.RedisClusterInformer, stsInformer appsinformers.StatefulSetInformer, kubeClient clientset.Interface, customCRDClient customclient.Interface, kubeConfig *rest.Config, options options.OperatorManagerServer) (*RedisClusterOperator, error) { //创建该operator的recorder，记录events eventBroadcaster := record.NewBroadcaster() eventBroadcaster.StartLogging(glog.Infof) eventBroadcaster.StartRecordingToSink(\u0026amp;v1core.EventSinkImpl{Interface: v1core.New(kubeClient.CoreV1().RESTClient()).Events(\u0026#34;\u0026#34;)}) //创建该operator的结构体 rco := \u0026amp;RedisClusterOperator{ options: \u0026amp;options, kubeConfig: kubeConfig, defaultClient: kubeClient, //extensionCRClient: extensionCRClient, customCRDClient: customCRDClient, eventRecorder: eventBroadcaster.NewRecorder(scheme.Scheme, v1.EventSource{Component: \u0026#34;operator-manager\u0026#34;}), queue: workqueue.NewNamedRateLimitingQueue(workqueue.DefaultControllerRateLimiter(), \u0026#34;rediscluster\u0026#34;), } //redisInformer注册回调函数，当informer监听到redis CR资源变化时，调用对应AddFunc、UpdateFunc、DeleteFunc回调函数将CR资源放到queue中 redisInformer.Informer().AddEventHandler(cache.ResourceEventHandlerFuncs{ AddFunc: rco.addRedisCluster, UpdateFunc: rco.updateRedisCluster, // This will enter the sync loop and no-op, because the RedisCluster has been deleted from the store. DeleteFunc: rco.deleteRedisCluster, }) //定义最终处理业务逻辑的函数 rco.syncHandler = rco.syncRedisCluster rco.enqueueRedisCluster = rco.enqueue rco.redisClusterInformer = redisInformer.Informer() //redisInformer是否已经开始同步事件变化 rco.redisClusterListerSynced = rco.redisClusterInformer.HasSynced //lister提供操作informer中缓存的变化的资源接口 rco.redisClusterLister = redisInformer.Lister() //statefulsetInformer注册回调函数，当informer监听到statefulset资源变化时，调用对应AddFunc、UpdateFunc、DeleteFunc回调函数将redis实例的statefulset加入到queue中 stsInformer.Informer().AddEventHandler( cache.ResourceEventHandlerFuncs{ AddFunc: rco.addStatefulSet, UpdateFunc: func(old, cur interface{}) { oldSts := old.(*appsv1.StatefulSet) curSts := cur.(*appsv1.StatefulSet) if oldSts.Status.Replicas != curSts.Status.Replicas { glog.V(4).Infof(\u0026#34;Observed updated replica count for StatefulSet: %v, %d-\u0026gt;%d\u0026#34;, curSts.Name, oldSts.Status.Replicas, curSts.Status.Replicas) } rco.updateStatefulSet(oldSts, curSts) }, DeleteFunc: rco.deleteStatefulSet, }, ) rco.stsLister = stsInformer.Lister() //statefulsetInformer是否已经开始同步事件变化 rco.stsListerSynced = stsInformer.Informer().HasSynced return rco, nil } Run函数中等待redis CR资源、statefulset资源对象同步，然后启动指定个数worker，并永久阻塞，直到stopCh被close（不同operator需要修改rco.redisClusterListerSynced为对应的ListerSynced）\nfunc (rco *RedisClusterOperator) Run(workers int, stopCh \u0026lt;-chan struct{}) { defer utilruntime.HandleCrash() defer rco.queue.ShutDown() glog.Infof(\u0026#34;Starting rediscluster operator\u0026#34;) defer glog.Infof(\u0026#34;Shutting down rediscluster operator\u0026#34;) //等待redis CR资源、statefulset资源对象同步。 if !controller.WaitForCacheSync(\u0026#34;rediscluster\u0026#34;, stopCh, rco.redisClusterListerSynced, rco.stsListerSynced) { return } //循环启动指定个数worker，并永久阻塞，直到stopCh被close for i := 0; i \u0026lt; workers; i++ { go wait.Until(rco.worker, time.Second, stopCh) } \u0026lt;-stopCh } worker方法死循环rco.processNextWorkItem()在队列Operator中定义的queue中取出变化的资源去处理（不同operator有不同的业务处理逻辑）\nfunc (rco *RedisClusterOperator) worker() { for rco.processNextWorkItem() { } } 从informer监听到资源对象变化，回调函数将资源对象key（namespace/name）放到queue中，到worker取出queue中的key去做处理，处理完成后Done掉key流程图如下：\n回调函数将资源对象的key加入到queue中，worker从queue中取出key去处理业务，此时key会被放到processing集合中，表示该key正在被处理。worker处理key时如果遇到错误，该key会根据重试次数是否大于最大重试次数被加入到rateLimited（可以限制添加到queue中速度，最终还会被加入到queue）。worker处理key成功后，Forget(key)表示从rateLimited中清除，Done(key)表示key处理完毕，从processing集合中删除。该代码如下：\nfunc (rco *RedisClusterOperator) processNextWorkItem() bool { key, quit := rco.queue.Get() if quit { return false } // Done marks item as done processing, and if it has been marked as dirty again // while it was being processed, it will be re-added to the queue for // re-processing. defer rco.queue.Done(key) err := rco.syncHandler(key.(string)) //加入到rateLimited中、forget(key) rco.handleErr(err, key) //处理key，主业务逻辑 go rco.syncHandler(key.(string)) return true } 开发注意事项 # 开启worker时，调用cache.WaitForCacheSync等待缓存开始同步。\n不要改变原始对象（从lister中取出的对象），而要使用DeepCopy，因为缓存在informer之间共享。\n根据CRD构建Statefulset时，给Statefulset加OwnerReferences，这样在删除CRD的时候，可以设置是否级联删除statefulset。\n参考：\nk8s垃圾收集：https://kubernetes.io/zh/docs/concepts/workloads/controllers/garbage-collection/\nKubernetes之Garbage Collection：https://blog.csdn.net/dkfajsldfsdfsd/article/details/81130786\n调试 # 本地用IDE\u0026ndash;goland调试代码时，配置如下：\nRun kind：选File；\nFiles：指定main函数所在文件的全路径；\nOutput directory：指定编译后输出的二进制文件位置。可输入。（默认输出exe格式windows可执行文件）\nRun after build：勾选后，编译完成后运行。\nGo tool arguments：填写-i（用于增量编译提速）。\nProgram arguments：用于指定程序启动参数：\n--kubeconfig=D:\\SoftwareAndProgram\\program\\Go\\Development\\src\\harmonycloud.cn\\middleware-operator-manager\\artifacts\\config60 --v=5 \u0026ndash;kubeconfig指定kubeconfig文件所在全路径（即k8s集群master节点的/root/.kube/config），其指定k8s集群apiserver地址已经访问时的证书信息。\n\u0026ndash;v指定glog日志级别，\u0026ndash;v=5表示只输出info小于5和error、warn日志。\nglog.V(4).Infof(\u0026#34;Adding RedisCluster %s\u0026#34;, rc.Name) glog.Warningf(\u0026#34;-----------redisCluster: %#v--\u0026#34;, redisCluster) glog.Errorf(err.Error()) 镜像制作 # 编译前提 # 提前安装好go语言开发环境，正确设置GOROOT和GOPATH环境变量，要求go1.8.3版本以上\n编译二进制 # 将middleware-operator-manager放在$GOPATH/src/harmonycloud.cn/目录下，进入到 $GOPATH/src/harmonycloud.cn/middleware-operator-manager/cmd/operator-manager目录， 最终要生成linux的可执行文件：\n如果是在windows上编译： 打开cmd窗口，进入以上目录后，执行以下命令：\nset GOOS=linux go build -a -o operator-manager 如果是在linux上编译： 执行以下命令：\ngo build -a -o operator-manager 等待编译完成，最终在当前目录下生成operator-manager可执行文件\n镜像制作 # $GOPATH/src/harmonycloud.cn/middleware-operator-manager/artifacts目录下有Dockerfile文件，基础镜像为busybox\nFROM busybox ADD operator-manager /usr/bin/ RUN chmod +x /usr/bin/operator-manager 同级目录下有operator-manager deployment描述文件operator-manager.yaml:\napiVersion: extensions/v1beta1 kind: Deployment metadata: generation: 2 labels: app: operator-manager name: operator-manager namespace: kube-system spec: replicas: 2 selector: matchLabels: app: operator-manager strategy: rollingUpdate: maxSurge: 1 maxUnavailable: 1 type: RollingUpdate template: metadata: creationTimestamp: null labels: app: operator-manager spec: containers: - command: - operator-manager - --v=5 - --leader-elect=true image: 192.168.26.46/k8s-deploy/operator-manager:v1 resources: limits: cpu: 500m memory: 512Mi requests: cpu: 200m memory: 512Mi imagePullPolicy: Always name: operator-manager terminationMessagePath: /dev/termination-log terminationMessagePolicy: File dnsPolicy: ClusterFirst restartPolicy: Always schedulerName: default-scheduler securityContext: {} terminationGracePeriodSeconds: 30 同级目录下有build.sh脚本，指定了docker镜像仓库地址为192.168.26.46\n#!/bin/bash docker build -f ./Dockerfile -t operator-manager:v1 . docker tag operator-manager:v1 192.168.26.46/k8s-deploy/operator-manager:v1 docker push 192.168.26.46/k8s-deploy/operator-manager:v1 kubectl apply -f operator-manager.yaml 执行该脚本即可以将operator-manager二进制打成镜像并推送到192.168.26.46仓库的k8s-deploy项目下： 同时执行了\nkubectl apply -f operator-manager.yaml 命令创建了operator-manager的deployment对象，完成了部署。\noperator高可用 # 用k8s组件中leader选举机制实现redis operator组件的高可用，即正常情况下redis operator组件的多个副本只有一个是处于业务逻辑运行状态，其它副本则不断的尝试去获取锁，去竞争leader，直到自己成为leader。如果正在运行的leader因某种原因导致当前进程退出，或者锁丢失，则由其它副本去竞争新的leader，获取leader继而执行业务逻辑。\n启动两个operator-manager实例：\n可以看到只有一个实例operator-manager-86d785b5fc-m5rgh在同步事件，处理业务：\noperator-manager-86d785b5fc-sszj2实例一直在竞争尝试获取锁：\n删除掉正在同步事件的实例operator-manager-86d785b5fc-m5rgh：\n实例operator-manager-86d785b5fc-sszj2竞争获取到锁，开始处理业务逻辑：\n故可以通过反亲和性防止两个operator-manager实例调度到同一主机上，达到主备高可用。\n最后附上源码地址：\nhttps://github.com/ll837448792/middleware-operator-manager\n参考：\n谈谈k8s的leader选举\u0026ndash;分布式资源锁\n","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/%E5%BC%80%E5%8F%91%E4%B8%80%E4%B8%AAoperator%E6%89%A9%E5%B1%95kubernetes%E7%9A%84%E8%83%BD%E5%8A%9B/","section":"Posts","summary":"\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eOperator 是 CoreOS 推出的旨在简化复杂有状态应用管理，它是一个感知应用状态的控制器，通过扩展 Kubernetes API 来自动创建、管理和配置应用实例。 Operator 基于 CRD 扩展资源对象，并通过控制器来保证应用处于预期状态。\u003c/p\u003e","title":"开发一个operator扩展kubernetes的能力","type":"posts"},{"content":"","date":"2019年10月18日","externalUrl":null,"permalink":"/tags/windows/","section":"Tags","summary":"","title":"Windows","type":"tags"},{"content":" 正文 # 最近工作需要连接公司的vpn。连接前电脑可以上外网，微信、网页都可以访问，但是连接上vpn后，只能访问公司网络了，这就有点虐了。消息收不到很不方便，也查不了资料。以下来说道说道怎么解决，因为网上查到的一些资料，只有文字，无图导致理解的费劲儿，所以下文有很多图，也对比了vpn各种配置的图，可能会有点啰嗦，还望海涵！\n电脑操作系统：win10\n未连接vpn之前 # 未连接vpn之前cmd里执行route print结果如下：\n此时网页可以正常访问：\n来看看vpn是这连接和配置的，服务器地址为115.236.33.122，名称随便起了个WLAN1：\n不勾选“在远程网关使用默认网关” # WLAN1的属性\u0026ndash;\u0026raquo;IPV4\u0026ndash;\u0026raquo;高级\u0026ndash;\u0026raquo;在远程网关使用默认网关，不勾选的情况下，去连接该vpn：\nvpn连接后：\nxshell连接不上公司的IP：\n此时的cmd里执行route print看到如下，多了一行路由项：\n此时网页可以正常访问，无线网连接处也没有黄色感叹号：\n可以发现不勾选“在远程网关使用默认网关”的情况下，无法连接公司网络，显然是不行的。\n勾选上“在远程网关使用默认网关” # 先断开vpn，然后修改：\nWLAN1的属性\u0026ndash;\u0026raquo;IPV4\u0026ndash;\u0026raquo;高级\u0026ndash;\u0026raquo;在远程网关使用默认网关，勾选上后：\n再连接vpn后，xshell可以连接公司的IP了。同时无线网上有了黄色感叹号，说明此时外网是上不了的，百度无法访问：\n此时的路由表多了两条路由项：\n解决问题 # 那怎么既能连接公司网，又能上外网，连接百度查资料呢？\n首先需要把WLAN1的属性\u0026ndash;\u0026raquo;IPV4\u0026ndash;\u0026raquo;高级\u0026ndash;\u0026raquo;在远程网关使用默认网关的勾去掉：\n然后连接vpn，连上后，无线网上没有黄色感叹号，此时可以上外网，但连接不上公司的网，接下来解决该问题。\n在cmd里执行ipconfig/all命令，结果如下，可以看到WLAN1的ip地址为172.20.1.85，子网掩码为：255.255.255.255；无线局域网的ip地址为192.168.68.131，子网掩码为：255.255.255.0，网关为192.168.68.1\n再执行route print可以看到如下结果：\n我们要访问公司网络，需要加公司的网段到路由表，比如我要连接10.10.103.151 IP，子网掩码255.255.0.0，那么就需要加如下的路由，其中的172.20.1.85为上面查到的WLAN1的IP，下一跳55写不写没关系：\nroute add -p 10.10.0.0 mask 255.255.0.0 172.20.1.85 metric 55 此时的route print结果如下：\n然后再看看公司网络是否可以连接上，xshell成功连接公司的服务器：\n此时外网也可以正常访问，查资料，聊天也方便了。下一次连接vpn可能得修改路由里的WLAN1的IP，比如下一次连接vpn后WLAN1的IP为172.20.1.86，则修改命令如下：\nroute change -p 10.10.0.0 mask 255.255.0.0 172.20.1.86 ","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/%E8%BF%9E%E4%B8%8A%E5%85%AC%E5%8F%B8%E7%9A%84vpn%E5%90%8E%E7%94%B5%E8%84%91%E4%B8%8A%E4%B8%8D%E4%BA%86%E5%A4%96%E7%BD%91%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/","section":"Posts","summary":"\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e最近工作需要连接公司的vpn。连接前电脑可以上外网，微信、网页都可以访问，但是连接上vpn后，只能访问公司网络了，这就有点虐了。消息收不到很不方便，也查不了资料。以下来说道说道怎么解决，因为网上查到的一些资料，只有文字，无图导致理解的费劲儿，所以下文有很多图，也对比了vpn各种配置的图，可能会有点啰嗦，还望海涵！\u003c/p\u003e","title":"连上公司的vpn后，电脑上不了外网解决办法","type":"posts"},{"content":" 正文 # 一般生产环境上由于网络安全策略，大多数端口是不能为集群外部访问的。多个集群之间一般都是通过k8s的ApiServer组件提供的接口通信，如https://192.168.1.101:6443。所以在做云平台时，集群管理平台（雅称：观云台）需要操作其他集群的资源对象时，必然也得通过ApiServer。\nk8s负载均衡器组件ingress-nginx-controller中集成的nginx，当集群ingress、tcp configmaps、udp configmaps等资源发生变化时，ingress-nginx-controller会根据这些资源最新配置，并根据提前设定好的nginx.tmpl模板（nginx配置文件nginx.conf由该模板生成）生成最新的nginx.conf配置，并自动进行nginx -s reload操作。\n最近做的一个需求，部分负载均衡器可以在页面上由运维人员自动配置，通过nginx的server、map配置。根据请求头的不同将流量分配到不同的服务。可以参考nginx map配置根据请求头不同分配流量到不同后端服务\n配置后需要在观云台上手动reload负载均衡器，以使配置生效。这就涉及到从观云台去操作多集群的负载均衡器。\n通过修改ingress-nginx-controller源码提供接口reload方案，由于网络规则限制肯定行不通；\n只有6443端口可以走。能不能像操作集群内资源一样去操作其他集群资源？\n1、kubectl命令其实对应的就是调用apiserver去操作资源，在集群内我们都知道可以用以下命令：\nkubectl exec -ti ingress-nginx-abab121 -nkube-system -- nginx -s reload 那么从A集群去操作B集群，假设B的ApiServer地址为：https://192.168.1.101:6443，Bearer token为212k1jj1jak12k1kjaeeba，则命令如下：\nkubectl exec -ti ingress-nginx-abab121 -nkube-system --server=https://192.168.1.101:6443 --token=212k1jj1jak12k1kjaeeba --insecure-skip-tls-verify=true -- nginx -s reload 通过查看kubelet的源代码，可以发现$GOPATH\\src\\k8s.io\\kubernetes\\pkg\\kubelet\\server\\server.go的InstallDebuggingHandlers方法中注册了exec、attach、portForward等接口，同时kubelet的内部接口通过api server对外提供服务，所以对API server的这些接口调用，可以直接访问到kubelet，即client \u0026ndash;\u0026raquo; API server \u0026ndash;\u0026gt; kubelet\n2、可以用curl命令调用如下：\ncurl -k \\ -H \u0026#34;Connection: Upgrade\u0026#34; \\ -H \u0026#34;Authorization: Bearer 212k1jj1jak12k1kjaeeba\u0026#34; \\ -H \u0026#34;Upgrade: websocket\u0026#34; \\ -H \u0026#34;Sec-Websocket-Key: x3JJHMbDL1EzLkh9GBhXDw==\u0026#34; \\ -H \u0026#34;Sec-Websocket-Version: 13\u0026#34; \\ \u0026#34;https://192.168.26.19:6443/api/v1/namespaces/liano/pods/nginx/exec?command=ls\u0026amp;stdin=true\u0026amp;stout=true\u0026amp;tty=true\u0026#34; 3、kubernetes开源社区维护了各种语言版本与k8s apiserver交互的client库，比如java库地址如下：\nhttps://github.com/kubernetes-client/java\n其中提供了调用pod的exec接口代码示例：\nhttps://github.com/kubernetes-client/java/blob/master/examples/src/main/java/io/kubernetes/client/examples/ExecExample.java\n需要先依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.kubernetes\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;client-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.0.0\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;compile\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 然后根据apiserver地址和Bearer token构建client，到访问pod exec接口进行nginx -s reload代码示例如下：\npackage com.liano.api.test; import com.alibaba.fastjson.JSONObject; import com.google.common.base.Preconditions; import io.kubernetes.client.ApiClient; import io.kubernetes.client.ApiException; import io.kubernetes.client.Configuration; import io.kubernetes.client.Exec; import io.kubernetes.client.util.ClientBuilder; import io.kubernetes.client.util.credentials.AccessTokenAuthentication; import java.io.BufferedReader; import java.io.IOException; import java.io.InputStream; import java.io.InputStreamReader; import java.io.Reader; /** * @program: k8s-mars * @description: ExecKubelet * @author: liano * @create: 2019-03-06 15:10 **/ public class ExecKubeletDemo { public static void main(String[] args) throws IOException, ApiException, InterruptedException { new ExecKubeletDemo().execNginxReload(); } private void execNginxReload() throws InterruptedException, ApiException, IOException { //apiServer地址和Bbearer token方式认证 ApiClient client = new ClientBuilder().setBasePath(\u0026#34;https://10.10.101.60:6443\u0026#34;).setVerifyingSsl(false) .setAuthentication(new AccessTokenAuthentication(\u0026#34;33095a7b86a7a3462ea45a1410624b\u0026#34;)).build(); // client.setDebugging(true); Configuration.setDefaultApiClient(client); JSONObject res = process(\u0026#34;nginx-97ccd777-xk9pw\u0026#34;, \u0026#34;kube-system\u0026#34;); System.out.println(JSONObject.toJSONString(res)); } private JSONObject process(String podName, String namespace) throws IOException, ApiException, InterruptedException { Exec exec = new Exec(); // final Process proc = exec.exec(\u0026#34;default\u0026#34;, \u0026#34;nginx-4217019353-k5sn9\u0026#34;, new String[] // {\u0026#34;sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;echo foo\u0026#34;}, true, tty); String[] commands = new String[]{\u0026#34;nginx\u0026#34;, \u0026#34;-s\u0026#34;, \u0026#34;reload\u0026#34;}; final Process proc = exec.exec(namespace, podName, commands, true, true); JSONObject res = new JSONObject(); Thread out = new Thread( new Runnable() { public void run() { String copy = copy(proc.getInputStream()); res.put(\u0026#34;data\u0026#34;, copy); } }); out.start(); proc.waitFor(); out.join(); proc.destroy(); if (proc.exitValue() != 0) { res.put(\u0026#34;success\u0026#34;, false); } else { res.put(\u0026#34;success\u0026#34;, true); } return res; } private String copy(InputStream from) { Preconditions.checkNotNull(from); BufferedReader in = null; Reader reader = null; StringBuilder sb = new StringBuilder(); try { reader = new InputStreamReader(from); in = new BufferedReader(reader); String line; while ((line = in.readLine()) != null) { sb.append(line); } } catch (Exception e) { System.out.println(e); } finally { try { if (from != null) { from.close(); } if (reader != null) { reader.close(); } if (in != null) { in.close(); } } catch (Exception e) { System.out.println(e); } } return sb.toString(); } } 从io.kubernetes.client.Exec源码中可以看到，需求通过 HTTP/1.1 协议的101状态码进行握手进一步建立websocket。websocket是一种在单个TCP连接上进行全双工通信的协议， 是独立的、创建在 TCP 上的协议。为了创建Websocket连接，需要通过客户端发出请求，之后服务器进行回应，这个过程通常称为“握手”（handshaking）。\n一个典型的Websocket握手请求如下：\nGET / HTTP/1.1 Upgrade: websocket Connection: Upgrade Host: example.com Origin: http://example.com Sec-WebSocket-Key: sN9cRrP/n9NdMgdcy2VJFQ== Sec-WebSocket-Version: 13 服务器回应\nHTTP/1.1 101 Switching Protocols Upgrade: websocket Connection: Upgrade Sec-WebSocket-Accept: fFBooB7FAkLlXgRSz0BT3v4hq5s= Sec-WebSocket-Location: ws://example.com/ 字段说明\nConnection必须设置Upgrade，表示客户端希望连接升级。 Upgrade字段必须设置Websocket，表示希望升级到Websocket协议。 Sec-WebSocket-Key是随机的字符串，服务器端会用这些数据来构造出一个SHA-1的信息摘要。把“Sec-WebSocket-Key”加上一个特殊字符串“258EAFA5-E914-47DA-95CA-C5AB0DC85B11”，然后计算SHA-1摘要，之后进行BASE-64编码，将结果做为“Sec-WebSocket-Accept”头的值，返回给客户端。如此操作，可以尽量避免普通HTTP请求被误认为Websocket协议。 Sec-WebSocket-Version 表示支持的Websocket版本。RFC6455要求使用的版本是13，之前草案的版本均应当弃用。 Origin字段是可选的，通常用来表示在浏览器中发起此Websocket连接所在的页面，类似于Referer。但是，与Referer不同的是，Origin只包含了协议和主机名称。 其他一些定义在HTTP协议中的字段，如Cookie等，也可以在Websocket中使用。 ","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/kubernetespodexec%E6%8E%A5%E5%8F%A3%E8%B0%83%E7%94%A8/","section":"Posts","summary":"\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e一般生产环境上由于网络安全策略，大多数端口是不能为集群外部访问的。多个集群之间一般都是通过k8s的ApiServer组件提供的接口通信，如https://192.168.1.101:6443。所以在做云平台时，集群管理平台（雅称：观云台）需要操作其他集群的资源对象时，必然也得通过ApiServer。\u003c/p\u003e","title":"kubernetes pod exec接口调用","type":"posts"},{"content":" 正文 # 用以下命令生成代码：\n./generate-groups.sh all \u0026#34;github.com/openshift-evangelist/crd-code-generation/pkg/client\u0026#34; \u0026#34;github.com/openshift-evangelist/crd-code-generation/pkg/apis\u0026#34; \u0026#34;ingressgroup:v1\u0026#34; 第一个报错 # 生成代码报错：\nGenerating deepcopy funcs F0910 19:18:35.552948 12153 main.go:82] Error: Failed making a parser: unable to add directory \u0026#34;github.com/openshift-evangelist/crd-code-generation/pkg/client\u0026#34;: unable to import \u0026#34;github.com/asdfsx/getkubeconfig/pkg/apis/example/v1\u0026#34;: cannot find package \u0026#34;github.com/openshift-evangelist/crd-code-generation/pkg/client\u0026#34; in any of: D:/Program Files/Go/go103/src/github.com/openshift-evangelist/crd-code-generation/pkg/client (from $GOROOT) D:/SoftwareAndProgram/program/Go/Development/src/github.com/openshift-evangelist/crd-code-generation/pkg/client (from $GOPATH) 这个问题可以参考issue\n可以参考这个文章：\nhttps://medium.com/@trstringer/create-kubernetes-controllers-for-core-and-custom-resources-62fc35ad64a3\n由于该链接国内访问比较困难，故转载到了这里：\nhttps://www.jianshu.com/p/dcfe6eac4152\n第二个报错： # Generating deepcopy funcs F1104 02:57:44.419529 35 main.go:82] Error: Failed executing generator: some packages had errors: type \u0026#34;k8s.io/apimachinery/pkg/runtime.Object\u0026#34; in k8s:deepcopy-gen:interfaces tag of type k8s.io/apimachinery/pkg/runtime.Object is not an interface, but: \u0026#34;\u0026#34; goroutine 1 [running]: 这个报错是因为k8s.io/apimachinery这个包目录结构不对，放到vendor目录下找不到，必须放到$GOPATH下的src/k8s.io/apimachinery，具体参考issue\n我解决了这个问题 。这不起作用，除非k8s.io/apimachinery在GOPATH中，如果它只是在vendor目录下，那么deepcopy无法找到它。至少，这需要在某处记录。如果在vendor目录下也能正常工作，那将会很棒。\n目录结构如下：\n$GOPATH/src\n$GOPATH/src/github.com/\n第三个报错 # Generating deepcopy funcs F0221 09:54:08.335328 26316 main.go:82] Error: Failed executing generator: som e packages had errors: errors in package \u0026#34;github.com/openshift-evangelist/crd-code-generation/pkg/apis/ ingressgroup/v1\u0026#34;: unable to format file \u0026#34;D:\\\\SoftwareAndProgram\\\\program\\\\Go\\\\Development\\\\src\\\\gi thub.com\\\\openshift-evangelist\\\\crd-code-generation\\\\pkg\\\\apis\\\\ingressgroup\\\\v1 \\\\zz_generated.deepcopy.go\u0026#34; (The filename, directory name, or volume label synta x is incorrect.). windows上执行报这个错，需要在linux上执行generate-groups.sh 脚本。\n最终生成如下： # [root@master-192 code-generator]# dos2unix generate-groups.sh dos2unix: converting file generate-groups.sh to Unix format ... [root@master-192 code-generator]# ./generate-groups.sh all \u0026#34;github.com/openshift-evangelist/crd-code-generation/pkg/client\u0026#34; \u0026#34;github.com/openshift-evangelist/crd-code-generation/pkg/apis\u0026#34; \u0026#34;ingressgroup:v1\u0026#34; Generating deepcopy funcs Generating clientset for ingressgroup:v1 at github.com/openshift-evangelist/crd-code-generation/pkg/client/clientset Generating listers for ingressgroup:v1 at github.com/openshift-evangelist/crd-code-generation/pkg/client/listers Generating informers for ingressgroup:v1 at github.com/openshift-evangelist/crd-code-generation/pkg/client/informers 最终生成目录结构如下：\n[root@master-192 crd-code-generation]# pwd /root/Work/programmer/go/gopath/src/github.com/openshift-evangelist/crd-code-generation [root@master-192 crd-code-generation]# tree . └── pkg ├── apis │ └── ingressgroup │ ├── register.go │ └── v1 │ ├── doc.go │ ├── register.go │ ├── types.go │ └── zz_generated.deepcopy.go └── client ├── clientset │ └── versioned │ ├── clientset.go │ ├── doc.go │ ├── fake │ │ ├── clientset_generated.go │ │ ├── doc.go │ │ └── register.go │ ├── scheme │ │ ├── doc.go │ │ └── register.go │ └── typed │ └── ingressgroup │ └── v1 │ ├── doc.go │ ├── fake │ │ ├── doc.go │ │ ├── fake_ingressgroup_client.go │ │ └── fake_ingressgroup.go │ ├── generated_expansion.go │ ├── ingressgroup_client.go │ └── ingressgroup.go ├── informers │ └── externalversions │ ├── factory.go │ ├── generic.go │ ├── ingressgroup │ │ ├── interface.go │ │ └── v1 │ │ ├── ingressgroup.go │ │ └── interface.go │ └── internalinterfaces │ └── factory_interfaces.go └── listers └── ingressgroup └── v1 ├── expansion_generated.go └── ingressgroup.go ","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/k8s%E8%87%AA%E5%AE%9A%E4%B9%89%E8%B5%84%E6%BA%90%E7%B1%BB%E5%9E%8B%E4%BB%A3%E7%A0%81%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90/","section":"Posts","summary":"\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e用以下命令生成代码：\u003c/p\u003e","title":"k8s自定义资源类型代码自动生成","type":"posts"},{"content":" 正文 # 最近在做一个需求开发：根据请求后的不同，nginx将请求分发到不同的后端服务；需要修改kubernetes的ingress-nginx-controller的源码，调试的时候遇到了挺多问题，写出来，有需要的老铁可以参考。具体方案就不说了，只说一下nginx配置这一块。\n首先贴出组件版本：\ningress-nginx-controller的版本为0.9-beta.18，可以在github上找到开源的项目源码：\nnginx map配置根据请求头不同分配流量到不同后端服务\nnginx版本为：nginx version: nginx/1.13.7\nmap配置的一个报错： # nginx.conf文件部分如下：\nhttp { include /etc/nginx/conf.d/server-map.d/*-map.conf; include /etc/nginx/conf.d/*-upstream.conf; include /etc/nginx/conf.d/server-map.d/*-server.conf; .... map_hash_bucket_size 64; .... } 在/etc/nginx/conf.d/server-map.d/目录下的flow-ppp-map.conf：\nmap $http_x_group_env $svc_upstream { default zxl-test-splitflow-old-version; ~*old zxl-test-splitflow-old-version; ~*new zxl-test-splitflow-new-version; } flow-ppp-server.conf\nserver { listen 8998; server_name aa.hc.harmonycloud.cn; location /testdemo/test { proxy_pass http://$svc_upstream; } } ingressgroup-upstream.conf\nupstream zxl-test-splitflow-old-version { server 10.168.173.29:8080 max_fails=0 fail_timeout=0; } upstream zxl-test-splitflow-new-version { server 10.168.177.171:8080 max_fails=0 fail_timeout=0; } 当nginx -tc /etc/nginx/nginx.conf测试配置正确与否时报错如下：\nError: exit status 1 nginx: [emerg] \u0026#34;map_hash_bucket_size\u0026#34; directive is duplicate in /etc/nginx/nginx.conf:60 nginx: configuration file c test failed 解决： # 这是因为首次调用map时会隐式设置map_hash_bucket_size，即在nginx中map后写map_hash_bucket_size相当于设置了两次map_hash_bucket_size，如：\nhttp { ... map $status $_status { default 42; } map_hash_bucket_size 64; ... } 因此可以在map之前设置它，如下所示。\nhttp { map_hash_bucket_size 64; ... map $status $_status { default 42; } ... } 所以include map配置也应该放到设置map_hash_bucket_size之后：\nhttp { ... map_hash_bucket_size 64; ... include /etc/nginx/conf.d/server-map.d/*-map.conf; include /etc/nginx/conf.d/*-upstream.conf; include /etc/nginx/conf.d/server-map.d/*-server.conf; } map配置说明： # 通过上面的include三个配置文件，最终对nginx生效的配置应该是这样的：\nhttp { ... map_hash_bucket_size 64; ... map $http_x_group_env $svc_upstream { default zxl-test-splitflow-old-version; ~*old zxl-test-splitflow-old-version; ~*new zxl-test-splitflow-new-version; } upstream zxl-test-splitflow-old-version { server 10.168.173.29:8080 max_fails=0 fail_timeout=0; } upstream zxl-test-splitflow-new-version { server 10.168.177.171:8080 max_fails=0 fail_timeout=0; } server { listen 8998; server_name aa.hc.harmonycloud.cn; location /testdemo/test { proxy_pass http://$svc_upstream; } } } 当在电脑上hosts文件里配置了aa.hc.harmonycloud.cn域名解析后，访问http://aa.hc.harmonycloud.cn:8998/testdemo/test时(即server的server_name和listen、location的配置)，nginx将会把请求转发到http://$svc_upstream，这个$svc_upstream具体是什么，就是通过map配置来赋值的。这里map配置如下：\nmap $http_x_group_env $svc_upstream { default zxl-test-splitflow-old-version; ~*old zxl-test-splitflow-old-version; ~*new zxl-test-splitflow-new-version; } 其中$http_x_group_env可以是nginx内置变量，也可以是自定义的header的key、请求参数名；$svc_upstream即为自定义变量名。这里的配置含义为：当请求头里的x-group-env的值old时，$svc_upstream被赋值为zxl-test-splitflow-old-version；当请求头里的x-group-env的值new时，$svc_upstream被赋值为zxl-test-splitflow-new-version；默认赋值为zxl-test-splitflow-old-version；\n（其中正则表达式如果以 “” 开头，表示这个正则表达式对大小写敏感。以 “*”开头，表示这个正则表达式对大小写不敏感）。而zxl-test-splitflow-new-version和zxl-test-splitflow-old-version表示两个upstream名称。\n因此nginx将会把请求转发到http://$svc_upstream，这里的$svc_upstream会被替换为upstream的名称，最终将得到upstream中的后端服务IP和Port。\n注意：如果我们自定义header为X-Real-IP,通过第二个nginx获取该header时需要这样：$http_x_real_ip; (一律采用小写，而且前面多了个http_，且中间用_替换）\n测试 # 当请求头里加x-group-env为new时，访问后端打印出的是I am new version\n当请求头里加x-group-env为old时，访问后端打印出的是I am old version\n最终通过请求头不同实现了将流量分配到不同的后端服务。\n将请求头的key变为X-Group-Env，value变为OLD或者NEW也没关系：\n","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/nginxmap%E9%85%8D%E7%BD%AE%E6%A0%B9%E6%8D%AE%E8%AF%B7%E6%B1%82%E5%A4%B4%E4%B8%8D%E5%90%8C%E5%88%86%E9%85%8D%E6%B5%81%E9%87%8F%E5%88%B0%E4%B8%8D%E5%90%8C%E5%90%8E%E7%AB%AF%E6%9C%8D%E5%8A%A1/","section":"Posts","summary":"\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e最近在做一个需求开发：根据请求后的不同，nginx将请求分发到不同的后端服务；需要修改kubernetes的ingress-nginx-controller的源码，调试的时候遇到了挺多问题，写出来，有需要的老铁可以参考。具体方案就不说了，只说一下nginx配置这一块。\u003c/p\u003e","title":"nginx map配置根据请求头不同分配流量到不同后端服务","type":"posts"},{"content":"","date":"2019年10月18日","externalUrl":null,"permalink":"/tags/email/","section":"Tags","summary":"","title":"Email","type":"tags"},{"content":"","date":"2019年10月18日","externalUrl":null,"permalink":"/tags/java/","section":"Tags","summary":"","title":"Java","type":"tags"},{"content":" 正文 # 这几篇文章写的就挺好了，传送过去看看吧：\n1、 使用JavaMail创建邮件和发送邮件\n可能遇到的问题：\n1、因为端口号问题导致的错误：\njavax.mail.MessagingException: Exception reading response; nested exception is: java.net.SocketTimeoutException: Read timed out javax.mail.MessagingException: Exception reading response; nested exception is: java.net.SocketTimeoutException: Read timed out at com.sun.mail.smtp.SMTPTransport.readServerResponse(SMTPTransport.java:2210) at com.sun.mail.smtp.SMTPTransport.openServer(SMTPTransport.java:1950) at com.sun.mail.smtp.SMTPTransport.protocolConnect(SMTPTransport.java:642) at javax.mail.Service.connect(Service.java:317) at javax.mail.Service.connect(Service.java:176) at javax.mail.Service.connect(Service.java:125) at javax.mail.Transport.send0(Transport.java:194) at javax.mail.Transport.send(Transport.java:124) 问题和解决这里可以看到，把port configuration from 465 to 587(把端口从465改成587)\nhttps://stackoverflow.com/questions/31535863/error-when-sending-email-via-java-mail-api\n2、使用javamail发送内嵌图片的html格式邮件\n要在邮件中包含图片简单办法是使用image标签，src指向服务器上图片的位置。\npackage com.example.emaildemo; import javax.mail.Message; import javax.mail.Session; import javax.mail.Transport; import javax.mail.internet.InternetAddress; import javax.mail.internet.MimeMessage; import java.util.Properties; /** * @program: email-demo * @description: * @author: smallsoup * @create: 2019-01-27 16:44 **/ public class SendEmailUtil { public static void main(String[] args) throws Exception { Properties props = new Properties(); props.setProperty(\u0026#34;mail.transport.protocol\u0026#34;, \u0026#34;smtp\u0026#34;); props.setProperty(\u0026#34;mail.host\u0026#34;, \u0026#34;smtp.exmail.qq.com\u0026#34;); props.setProperty(\u0026#34;mail.smtp.auth\u0026#34;, \u0026#34;true\u0026#34;); //使用JavaMail发送邮件的5个步骤 //1、创建session Session mailSession = Session.getInstance(props); //开启Session的debug模式，这样就可以查看到程序发送Email的运行状态 mailSession.setDebug(true); //2、通过session得到transport对象 Transport transport = mailSession.getTransport(); //3、使用邮箱的用户名和密码连上邮件服务器,这里有多个构造器,可传入host、端口、user、password transport.connect( \u0026#34;你的邮箱地址\u0026#34;, \u0026#34;你的邮箱AUTH密码,不是登陆密码哦,在邮箱的设置里单独开启和设置\u0026#34;); MimeMessage message = new MimeMessage(mailSession); message.setSubject(\u0026#34;HTML mail Hello\u0026#34;); message.setFrom(new InternetAddress(\u0026#34;你的邮箱地址\u0026#34;)); //4、创建邮件 message.setContent(\u0026#34;\u0026lt;h1\u0026gt;This is a test\u0026lt;/h1\u0026gt;\u0026#34; + \u0026#34;\u0026lt;img src=\\\u0026#34;http://www.rgagnon.com/images/jht.gif\\\u0026#34;\u0026gt;\u0026#34;, \u0026#34;text/html\u0026#34;); message.addRecipient(Message.RecipientType.TO, new InternetAddress(\u0026#34;接收人邮箱地址\u0026#34;)); //5、发送邮件 // transport.sendMessage(message, message.getRecipients(Message.RecipientType.TO)); transport.sendMessage(message, message.getAllRecipients()); transport.close(); } } 上面发送带图片邮件的方法很简单，但是有些邮件客户端会把是否包含有服务器端图片作为垃圾邮件的判断机制。我们可以将图片内嵌到邮件中，然后用cid加content-id引用内嵌的图片。\npackage com.example.emaildemo; import javax.activation.DataHandler; import javax.activation.DataSource; import javax.activation.FileDataSource; import javax.mail.BodyPart; import javax.mail.Message; import javax.mail.Session; import javax.mail.Transport; import javax.mail.internet.InternetAddress; import javax.mail.internet.MimeBodyPart; import javax.mail.internet.MimeMessage; import javax.mail.internet.MimeMultipart; import java.util.Properties; /** * @program: email-demo * @description: * @author: smallsoup * @create: 2019-01-27 16:44 **/ public class SendEmailUtil { public static void main(String[] args) throws Exception { Properties props = new Properties(); props.setProperty(\u0026#34;mail.transport.protocol\u0026#34;, \u0026#34;smtp\u0026#34;); props.setProperty(\u0026#34;mail.host\u0026#34;, \u0026#34;smtp.exmail.qq.com\u0026#34;); props.setProperty(\u0026#34;mail.smtp.auth\u0026#34;, \u0026#34;true\u0026#34;); //使用JavaMail发送邮件的5个步骤 //1、创建session Session mailSession = Session.getInstance(props); //开启Session的debug模式，这样就可以查看到程序发送Email的运行状态 mailSession.setDebug(true); //2、通过session得到transport对象 Transport transport = mailSession.getTransport(); //3、使用邮箱的用户名和密码连上邮件服务器,这里有多个构造器,可传入host、端口、user、password transport.connect( \u0026#34;你的邮箱地址\u0026#34;, \u0026#34;你的邮箱AUTH密码,不是登陆密码哦,在邮箱的设置里单独开启和设置\u0026#34;); MimeMessage message = new MimeMessage(mailSession); message.setSubject(\u0026#34;HTML mail Hello\u0026#34;); message.setFrom(new InternetAddress(\u0026#34;你的邮箱地址\u0026#34;)); message.addRecipient(Message.RecipientType.TO, new InternetAddress(\u0026#34;接收人邮箱地址\u0026#34;)); //4、创建邮件 //This HTML mail have to 2 part, the BODY and the embedded image MimeMultipart multipart = new MimeMultipart(\u0026#34;related\u0026#34;); // first part (the html) BodyPart messageBodyPart = new MimeBodyPart(); String htmlText = \u0026#34;\u0026lt;H1\u0026gt;Hello\u0026lt;/H1\u0026gt;\u0026lt;img src=\\\u0026#34;cid:image\\\u0026#34;\u0026gt;\u0026#34;; messageBodyPart.setContent(htmlText, \u0026#34;text/html\u0026#34;); // add it multipart.addBodyPart(messageBodyPart); // second part (the image) messageBodyPart = new MimeBodyPart(); DataSource fds = new FileDataSource(\u0026#34;C:\\\\images\\\\jht.gif\u0026#34;); messageBodyPart.setDataHandler(new DataHandler(fds)); messageBodyPart.setHeader(\u0026#34;Content-ID\u0026#34;,\u0026#34;image\u0026#34;); // add it multipart.addBodyPart(messageBodyPart); // put everything together message.setContent(multipart); //5、发送邮件 transport.sendMessage(message, message.getAllRecipients()); transport.close(); } } SpringBoot发送邮件需要加依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-mail\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 具体可参考：\njava发送html模板的高逼格邮件\n","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/javamail%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6/","section":"Posts","summary":"\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e这几篇文章写的就挺好了，传送过去看看吧：\u003c/p\u003e","title":"Javamail发送邮件","type":"posts"},{"content":" 正文 # 最近做了一个监测k8s服务pod水平伸缩发送邮件的功能（当pod的cpu/内存达到指定阈值后会水平扩展出多个pod、或者指定时间内pod数应扩展到指定数量），一开始写了个格式很low的邮件，像下面这样：\n主流程打通，算个v1版本吧，程序员是个追求完美的人，再说这么低逼格的邮件，给客户看，客户也会不满意。那怎么提高邮件的逼格呢？下面写了个简单的demo，v2版本如下：\n感兴趣的小伙伴可以参考，模板可以找你公司前端和美工小姐姐设计。\n因为监测k8s服务pod水平伸缩是用go开发的，发送通知邮件提供了个接口，用springboot写的，以下也用springboot做demo\nSpringboot的pom.xml文件：\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.2.RELEASE\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;groupId\u0026gt;com.example\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;email-demo\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;email-demo\u0026lt;/name\u0026gt; \u0026lt;description\u0026gt;Demo project for Spring Boot\u0026lt;/description\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;java.version\u0026gt;1.8\u0026lt;/java.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-lang3\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.8.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;fastjson\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.47\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!--发送邮件的必要依赖--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-mail\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt; pod-scale-alarm.html模板文件：\n模板中的{0}、{1}这样的占位符后面java代码会替换掉\n\u0026lt;body style=\u0026#34;color: #666; font-size: 14px; font-family: \u0026#39;Open Sans\u0026#39;,Helvetica,Arial,sans-serif;\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;box-content\u0026#34; style=\u0026#34;width: 80%; margin: 20px auto; max-width: 800px; min-width: 600px;\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;header-tip\u0026#34; style=\u0026#34;font-size: 12px; color: #aaa; text-align: right; padding-right: 25px; padding-bottom: 10px;\u0026#34;\u0026gt; Confidential - Scale Alarm Use Only \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;info-top\u0026#34; style=\u0026#34;padding: 15px 25px; border-top-left-radius: 10px; border-top-right-radius: 10px; background: {0}; color: #fff; overflow: hidden; line-height: 32px;\u0026#34;\u0026gt; \u0026lt;img src=\u0026#34;cid:icon-alarm\u0026#34; style=\u0026#34;float: left; margin: 0 10px 0 0; width: 32px;\u0026#34; /\u0026gt;\u0026lt;div style=\u0026#34;color:#010e07\u0026#34;\u0026gt;\u0026lt;strong\u0026gt;服务实例水平伸缩通知\u0026lt;/strong\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;info-wrap\u0026#34; style=\u0026#34;border-bottom-left-radius: 10px; border-bottom-right-radius: 10px; border:1px solid #ddd; overflow: hidden; padding: 15px 15px 20px;\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;tips\u0026#34; style=\u0026#34;padding:15px;\u0026#34;\u0026gt; \u0026lt;p style=\u0026#34; list-style: 160%; margin: 10px 0;\u0026#34;\u0026gt;Hi,\u0026lt;/p\u0026gt; \u0026lt;p style=\u0026#34; list-style: 160%; margin: 10px 0;\u0026#34;\u0026gt;{1}\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;time\u0026#34; style=\u0026#34;text-align: right; color: #999; padding: 0 15px 15px;\u0026#34;\u0026gt;{2}\u0026lt;/div\u0026gt; \u0026lt;br\u0026gt; \u0026lt;table class=\u0026#34;list\u0026#34; style=\u0026#34;width: 100%; border-collapse: collapse; border-top:1px solid #eee; font-size:12px;\u0026#34;\u0026gt; \u0026lt;thead\u0026gt; \u0026lt;tr style=\u0026#34; background: #fafafa; color: #333; border-bottom: 1px solid #eee;\u0026#34;\u0026gt; {3} \u0026lt;/tr\u0026gt; \u0026lt;/thead\u0026gt; \u0026lt;tbody\u0026gt; {4} \u0026lt;/tbody\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; success-alarm.png图标：\njava代码如下，简单的demo，优化可以自己在项目中去做。\npackage com.example.emaildemo; import org.apache.commons.lang3.time.DateFormatUtils; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.core.io.ClassPathResource; import org.springframework.mail.javamail.JavaMailSenderImpl; import org.springframework.mail.javamail.MimeMessageHelper; import javax.mail.MessagingException; import javax.mail.internet.MimeMessage; import java.io.BufferedReader; import java.io.IOException; import java.io.InputStream; import java.io.InputStreamReader; import java.text.MessageFormat; import java.util.Date; import java.util.Objects; import java.util.Properties; /** * @program: email-demo * @description: * @author: smallsoup * @create: 2019-01-27 16:44 **/ public class SendEmailUtil { private static final Logger LOGGER = LoggerFactory.getLogger(SendEmailUtil.class); public static void main(String[] args) throws MessagingException, IOException { JavaMailSenderImpl javaMailSender = new JavaMailSenderImpl(); javaMailSender.setUsername(\u0026#34;你的邮箱地址\u0026#34;); javaMailSender.setPassword(\u0026#34;你的邮箱AUTH密码,不是登陆密码哦,在邮箱的设置里单独开启和设置\u0026#34;); javaMailSender.setHost(\u0026#34;smtp.exmail.qq.com\u0026#34;); javaMailSender.setPort(587); javaMailSender.setDefaultEncoding(\u0026#34;UTF-8\u0026#34;); Properties props = new Properties(); props.setProperty(\u0026#34;mail.smtp.host\u0026#34;, \u0026#34;smtp.exmail.qq.com\u0026#34;); props.setProperty(\u0026#34;mail.transport.protocol\u0026#34;, \u0026#34;smtp\u0026#34;); props.setProperty(\u0026#34;mail.smtp.auth\u0026#34;, \u0026#34;true\u0026#34;); props.setProperty(\u0026#34;mail.smtp.connectiontimeout\u0026#34;, \u0026#34;20000\u0026#34;); props.setProperty(\u0026#34;mail.smtp.timeout\u0026#34;, \u0026#34;20000\u0026#34;); javaMailSender.setJavaMailProperties(props); MimeMessage message = javaMailSender.createMimeMessage(); MimeMessageHelper helper = new MimeMessageHelper(message, true, \u0026#34;UTF-8\u0026#34;); helper.setTo(new String[]{\u0026#34;收件人邮箱\u0026#34;}); helper.setCc(\u0026#34;抄送人邮箱\u0026#34;); helper.setFrom(\u0026#34;你的邮箱地址\u0026#34;); helper.setSubject(\u0026#34;liang subject\u0026#34;); helper.setText(buildContent(), true); String alarmIconName = \u0026#34;success-alarm.png\u0026#34;; ClassPathResource img = new ClassPathResource(alarmIconName); if (Objects.nonNull(img)) { helper.addInline(\u0026#34;icon-alarm\u0026#34;, img); } javaMailSender.send(message); } private static String buildContent() throws IOException { //加载邮件html模板 String fileName = \u0026#34;pod-scale-alarm.html\u0026#34;; InputStream inputStream = ClassLoader.getSystemResourceAsStream(fileName); BufferedReader fileReader = new BufferedReader(new InputStreamReader(inputStream)); StringBuffer buffer = new StringBuffer(); String line = \u0026#34;\u0026#34;; try { while ((line = fileReader.readLine()) != null) { buffer.append(line); } } catch (Exception e) { LOGGER.error(\u0026#34;读取文件失败，fileName:{}\u0026#34;, fileName, e); } finally { inputStream.close(); fileReader.close(); } String contentText = \u0026#34;以下是服务实例伸缩信息, 敬请查看.\u0026lt;br\u0026gt;below is the information of service instance scale, please check. \u0026#34;; //邮件表格header String header = \u0026#34;\u0026lt;td\u0026gt;分区(Namespace)\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;服务(Service)\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;伸缩结果(Scale Result)\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;伸缩原因(Scale Reason)\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;当前实例数(Pod instance number)\u0026lt;/td\u0026gt;\u0026#34;; StringBuilder linesBuffer = new StringBuilder(); linesBuffer.append(\u0026#34;\u0026lt;tr\u0026gt;\u0026lt;td\u0026gt;\u0026#34; + \u0026#34;myNamespace\u0026#34; + \u0026#34;\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;\u0026#34; + \u0026#34;myServiceName\u0026#34; + \u0026#34;\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;\u0026#34; + \u0026#34;myscaleResult\u0026#34; + \u0026#34;\u0026lt;/td\u0026gt;\u0026#34; + \u0026#34;\u0026lt;td\u0026gt;\u0026#34; + \u0026#34;mReason\u0026#34; + \u0026#34;\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;\u0026#34; + \u0026#34;my4\u0026#34; + \u0026#34;\u0026lt;/td\u0026gt;\u0026lt;/tr\u0026gt;\u0026#34;); //绿色 String emailHeadColor = \u0026#34;#10fa81\u0026#34;; String date = DateFormatUtils.format(new Date(), \u0026#34;yyyy/MM/dd HH:mm:ss\u0026#34;); //填充html模板中的五个参数 String htmlText = MessageFormat.format(buffer.toString(), emailHeadColor, contentText, date, header, linesBuffer.toString()); //改变表格样式 htmlText = htmlText.replaceAll(\u0026#34;\u0026lt;td\u0026gt;\u0026#34;, \u0026#34;\u0026lt;td style=\\\u0026#34;padding:6px 10px; line-height: 150%;\\\u0026#34;\u0026gt;\u0026#34;); htmlText = htmlText.replaceAll(\u0026#34;\u0026lt;tr\u0026gt;\u0026#34;, \u0026#34;\u0026lt;tr style=\\\u0026#34;border-bottom: 1px solid #eee; color:#666;\\\u0026#34;\u0026gt;\u0026#34;); return htmlText; } } ","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/java%E5%8F%91%E9%80%81html%E6%A8%A1%E6%9D%BF%E7%9A%84%E9%AB%98%E9%80%BC%E6%A0%BC%E9%82%AE%E4%BB%B6/","section":"Posts","summary":"\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e最近做了一个监测k8s服务pod水平伸缩发送邮件的功能（当pod的cpu/内存达到指定阈值后会水平扩展出多个pod、或者指定时间内pod数应扩展到指定数量），一开始写了个格式很low的邮件，像下面这样：\u003cbr /\u003e\n\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"简单邮件\" src=\"https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy85MTM0NzYzLWNmY2JjMzM4MDBiMGExY2EucG5n?x-oss-process=image/format,png\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e","title":"java发送html模板的高逼格邮件","type":"posts"},{"content":"","date":"2019年10月18日","externalUrl":null,"permalink":"/tags/linux/","section":"Tags","summary":"","title":"Linux","type":"tags"},{"content":"","date":"2019年10月18日","externalUrl":null,"permalink":"/tags/yum/","section":"Tags","summary":"","title":"Yum","type":"tags"},{"content":"在配置yum前首先得说说rpm，在redhat和centos linux系统上，rpm作为软件包管理工具，可以方便的安装、查询、卸载软件包。常见命令如下：\n#安装： rpm -ivh jdk-7u25-linux-x64.rpm #卸载： rpm -e jdk-7u25-linux-x64.rpm #升级： rpm -Uvh jdk-7u25-linux-x64.rpm #查询软件的安装路径： rpm -ql yum-3.4.3-118.el7.noarch #查询所有安装的包： rpm -qa #查询某个文件是哪个rpm包产生： rpm -qf /var/lib/yum/yumdb 但是在多个包组成的rpm包用rpm命令安装时，其依赖包问题是超级繁琐的。\nyum是redhat和centos的软件包管理工具，安装软件包时可以在网上远程仓库或者本地自动下载所有依赖包，解决了rpm的痛点。今天主要学习下远程yum源配置。由于redhat 自带的 yum 源是需要注册收费才能更新下载软件的，如果没有注册就使用，则会报下面的错误：\nThis system is not registered to Red Hat Subscription Management. You can use subscription-manager to register. 所以我们需要把yum源修改为centos的源。\n查看自带yum：\nrpm -qa | grep yum 卸载自带yum：\nrpm -qa | grep yum | xargs rpm -e --nodeps 查看系统版本：\ncat /etc/redhat-release 下载安装软件包：\n#下载链接 http://mirrors.163.com/centos/7/os/x86_64/Packages/ #需要下载以下三个rpm包： yum-metadata-parser-1.1.4-10.el7.x86_64.rpm yum-3.4.3-158.el7.centos.noarch.rpm yum-plugin-fastestmirror-1.1.31-45.el7.noarch.rpm 执行以下安装命令报错，依赖包的版本不符：\n#执行yum安装 rpm -ivh yum* 这里升级python-urlgrabber和rpm包版本：\n#升级rpm包到： rpm-4.11.3-32.el7.x86_64.rpm python-urlgrabber-3.10-8.el7.noarch.rpm #下载 wget http://mirrors.163.com/centos/7/os/x86_64/Packages/rpm-4.11.3-32.el7.x86_64.rpm wget http://mirrors.163.com/centos/7/os/x86_64/Packages/python-urlgrabber-3.10-8.el7.noarch.rpm #升级 rpm -Uvh rpm-4.11.3-32.el7.x86_64.rpm --nodeps rpm -Uvh python-urlgrabber-3.10-8.el7.noarch.rpm --nodeps 然后安装：\n新建配置文件：\nvim /etc/yum.repos.d/CentOS-Base.repo 加入以下配置：\n#CentOS-Base.repo # # The mirror system uses the connecting IP address of the client and the # update status of each mirror to pick mirrors that are updated to and # geographically close to the client. You should use this for CentOS updates # unless you are manually picking other mirrors. # # If the mirrorlist= does not work for you, as a fall back you can try the # remarked out baseurl= line instead. # # [base] name=CentOS-$7 - Base - 163.com #mirrorlist=http://mirrorlist.centos.org/?release=$7\u0026amp;arch=$basearch\u0026amp;repo=os baseurl=http://mirrors.163.com/centos/7/os/$basearch/ gpgcheck=1 gpgkey=http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-7 #released updates [updates] name=CentOS-$7 - Updates - 163.com #mirrorlist=http://mirrorlist.centos.org/?release=$7\u0026amp;arch=$basearch\u0026amp;repo=updates baseurl=http://mirrors.163.com/centos/7/updates/$basearch/ gpgcheck=1 gpgkey=http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-7 #additional packages that may be useful [extras] name=CentOS-$7 - Extras - 163.com #mirrorlist=http://mirrorlist.centos.org/?release=$7\u0026amp;arch=$basearch\u0026amp;repo=extras baseurl=http://mirrors.163.com/centos/7/extras/$basearch/ gpgcheck=1 gpgkey=http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-7 #additional packages that extend functionality of existing packages [centosplus] name=CentOS-$7 - Plus - 163.com baseurl=http://mirrors.163.com/centos/7/centosplus/$basearch/ gpgcheck=1 enabled=0 gpgkey=http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-7 然后清理缓存：\nyum clean all 生成缓存：\nyum makecache 测试源：\nyum update -y --skip-broken 可以看到已经可以通过yum安装相关软件包更新。\n","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/yum%E6%BA%90%E9%85%8D%E7%BD%AE/","section":"Posts","summary":"\u003cp\u003e在配置yum前首先得说说rpm，在redhat和centos linux系统上，rpm作为软件包管理工具，可以方便的安装、查询、卸载软件包。常见命令如下：\u003c/p\u003e","title":"yum源配置","type":"posts"},{"content":"上一节我们在虚拟机上搭建了linux系统，并利用桥接模式访问互联网，这一节，我们来配置一下通过NAT模式访问互联网。说到这里有些小伙伴可能要问了，NAT模式和桥接模式有什么区别呢？\n桥接模式：\n虚拟机虚拟出来的系统和局域网内的独立主机属于同等地位，它可以访问局域网内任何一台机器，该模式下，我们得为虚拟主机——linux配置IP地址，子网掩码，而且该IP要和宿主机的IP是同一网段。如果我们需要在局域网内建立一个虚拟服务器，并为局域网用户提供服务，那就得选择该模式。\nNAT模式：\nNat模式，虚拟机通过宿主机所在的网络来访问internet，即虚拟机把宿主机作为路由器来访问互联网。\n开始配置\n1、VM8 使用固定IP：\n2、 这里使用NAT模式：\n3、VM中依次：编辑——\u0026gt;虚拟网络编辑器，点VMnet8 把使用本\n地DHCP的勾去掉，子网IP和主机VM8的IP同网段，然后点NAT设置。\n网关IP和刚才的IP也是同一个网段。 # 4. 修改网络配置\nvim /etc/sysconfig/network-scripts/ifcfg-eno16777736 增加这些：\nTYPE=Ethernet BOOTPROTO=static DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no NAME=eno16777736 UUID=0e2e0e3d-eaaf-4810-9c6a-dda5ebe0ac9c ONBOOT=yes IPADDR0=192.168.2.5 GATEWAY0=192.168.2.2 PREFIX0=24 DNS1=192.168.2.2 HWADDR=00:0C:29:1D:3A:DF PEERDNS=yes PEERROUTES=yes IPV6_PEERDNS=yes IPV6_PEERROUTES=yes 5. 修改完以后重启network\nsystemctl restart network 或者用:\nservice network restart 注意： # 想要上网，即ping www.baidu.com不通时，要将/etc/sysconfig/network-scripts/ifcfg-eno16777736中的DNS1和GATEWAY1设置为一样的地址。\n","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/nat%E6%A8%A1%E5%BC%8F%E5%AE%9E%E7%8E%B0%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%85%B1%E4%BA%AB%E4%B8%BB%E6%9C%BA%E7%BD%91%E7%BB%9C/","section":"Posts","summary":"\u003cp\u003e上一节我们在虚拟机上搭建了linux系统，并利用桥接模式访问互联网，这一节，我们来配置一下通过NAT模式访问互联网。说到这里有些小伙伴可能要问了，NAT模式和桥接模式有什么区别呢？\u003c/p\u003e","title":"NAT模式实现虚拟机共享主机网络","type":"posts"},{"content":"","date":"2019年10月18日","externalUrl":null,"permalink":"/tags/vmware/","section":"Tags","summary":"","title":"Vmware","type":"tags"},{"content":" 正文 # 以前的电脑上安装过vmware+redhat，但是奈何电脑太老，配置太低，打开的时候超级卡，没法用。换了电脑后，再装上玩玩，故此记录一下安装过程。需要安装的小伙伴可以在此获取包然后按此步骤安装。\n1、创建新的虚拟机 -\u0026gt; 自定义安装\n2、选择虚拟机兼容版本，选择最高的就好\n3、选择安装系统的方式，我们选择稍后安装\n4、选择安装的系统类型，系统为32位的就选32位的（redhat enterprise linux 7），系统为64位的就安装64位的\n5、设置安装的虚拟机系统名称以及安装的虚拟机存放路径，路径自己定义（建议不要放到C盘）\n6、为虚拟机分配处理器（cpu）个数和每个cpu核数\n7、为虚拟机分配内存大小\n8、选择网络类型，这里使用桥接模式，安装好后会利用该方式上网\n9、选择使用网络类型选择I/O设备接口的控制器类型，我们选择默认\n10、选择虚拟磁盘类型，我们选择scsi磁盘（服务器常用磁盘类型SCSI和SAS）\n11、选择新建一块新的虚拟磁盘\n12、定义虚拟磁盘大小，磁盘分配25G，并不是说一定占用25G的磁盘空间，是随着使用时间增加，会慢慢增加，这里选择存储为单文件\n13、点击下一步，然后点击完成。\n14、设置刚才新建的虚拟机，编辑虚拟机设置，cd/dvd选项，使用光盘镜像安装，选择光盘路径点击确定：\n15、然后开启虚拟机\n如果提示以下报错：\n已将该虚拟机配置为使用 64 位客户机操作系统。但是，无法执行 64 位操作。\n此主机支持 Intel VT-x，但 Intel VT-x 处于禁用状态。\n如果已在 BIOS/固件设置中禁用 Intel VT-x，或主机自更改此设置后从未重新启动，则 Intel VT-x 可能被禁用。\n报以上的错，说明BIOS中的Intel Virtual Technology不是Enable状态，需要重启电脑，然后按F2进入BIOS设置Intel Virtual Technology为Enable，如图：\n电脑重启后重新打开虚拟机。\n16、打开虚拟机后，如果提示如下图，选择不再提示，确定。\n17、加电进入安装选项，选择第一个选项\n开始安装，下一步\n选择语言，这里是安装时候的语言，不是安装完成后的系统语言\n软件选择\n这里如果安装后是带图形化的，可以选择“带GUI的服务器” -\u0026gt; KDE，这种方式比较耗内存和占硬盘；\n如果需要安装后不带图形化的（即安装完只有黑框框，看着逼格很高），可以选择“最小安装”。\n这里选择带图形化的。\n选择安装位置，选择“我要配置分区”，点击完成\nLVM改成标准分区，点击加号，挂载点 / 容量20G；点击添加挂载点。同理加swap为4G，/boot为2G\n点击完成，接受更改\n点击开始安装：\n然后修改ROOT用户的密码，大概过10几分钟后，安装完成，点击重启。\n同意协议\n不进行kdump备份\n点击完成后，选择确定重启。\n重启后选择系统语言，输入法，创建本地账号，位置选择上海\n安装好了，看看效果：\n18、接下来配置桥接模式上网\n点击仅主机 -\u0026gt; 更改设置\n点桥接模式，选择网卡\n配置Redhat7的虚拟机设置 -\u0026gt; 网络适配器 -\u0026gt; 网络连接设置为桥接模式。\n（这个在安装时候我们就选择了此模式）\n查看本地主机IP：\n打开终端，ipconfig：\n然后编辑网络配置：\nvim /etc/sysconfig/network-scripts/ifcfg-eno16777736 BOOTPROTO=static #static，静态ip，而不是dhcp，自动获取ip地址。 IPADDR=192.168.43.5 #设置我想用的静态ip地址，要和物理主机在同一网段，但又不能相同。 NETMASK=255.255.255.0 #子网掩码，和物理主机一样就可以了。 GATEWAY=192.168.43.1 #和物理主机一样 DNS1=114.114.114.114 #DNS服务地址，写114.114.114.114 ONBOOT=yes #开机启用网络配置。 如下图所示：\n修改完后，保存退出。执行：\nsystemctl restart network重启网络。\n然后用ifconfig命令查看配置：\n然后测试网络， 在本地ping linux的IP，这里即：ping 192.168.43.5，然后在linux上ping本地：这里即ping 192.168.43.16，如果本地可以ping通linux，但linux不能ping通本地，说明windows开了防火墙，请关闭防火墙后重试。\n在linux上ping淘宝网址：\n利用Firefox浏览器成功访问淘宝。\n以上使用到的软件：VMware12、RedHat7、Xshell等软件，可以关注文末公众号，回复：【1】获取。\n","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/vmware%E4%B8%8A%E5%AE%89%E8%A3%85linux%E8%BF%87%E7%A8%8B%E8%AE%B0%E5%BD%95/","section":"Posts","summary":"\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e以前的电脑上安装过vmware+redhat，但是奈何电脑太老，配置太低，打开的时候超级卡，没法用。换了电脑后，再装上玩玩，故此记录一下安装过程。需要安装的小伙伴可以在此获取包然后按此步骤安装。\u003c/p\u003e","title":"vmware上安装linux过程记录","type":"posts"},{"content":"","date":"2019年10月18日","externalUrl":null,"permalink":"/tags/cmder/","section":"Tags","summary":"","title":"Cmder","type":"tags"},{"content":"","date":"2019年10月18日","externalUrl":null,"permalink":"/tags/%E5%B7%A5%E5%85%B7/","section":"Tags","summary":"","title":"工具","type":"tags"},{"content":"今天来推荐一个超级好用的命令行工具：cmder\n一款Windows环境下非常简洁美观易用的cmd替代者，它支持了大部分的Linux命令。支持ssh连接linux，使用起来非常方便。比起cmd、powershell、conEmu，其界面美观简洁，功能强大。下面来看看效果：\n上面演示了linux下的ls -l、vi，以及vi编辑中的删除行，复制、粘贴，跳到行首、行尾。等基本命令，通过设置别名可以让操作起来更加方便。\n1、 把解压后的目录加到系统环境变量，然后win R，输入cmder即可快捷打开：\n如下：\n2、 通过ctrl 鼠标滚轮调整字体大小；\n3、 添加cmder到右键菜单\n打开cmder命令窗口，输入：\n$ cmder.exe /REGISTER ALL 效果如下：\n4、 解决中文乱码：\n在Settings -\u0026gt;Startup -\u0026gt; Environment中添加一行：\nset LC_ALL=zh_CN.UTF-8 如下：记得加后面的分号哦！\n5、 修改命令提示符号：\ncmder默认的命令提示符是λ，如果想改成常见的$ ,具体操作如下：\n打开cmder安装目录下的\\vendor\\clink.lua文件，\n找到42行的\u0026quot;{lamb}\u0026rsquo;\u0026rsquo; 改为想要的符号，然后重启cmder即可。\n6、 设置别名：\ncmder原生没有** ll **命令，但可以通过设置别名来实现：\n打开cmder安装目录下的\\config\\user-aliases.cmd文件，添加以下别名设置：\nl=ls --show-control-chars -F --color $* la=ls -aF --show-control-chars -F --color $* ll=ls -alF --show-control-chars -F --color $* 如下：\n7、 快捷键：\n另外还可以利用快捷键\nctrl u：删除当前命令行内容；\nctrl l：清屏；\n鼠标选中复制，右键粘贴~~~\n其他功能请移步google查看。\n","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/%E6%8E%A8%E8%8D%90%E4%B8%80%E6%AC%BE%E8%B6%85%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7cmder/","section":"Posts","summary":"\u003cp\u003e今天来推荐一个超级好用的命令行工具：cmder\u003c/p\u003e\n\u003cp\u003e一款Windows环境下非常简洁美观易用的cmd替代者，它支持了大部分的Linux命令。支持ssh连接linux，使用起来非常方便。比起cmd、powershell、conEmu，其界面美观简洁，功能强大。下面来看看效果：\u003c/p\u003e","title":"推荐一款超好用的工具cmder","type":"posts"},{"content":"","date":"2019年10月18日","externalUrl":null,"permalink":"/tags/lamp/","section":"Tags","summary":"","title":"Lamp","type":"tags"},{"content":"今天来在LAMP环境下搭建一个PHP项目，开始之前，先来普及下物联网常识：\n物联网，即Internet of Things，简写IOT。让所有能行使独立功能的普通物体实现互联互通的网络，通过物联网可以用中心计算机对机器、设备、人员进行集中管理、控制，实现物物相连。近几年物联网在运输、物流、健康医疗、智能环境（家庭、办公、工厂）等领域都在迅速发展，前景打好。\nB哥最近研究一个物联网项目：基本功能就是要在web网站和手机app端实时监控硬件上发来的数据，用于分析、集中管理与控制，硬件是基于ARM的，web端是用php开发的，基本功能可以跑起来，现在主要在这基础上实现自己的功能。上一节B哥已经在云服务器上搭建好LAMP环境（linux上安装LAMP笔记），接下来就要把web项目部署好服务器上。遇到了很多问题，在此一一记录。\n其中项目代码结构如下：\n先把项目传到服务器上，然后解压：\ncd /var/www/html unzip AdminIOT #先把目录下文件权限改为777 chmod -R 777 AdminIOT 用以下命令查看httpd、php、mariadb的版本：\nrpm -qa|grep -P \u0026#34;httpd|php|maria\u0026#34; 分别为2.4.6、5.4.16、5.5.56\n配置apache服务器的时候httpd-vhosts.conf文件在/usr/share/doc/httpd-2.4.6目录下\n(windows上好像直接在conf/extra/下)，\n于是在/etc/httpd/conf/httpd.conf中加入：\ninclude /usr/share/doc/httpd-2.4.6/httpd-vhosts.conf，\n结果启动时报错了。于是就把\n/usr/share/doc/httpd-2.4.6/httpd-vhosts.conf文件复制到/etc/httpd/conf/extra目录下：\n#创建目录 mkdir -p /etc/httpd/conf/extra #复制 cp /usr/share/doc/httpd-2.4.6/httpd-vhosts.conf /etc/httpd/conf/extra 然后在extra下的httpd-vhosts.conf中添加如下配置：\nDocumentRoot 为项目代码路径；\nServerName 服务别名，这里设置为域名，但是得在host文件里配置对应的IP，IP即为当前节点IP；\n\u0026lt;VirtualHost *:80\u0026gt; ServerName www.mysmallsoup.com DocumentRoot \u0026#34;/var/www/html/AdminIOT/public\u0026#34; DirectoryIndex index.php \u0026lt;Directory \u0026#34;/var/www/html/AdminIOT/public\u0026#34;\u0026gt; AllowOverride All Require all granted Options all \u0026lt;/Directory\u0026gt; ErrorLog \u0026#34;/var/log/httpd/dummy-host2.example.com-error_log\u0026#34; CustomLog \u0026#34;/var/log/httpd/dummy-host2.example.com-access_log\u0026#34; common \u0026lt;/VirtualHost\u0026gt; 然后在http.conf配置文件中包含httpd-vhosts.conf文件：\ncd /etc/httpd/conf vim httpd.conf #打开文件后在文件末尾加入以下配置： Include conf/extra/httpd-vhosts.conf 然后将域名绑定IP：\nvim /etc/hosts 加入IP 域名，如下：\n120.79.147.88 www.mysmallsoup.com 然后重新启动httpd服务器：\nsystemctl restart httpd **注：**如果直接在windows上用域名访问，得在windows的host里加IP 域名对应关系，但是加了以后访问会报如下错，因为域名得先备案才能用。所以下面都用IP访问。\n然后在本地windows浏览器里访问http://120.79.147.88:80地址，报错：\ndate(): It is not safe to rely on the system\u0026#39;s timezone settings： 然后在查到：\n实际上，从 PHP 5.1.0 ，当对使用date()等函数时，如果timezone设置不正确，在每一次调用时间函数时,都会产生E_NOTICE 或者 E_WARNING 信息。而又在php5.1.0中，date.timezone这个选项，默认情况下是关闭的，无论用什么php命令都是格林威治标准时间，但是PHP5.3中好像如果没有设置也会强行抛出了这个错误的,解决此问题，只要本地化一下，就行了。\n而我们使用的是PHP5.4版本，然后在php.ini文件中加入时区的配置：\nvim /etc/php.ini#加入如下配置：date.timezone = \u0026#34;Asia/Shanghai\u0026#34; 加入以后，保存退出，重新启动apache服务，刷新页面，错误就解决了。\n到这一步，说明项目部署流程已经打通，但是现在需要登录，那么肯定要在数据库里面先存入用户名密码等一些数据。接下来，先给数据库里导入些初始化数据。\n数据库导入数据：\n先重新启动数据库：\nsystemctl restart mariadb 然后试着在本地windows上用Navicat数据库管理工具导入sql脚本，用于数据库的初始化（建库、数据插入等），我习惯性的把端口写为3306（数据库默认端口），然后去连接，发现报错了：\n然后去查看3306端口是否监听：\nnetstat -anp | grep 3306 查不到东西，说明3306端口没有监听，这就奇怪了。然后登陆数据库：\nmysql -uroot -p数据库密码 登陆进去查看数据库端口：\nshow variables like \u0026#39;port\u0026#39;; 发现查到的端口竟然是0，然后又查了资料，发现是启动数据库的时候加了skip-networking导致的，启动时用了如下命令：\nmysqld_safe --user=mysql --skip-grant-tables --skip-networking \u0026amp; \u0026ndash;skip-networking=0表示监听配置端口，默认监听3306，等于1或者\u0026ndash;skip-networking不赋值表示跳过端口监听，此时监听0，网络不可访问数据库，只能数据库节点访问。可以通过以下命令查看：\nshow variables like \u0026#39;skip_networking\u0026#39;; 发现是ON，说明开启了skip_networking，接下来我们要关掉它。\n查看mysql进程：\nps -ef | grep mysql [图片上传中\u0026hellip;(image-3ac06c-1571321042895-17)]\n然后杀掉进程，重新启动数据库：\nkill 12080 mysqld_safe --user=mysql --skip-grant-tables --skip-networking=0 \u0026amp; 然后再来查看3306端口是否监听：\nnetstat -anp | grep 3306 发现端口正常监听，然后登陆数据库，查看：\n发现port为3306，skip_networking为OFF，此时再在windows上连接数据库，就ok了。\n连接上数据库后，就可以导入sql文件了：\n导入以后，打开刚才的web登陆页面，输入用户名和密码，发现验证码图片看不见：\n然后去看运行日志：\ncd /var/www/html/AdminIOT/runtime/log/201806 tailf 10.log 然后刷新验证码，报错Call to undefined function Think\\imagecreate()\n然后查看如下的说法：\n在php中imagecreate函数是一个图形处理函数，主要用于新建一个基于调色板的图像了，然后在这个基础上我们可以创建一些图形数字字符之类的，但这个函数需要GD库支持，如果没有开启GD库使用时会提示Call to undefined function imagecreate()错误。\n那就试着安装一下GD库吧，执行yum安装gd命令，然后重新启动apachce服务以使安装后的GD库生效。\nyum -y install php-gd systemctl restart httpd 然后刷新页面，验证码就可以正常显示了。登陆进去以后，又报错了：Call to undefined function think\\mb_strlen()。\n网上有人说，遇到上述错误，是未开启php_mbstring拓展，即找到php.ini里的\n;extension=php_mbstring.dll把前面的；去掉，但是找了发现没有这个扩展配置，可能是因为版本较高的原因。在/etc/php.d目录下也没找到此扩展，然后就用yum安装一个吧，然后重启apache服务：\nyum install -y php-mbstring systemctl restart httpd 重启以后登录页面后这个错误就没了，但是又报另一个错误：\ncould not find driver\n然后安装php-mysql，安装好后，重启apache服务：\nyum install php-mysql.x86_64 systemctl restart httpd 重新登录页面，这个错误也过去了。又报另一个错误：\nSQLSTATE[28000] [1045] Access denied for user \u0026lsquo;iotadmin\u0026rsquo;@\u0026rsquo;localhost\u0026rsquo; (using password: YES)。\n然后登陆数据库，授权iotadmin用户访问权限：\ngrant all privileges on adminiot.* to \u0026#39;iotadmin\u0026#39;@\u0026#39;localhost\u0026#39; identified by \u0026#39;iotadmin\u0026#39;; flush privileges; 执行完以后，再次刷新页面，报错就过去了。接下来的又是另一个错，错误如下图：\n进后台去看运行日志10.log，报错如下：\ncd /var/www/html/AdminIOT/runtime/log/201806/ tailf 10.log 找到代码Base.php的198行，如下：\n代码报错：Arbitrary expressions in empty are allowed in PHP 5.5 only less，\n大概意思就是说“不同类型的表达式用empty判空只有PHP5.5才”，而服务器上安装的是PHP5.4版本，所以就报这个错。这里不妨换一种方式写，只要逻辑是一样的。那就改成了这样，原来的写法先注释掉。\n然后把文件替换到服务器对应路径下，重启apache服务，刷新页面，一切OK。\n到这里web项目就正常跑起来了。一路走下来，步步是坑啊，做一下笔记，记录一下坑，以后肯定会用到的。\n","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/lamp%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2%E7%89%A9%E8%81%94%E7%BD%91%E9%A1%B9%E7%9B%AE/","section":"Posts","summary":"\u003cp\u003e今天来在LAMP环境下搭建一个PHP项目，开始之前，先来普及下物联网常识：\u003c/p\u003e","title":"LAMP环境部署物联网项目","type":"posts"},{"content":"","date":"2019年10月18日","externalUrl":null,"permalink":"/tags/%E7%89%A9%E8%81%94%E7%BD%91/","section":"Tags","summary":"","title":"物联网","type":"tags"},{"content":"B哥最近在参加比赛，需要把一个php项目部署到服务器上，故此在linux上安装LAMP环境，用于部署项目，第一次安装，做点儿笔记记录一下。\n安装条件：\nRedhat或者CentOS linux环境已装好，并配置了yum源。\n用yum安装httpd、mariadb、php\n安装httpd：\nyum -y install httpd 安装mariadb：\nyum -y install mariadb-server 安装php：\nyum -y install php php-mysql 检查安装包\nrpm -qa|grep -P \u0026#34;httpd|php|maria\u0026#34; 正常情况输出如下：\n启动httpd：\nsystemctl start httpd 验证httpd启动是否正常：\n在index.html文件里加入http running字符串：\necho “-----------------httpd running.-------------” \u0026gt; /var/www/html/index.html 然后用curl命令调接口：\ncurl -k http://localhost:80 -v 正常返回如下：\n问题解决：\n启动后用curl调返回403 Forbidden：\ngoogle查了资料也没有查到解决方法，然后无意间重启了一把竟然好了：\nsystemctl restart httpd 具体原因就不得而知了。重启以后在用curl命令调用就返回200OK了。\n启动mariadb：\nsystemctl start mariadb 然后登陆数据库，执行mysql命令，结果报错如下：\nERROR 1045 (28000): Access denied for user \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; (using password: NO) 这个谷哥上倒是有解决办法：\n1、首先stop数据库服务mariadb.service\nsystemctl stop mariadb.service 2、使用mysqld_safe启动mysqld：\nmysqld_safe --user=mysql --skip-grant-tables --skip-networking \u0026amp; 3、然后登陆数据库：\nmysql -u root mysql 切换到mysql数据库：\nuse mysql; 给root用户设置新的密码，这里newpassword就是新密码：\nUPDATE user SET PASSWORD=PASSWORD(\u0026#39;newpassword\u0026#39;) where USER=\u0026#39;root\u0026#39;; 更新权限：\nFLUSH PRIVILEGES; 然后退出数据库：\nquit 然后登陆数据库：\nmysql -uroot -p 输入密码，登陆进去如下：\n测试php：\n在index.php文件中加入以下字符：\necho \u0026#34; The PHP is running. ?php phpinfo(); ?\u0026gt; \u0026#34;\u0026gt;/var/www/html/index.php 然后curl调接口：\ncurl -k http://localhost:80/index.php -v 正常情况返回200OK，以及刚才插入Index.php中的字符串：\n至此LAMP已搭建完毕，小B哥准备部署项目喽。\n","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/linux%E4%B8%8A%E5%AE%89%E8%A3%85lamp%E7%AC%94%E8%AE%B0/","section":"Posts","summary":"\u003cp\u003eB哥最近在参加比赛，需要把一个php项目部署到服务器上，故此在linux上安装LAMP环境，用于部署项目，第一次安装，做点儿笔记记录一下。\u003c/p\u003e","title":"linux上安装LAMP笔记","type":"posts"},{"content":"之前也有写过有关于爬虫的实战练习：go语言爬取珍爱网\n当时爬取时当并发过大的时候，请求就会出现卡死的情况。其实这可能就是珍爱网对请求和连接进行了限制。\n爬虫和反爬是个“一边攻，一边守”的技术，但我们亲爱的爬虫工程师们也一直遵守着“只攻不破”的原则。网站服务器对爬虫一直在做限制，避免服务器流量异常，负载过大，防止恶意的攻击带来带宽和资源的浪费，甚至影响业务正常运行。往往办法是限制对同一个IP的连接数和并发数进行限制。今天我们就来看看nginx的连接频率limit_conn_module和请求频率limit_req_module 限制模块。\nHTTP请求建立在一次TCP连接基础上，一次TCP请求至少产生一次HTTP请求。\n连接限制：\n语法如下：\nSyntax:limit_conn_zone key zone=name:size; Default: - Context:http limit_conn_zone：一块空间，用于存放被限制连接的状态；\nkey：键，可以说是一个规则，就是对客服端连接的一个标识，比如可以用内置变量 — 客户端的ip；\nzone：就是这块空间的名字，这个需要和location的配置相对应；\nsize：就是申请空间的大小。\nlimit_conn指令： # Syntax: limit_conn zone number; Default: - Context: http, server, location 这里有个前提必须在http下先定义好limit_conn_zone才可以在这里引用。 # 这里的zone就是上面zone的名字，number就是同一时间连接的限制数。\n请求频率限制：\nSyntax: limit_req_zone key zone=name:size rate=rate; Default: - Context: http 语法和上面类似，rate为速率限制,以秒为单位多少个。\nlimit_req指令：\nSyntax: limit_req zone=name [burst=number] [nodelay] Default: - Context: http,server,location burst=number，重点说明一下这个配置，burst爆发的意思，这个配置的意思是设置一个大小为number的缓冲区当有大量请求（爆发）过来时，超过了访问频次限制的请求可以先放到这个缓冲区内，起到访问限速的作用\nnodelay，如果设置，超过访问频次而且缓冲区也满了的时候就会直接返回503（Service Temporarily Unavailable）服务暂时不可用，如果没有设置，则所有请求会等待排队。\n这两个默认是不需要配置的。\n配置示例如下：\n$binary_remote_addr表示二进制的IP地址，一个二进制的ip地址在32位机器上占用32个字节，那么1M可以存放多少呢，计算一下，1x1024x1024/32 = 32768，意思就是可以存放32678个ip地址，在一个会话中，比$remote_addr要节约10空间；\nrate=1r/s表示每秒只能有一个请求；\n1、\n把location下的limit配置都注释掉，用ab工具（压力测试工具）测试：\nab -n10000 -c1000 http://192.168.1.6/index.html 这里-n表示请求总数，-c表示同一时间的请求数。\n请求之后所有请求都成功：\n2、\n当只放开limit_req zone=req_zone;注释后，用压测工具ab发起同样的命令后：\n可以看到只成功请求3个，因为req_zone配置的rate为每秒一个请求。\n3、\n当只放开location下limit_req zone=req_zone burst=3 nodelay;注释时，继续发起请求：\n可以看到，成功了6个，比上一次多了3个。burst=3将3个请求放到缓冲区等下一秒执行。\n4、\n当只放开limit_conn conn_zone 1;注释时，使用ab进行测试。此时一个ip只能同一时刻只能建立一个连接。\n","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/nginx%E8%AF%B7%E6%B1%82%E8%BF%9E%E6%8E%A5%E9%99%90%E5%88%B6%E7%AC%94%E8%AE%B0/","section":"Posts","summary":"\u003cp\u003e之前也有写过有关于爬虫的实战练习：\u003ca href=\"http://mp.weixin.qq.com/s?__biz=MjM5MzU5NDYwNA==\u0026amp;mid=2247484158\u0026amp;idx=1\u0026amp;sn=20d37b629a9ae2ae47fa08ae8c9b8c7d\u0026amp;chksm=a695ef7d91e2666b6547fa4cecbc9032cb520a5466eb107b24ab43f48e12d89dbd1d6ea01441\u0026amp;scene=21#wechat_redirect\" target=\"_blank\"\u003ego语言爬取珍爱网\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e当时爬取时当并发过大的时候，请求就会出现卡死的情况。其实这可能就是珍爱网对请求和连接进行了限制。\u003c/p\u003e","title":"nginx请求连接限制笔记","type":"posts"},{"content":"1、\nstub_status模块：\n用于展示nginx处理连接时的状态。\n配置语法如下：\nSyntax：stub_status; Default：默认没有配置 Context：server、location 可以编辑default.conf，加上如下配置：\nvim /etc/nginx/conf.d/default.conf 然后检查配置的正确性：\n#-t 表示检查配置文件；-c表示检查指定的配置文件，默认为/etc/nginx/nginx.conf nginx -t -c /etc/nginx/nginx.conf 这里注意了，虽然修改的是default.conf，但是检查的时候始终还是加载nginx.conf，否则报错：\n因为nginx.conf中include了conf.d目录下的所有.conf文件。\n然后重新加载配置文件：\n#-s表示给master进程发送信号：stop、quit、reopen、reload；-c指定配置文件目录 nginx -s reload -c /etc/nginx/nginx.conf Active connections: 对后端发起的活动连接数；\nServer accepts handled requests: Nginx总共处理了13个连接,成功创建13次握手（证明中间没有失败的），总共处理了7个请求；\nReading: Nginx 读取到客户端的Header信息数；\nWriting: Nginx 返回给客户端的Header信息数；\nWaiting: 开启keep-alive的情况下,这个值等于 active – (reading + writing),意思就是Nginx已经处理完成,正在等候下一次请求指令的驻留连接。\n所以，在访问效率高,请求很快被处理完毕的情况下，Waiting数比较多是正常的。如果reading +writing数较多，则说明并发访问量非常大，正在处理过程中。\n2、\nrandom_index模块：\n指定目录中选择一个随机主页。\n配置语法：\nSyntax：random_index on | off; Default：random_index off;默认是关闭的 Context：location 在location下配置 在配置文件default.conf中加random_index on;并修改很目录为自定义的指定目录。\n在指定目录里放显示三种颜色的html页面：\nblack.html green.html red.html \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;/\u0026gt; \u0026lt;--- title\u0026gt;nginx-test\u0026lt;/--- title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body style=\u0026#34;background-color:red;\u0026#34;\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 然后reload nginx服务：\nsystemctl reload nginx.service 用浏览器访问随着刷新会显示不同颜色的页面。值得注意的是，nginx是不会加载指定目录下隐藏文件的.\n3、\nsub_module模块：\n主要用于HTTP内容替换。\n语法如下：\n1、 Syntax：sub_filter old_string new_string; 把old_string替换为new_string Default：没有配置 Context：http、server、location下配置 把old_string替换为new_string 2、 Syntax：sub_filter_last_modified on|off; Default：sub_filter_last_modified off; Context：http、server、location下配置 表示客户端和服务端交互时，nginx校验服务端内容是否有变更，主要用于缓存场景。 3、 Syntax：sub_filter_once on|off; Default：sub_filter_once on; Context：http、server、location下配置 表示默认匹配字符串个数；默认状态下是匹配第一个。 在指定目录下建一个submodule.html文件：\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;/\u0026gt; \u0026lt;--- title\u0026gt;nginx-test\u0026lt;/--- title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h2\u0026gt;smallsoup test tomcat test tomcat \u0026lt;/h2\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 然后在default.conf中配置这个目录为根目录，并配置sub_filter：\n用于把html中的tomcat修改为nginx，reload nginx后可以看到页面：\n但是只修改了第一个tomcat，第二个没有修改；如果要全部替换，需要配置：\n如果遇到页面上没有替换的情况，可能是浏览器缓存导致，需要强制刷新或者清理缓存后刷新。\n","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/nginx%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%A8%A1%E5%9D%97/","section":"Posts","summary":"\u003cp\u003e\u003cem\u003e\u003cstrong\u003e1、\u003c/strong\u003e\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003estub_status模块：\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e用于展示nginx处理连接时的状态。\u003c/p\u003e","title":"nginx学习之模块","type":"posts"},{"content":" 中间件位于客户机/ 服务器的操作系统之上，管理计算机资源和网络通讯。 是连接两个独立应用程序或独立系统的软件。\nweb请求通过中间件可以直接调用操作系统，也可以经过中间件把请求分发到多个应用上进行逻辑处理。\n因为有了中间件，使得大型网站在规划有了更好的层次性，维护上更加方便。也可以实现负载均衡、安全防护等。\nNginx是一个开源高性能、可靠的HTTP中间件、代理服务，在目前企业中得到了很大的利用。\n今天主要学习下nginx的安装配置，以便于后续学习。\n以下在本地虚拟机上搭建学习。\nlinux环境搭建可以参考：\nvmware上安装linux过程记录\n1、\n检查系统网络是否能连通公网：\nping www.taobao.com 2、\n确认yum源是否配置好，用于下载安装环境基础包：\nyum源配置可以参考：\nyum源配置\n用以下命令测试：\n3、\n确定iptables是否关闭，避免对后续学习验证造成影响，当然也可以设置好对应规则：\n执行命令：\niptables -F iptables -t nat -F 4、\n确认关闭selinux，避免对服务和请求造成影响，建议关闭。\n查看SELinux状态：\n/usr/sbin/sestatus -v ##如果SELinux status参数为enabled即为开启状态 SELinux status: enabled getenforce ##也可以用这个命令检查 关闭SELinux：\n临时关闭（不用重启机器）：\nsetenforce 0 ##设置SELinux 成为permissive模式 ##setenforce 1 设置SELinux 成为enforcing模式 修改配置文件（需要重启机器）：\n修改/etc/selinux/config 文件，将SELINUX=enforcing改为SELINUX=disabled\n5、\n配置nginx的yum源：\nvim /etc/yum.repos.d/nginx.repo [nginx] name=nginx repo baseurl=http://nginx.org/packages/centos/7/$basearch/ gpgcheck=0 enabled=1 6、\n然后执行命令测试：\nyum list | grep nginx 7、\n利用yum安装nginx：\nyum install nginx 安装完毕验证：\n我这里装的是1.14.0版。\n可以用命令查看nginx安装目录：\nrpm -ql nginx 8、\n下面对主要目录做说明：\n/etc/logrotate.d/nginx Nginx日志轮转，用于logrotate服务的日志切割，相当于java中的log4j和logback；\n/etc/nginx /etc/nginx/conf.d /etc/nginx/conf.d/default.conf /etc/nginx/nginx.conf 为Nginx主配置文件；\n/etc/nginx/koi-utf /etc/nginx/koi-win /etc/nginx/win-utf 用于nginx编码转换的配置文件；\n/var/log/nginx 为nginx的访问和错误日志目录；\n/var/cache/nginx/ 为nginx的缓存目录；\n/usr/share/nginx/html 其下放了首页index.html，为nginx的默认首页。\n9、\n利用以下命令启动nginx：\nsystemctl start nginx 然后访问页面：\n默认利用的是/usr/share/nginx/html目录下的index.html\n之后将对nginx做进一步深入学习。\n","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/nginx%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","section":"Posts","summary":"\u003cblockquote\u003e\n\u003cp\u003e中间件位于客户机/ 服务器的操作系统之上，管理计算机资源和网络通讯。 是连接两个独立应用程序或独立系统的软件。\u003c/p\u003e","title":"nginx学习笔记","type":"posts"},{"content":"","date":"2019年10月18日","externalUrl":null,"permalink":"/tags/elasticsearch/","section":"Tags","summary":"","title":"Elasticsearch","type":"tags"},{"content":"以下测试在elasticsearch5.6.10版本。\n首先要说明的是ElasticSearch从2.x开始就已经不支持删除一个type了，所以使用delete命令想要尝试删除一个type的时候会出现如下错误：\nNo handler found for uri [/dating_profile/zhenai/] and method [DELETE] 测试 # 假如存在一个名为dating_profile的index和zhenai的type：\ncurl -XDELETE http://192.168.1.102:9200/dating_profile/zhenai 执行后报错如下：\n所以现在如果想要删除type有两种选择：\n***1、***重新设置index。\n***2、***删除type下的所有数据。\n如果重新设置index，官方建议：\nhttps://www.elastic.co/guide/en/elasticsearch/reference/5.4/indices-delete-mapping.html\nDelete Mapping\nIt is no longer possible to delete the mapping for a type. Instead you should delete the index and recreate it with the new mappings.\n删除index # 如下，删除名为dating_profile的index：\ncurl -XDELETE http://192.168.1.102:9200/dating_profile/ 删除成功，返回值为：\n{ \u0026#34;acknowledged\u0026#34;: true } 删除type下的所有数据 # 想要一次性删除type为zhenai所有数据内容的话，可以参考官方文档：\nhttps://www.elastic.co/guide/en/elasticsearch/reference/5.4/docs-delete-by-query.html\n其中有讲到，可以通过_delete_by_query限制到一个单独的type，如下，它仅仅会删除index为dating_profile下type为zhenai下的所有数据：\ncurl -X POST \u0026#34;http://192.168.1.102:9200/dating_profile/zhenai/_delete_by_query?conflicts=proceed\u0026#34; -H \u0026#39;Content-Type: application/json\u0026#39; -d\u0026#39; { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} } }\u0026#39; 删除成功，返回值如下：\n{ \u0026#34;took\u0026#34;: 78, \u0026#34;timed_out\u0026#34;: false, \u0026#34;total\u0026#34;: 107, \u0026#34;deleted\u0026#34;: 107, \u0026#34;batches\u0026#34;: 1, \u0026#34;version_conflicts\u0026#34;: 0, \u0026#34;noops\u0026#34;: 0, \u0026#34;retries\u0026#34;: { \u0026#34;bulk\u0026#34;: 0, \u0026#34;search\u0026#34;: 0 }, \u0026#34;throttled_millis\u0026#34;: 0, \u0026#34;requests_per_second\u0026#34;: -1.0, \u0026#34;throttled_until_millis\u0026#34;: 0, \u0026#34;failures\u0026#34;: [] } 也可以一次性删除多个index和多个type下的文档，如下：删除index为dating_profile下的type为zhenai的数据；同时删除index为movies下的type为movie的数据。\ncurl -X POST \u0026#34;http://192.168.1.102:9200/dating_profile,movies/zhenai,movie/_delete_by_query\u0026#34; -H \u0026#39;Content-Type: application/json\u0026#39; -d\u0026#39; { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} } } \u0026#39; 返回值如下：\n{ \u0026#34;took\u0026#34;: 93, \u0026#34;timed_out\u0026#34;: false, \u0026#34;total\u0026#34;: 61, \u0026#34;deleted\u0026#34;: 61, \u0026#34;batches\u0026#34;: 1, \u0026#34;version_conflicts\u0026#34;: 0, \u0026#34;noops\u0026#34;: 0, \u0026#34;retries\u0026#34;: { \u0026#34;bulk\u0026#34;: 0, \u0026#34;search\u0026#34;: 0 }, \u0026#34;throttled_millis\u0026#34;: 0, \u0026#34;requests_per_second\u0026#34;: -1.0, \u0026#34;throttled_until_millis\u0026#34;: 0, \u0026#34;failures\u0026#34;: [] } 题外话 # 5.xES提供的Reindex可以直接在搜索集群中对数据进行重建。如下可以直接修改mapping。\n如下将index为dating_profile改为new_dating_profile\ncurl -XPOST \u0026#34;http://192.168.1.102:9200/_reindex?pretty\u0026#34; -H \u0026#39;Content-Type: application/json\u0026#39; -d\u0026#39; { \u0026#34;source\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;dating_profile\u0026#34; }, \u0026#34;dest\u0026#34;: { \u0026#34;index\u0026#34;: \u0026#34;new_dating_profile\u0026#34; } } \u0026#39; 这样执行后，旧的index还是存在的，dating_profile和new_dating_profile都可以查到旧数据。\nElasticSearch＋ELK日志平台全套视频教程等相关学习资源可以在公众号后台回复【1】加小助手索取。\n","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/elasticsearch5.x%E5%88%A0%E9%99%A4%E6%95%B0%E6%8D%AE/","section":"Posts","summary":"\u003cp\u003e以下测试在elasticsearch5.6.10版本。\u003c/p\u003e\n\u003cp\u003e首先要说明的是ElasticSearch从2.x开始就已经不支持删除一个type了，所以使用delete命令想要尝试删除一个type的时候会出现如下错误：\u003c/p\u003e","title":"ElasticSearch5.x 删除数据","type":"posts"},{"content":"","date":"2019年10月18日","externalUrl":null,"permalink":"/tags/golang/","section":"Tags","summary":"","title":"Golang","type":"tags"},{"content":"前段时间有群友在群里问一个go语言的问题：\n就是有一个main.go的main函数里调用了另一个demo.go里的hello()函数。其中main.go和hello.go同属于main包。但是在main.go的目录下执行go run main.go却报hello函数没有定义的错：\n代码结构如下：\n**gopath ---- src** **----gohello** **----hello.go** ** ----main.go** main.go如下：\npackage main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;my name is main\u0026#34;) hello() } hello.go如下：\npackage main import \u0026#34;fmt\u0026#34; func hello() { fmt.Println(\u0026#34;my name is hello\u0026#34;) } 当时我看了以为是他GOPATH配置的有问题，然后自己也按照这样试了一下，报同样的错，在网上查了，也有两篇文章是关于这个错的，也提供了解决方法，即用go run main.go hello.go，试了确实是可以的。\n虽然是个很简单的问题，但是也涉及到了go语言底层对于命令行参数的解析。那就来分析一下语言底层的实现吧，看一下底层做了什么，为什么报这个错？\n分析：\n以下使用到的Go SDK版本为1.8.3\n该版本中go支持的基本命令有以下16个：\nbuild compile packages and dependencies clean remove object files doc show documentation for package or symbol env print Go environment information bug start a bug report fix run go tool fix on packages fmt run gofmt on package sources generate generate Go files by processing source get download and install packages and dependencies install compile and install packages and dependencies list list packages run compile and run Go program test test packages tool run specified go tool version print Go version vet run go tool vet on packages 在Go SDK的src/cmd/go包下有main.go文件中，Command类型的commands数组对该16个命令提供了支持：\n我们首先知道go语言的初始化流程如下：\n在执行main.go中的主函数main之前，对import进来的包按顺序初始化，最后初始化main.go中的类型和变量，当初始化到commands数组时，由于cmdRun定义在于main.go同包下的run.go中，那么就先去初始化run.go中的变量和init方法，如下代码，先把cmdRun初始化为Command类型，然后执行init()函数。\nvar cmdRun = \u0026amp;Command{ UsageLine: \u0026#34;run [build flags] [-exec xprog] gofiles... [arguments...]\u0026#34;, Short: \u0026#34;compile and run Go program\u0026#34;, Long: ` Run compiles and runs the main package comprising the named Go source files. A Go source file is defined to be a file ending in a literal \u0026#34;.go\u0026#34; suffix. By default, \u0026#39;go run\u0026#39; runs the compiled binary directly: \u0026#39;a.out arguments...\u0026#39;. If the -exec flag is given, \u0026#39;go run\u0026#39; invokes the binary using xprog: \u0026#39;xprog a.out arguments...\u0026#39;. If the -exec flag is not given, GOOS or GOARCH is different from the system default, and a program named go_$GOOS_$GOARCH_exec can be found on the current search path, \u0026#39;go run\u0026#39; invokes the binary using that program, for example \u0026#39;go_nacl_386_exec a.out arguments...\u0026#39;. This allows execution of cross-compiled programs when a simulator or other execution method is available. For more about build flags, see \u0026#39;go help build\u0026#39;. See also: go build. `, } func init() { cmdRun.Run = runRun // break init loop addBuildFlags(cmdRun) cmdRun.Flag.Var((*stringsFlag)(\u0026amp;execCmd), \u0026#34;exec\u0026#34;, \u0026#34;\u0026#34;) } init()中，将runRun（其实类型是一个方法，用于处理run后的参数）赋值给cmdRu.run，addBuildFlags(cmdRun)主要是给run后面增加命令行参数（如：-x是打印其执行过程中用到的所有命令，同时执行它们）。其他15个命令和cmdRun类似，各有各的run实现。\n下来主要看main.go中main的这块代码：\nfor _, cmd := range commands { if cmd.Name() == args[0] \u0026amp;\u0026amp; cmd.Runnable() { cmd.Flag.Usage = func() { cmd.Usage() } if cmd.CustomFlags { args = args[1:] } else { cmd.Flag.Parse(args[1:]) args = cmd.Flag.Args() } cmd.Run(cmd, args) exit() return } } 这块代码遍历commands数组，当遍历到cmdRun时，cmd.Name()其实就是拿到cmdRun.UsageLine的第一个单词run\n就会进入if分支，由于cmd.CustomFlags没有初始化故为false，走else分支，然后开始解析args命令行参数，args[1:]即取run后的所有参数。然后去执行cmd.Run(cmd, args)，对于cmdRun来说，这里执行的就是run.go中init()的第一行赋值cmdRun.run（上面说了，这是一个函数，不同命令实现方式不同)，即去执行run.go中的runRun函数，该函数主要是将命令行参数当文件去处理，如果是_test为后缀的，即测试文件，直接报错。如果是目录也直接报错（而且go run后面只能包含一个含main函数的go文件）。注意到有这么一行：\np := goFilesPackage(files) goFilesPackage(files)除了校验文件类型和后缀，还会入栈，加载，出栈等操作，由于启动的时候没有传递hello.go，所以系统加载main.go时找不到hello函数，导致报错。\n","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/golang%E5%88%9D%E6%8E%A2%E4%B8%8E%E5%91%BD%E4%BB%A4%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","section":"Posts","summary":"\u003cp\u003e前段时间有群友在群里问一个go语言的问题：\u003c/p\u003e\n\u003cp\u003e就是有一个main.go的main函数里调用了另一个demo.go里的hello()函数。其中main.go和hello.go同属于main包。但是在main.go的目录下执行go run main.go却报hello函数没有定义的错：\u003c/p\u003e","title":"golang初探与命令源码分析","type":"posts"},{"content":"","date":"2019年10月18日","externalUrl":null,"permalink":"/tags/docker/","section":"Tags","summary":"","title":"Docker","type":"tags"},{"content":"公有仓库和私有仓库：\n**速度：**公有仓库走的公网，速度较慢；私有仓库走的是内网，即局域网；\n**安全性：**公有仓库存放在公共硬盘上；私有仓库存在自己服务器硬盘上。\n公有仓：\n最权威的，但速度比较慢：\nhttps://hub.docker.com/\n首先登陆：\n$ docker login -usmallsoup Password: WARNING! Your password will be stored unencrypted in /root/.docker/config.json. Configure a credential helper to remove this warning. See https://docs.docker.com/engine/reference/commandline/login/#credentials-store Login Succeeded 打标签，push镜像到hub仓库：\ndocker tag zookeeper:3.5 smallsoup/zookeeper:3.5 docker push smallsoup/zookeeper:3.5 已push成功，可以在hub上看到：\n私有仓：\n用docker提供的registry在本地搭建私有仓：\ndocker pull registry:2.5.2 docker run -d -p 5000:5000 registry:2.5.2 docker tag zookeeper:3.5 localhost:5000/zookeeper:3.5 docker push zookeeper:3.5 localhost:5000/zookeeper:3.5 因没有设置安全性，所以直接可以push上去。\n由于是本地仓库，所以pull的速度很快。\n[root@localhost micro-service]# docker pull localhost:5000/zookeeper:3.5 3.5: Pulling from zookeeper Digest: sha256:3474ec46da9db9dc27a431f9645a2df9c91d5b969f591fe0ccd4c40f2bfd1579 Status: Image is up to date for localhost:5000/zookeeper:3.5 但是这个私有仓不能满足我们的需求，生产线上万一该私有仓服务器故障，其他服务器也无法接管。再者，也没有页面可以便于管理。\n业内出现的harbor，主要提供 Dcoker Registry 管理UI，可基于角色访问控制, AD/LDAP 集成，日志审核等功能，完全的支持中文，非常适用于生产环境。\nharbor私有仓库搭建\ngithub地址：\nhttps://github.com/goharbor/harbor/releases\n下载地址：\nhttps://storage.googleapis.com/harbor-releases/harbor-offline-installer-v1.5.3.tgz\n这个链接速度太慢，可以在这里下载：\nhttp://harbor.orientsoft.cn/\n以下使用的harbor版本是harbor-offline-installer-v1.5.0.tgz\n首先解压：\ntar -zxf harbor-offline-installer-v1.5.0.tgz 然后运行./install脚本进行安装，如果需要特殊设置，可以先修改harbor.cfg和docker-compose.yml后在进行./install安装操作\n[Step 4]: starting Harbor ... Creating network \u0026#34;harbor_harbor\u0026#34; with the default driver Creating harbor-log ... done Creating harbor-adminserver ... Creating redis ... error Creating harbor-db ... Creating registry ... Creating harbor-adminserver ... done ERROR: for redis Cannot create container for service redis: b\u0026#39;Conflict. The container name \u0026#34;/redis\u0026#34; is already in use Creating harbor-db ... done Creating registry ... done Creating harbor-ui ... done Creating nginx ... done ERROR: for redis Cannot create container for service redis: b\u0026#39;Conflict. The container name \u0026#34;/redis\u0026#34; is already in use by container \u0026#34;c3813d66ccad284d3529227fabf3d5c19cb991237de8d3e72fc470ffd2cbfa99\u0026#34;. You have to remove (or rename) that container to be able to reuse that name.\u0026#39; ERROR: Encountered errors while bringing up the project. 安装过程中报以上错误，是因为服务器上已经有了名为redis的容器名，和harbor将要安装的redis容器名重名，需要rename服务器上已有的redis容器名为micro-service-redis：\n$ docker ps -a --filter name=redis CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES c3813d66ccad hub.c.163.com/public/redis:2.8.4 \u0026#34;/run.sh\u0026#34; 2 days ago Up 42 hours 0.0.0.0:6379-\u0026gt;6379/tcp redis $ docker rename redis micro-service-redis $ docker ps -aq --filter name=redis c3813d66ccad $ docker ps -a --filter name=redis CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES c3813d66ccad hub.c.163.com/public/redis:2.8.4 \u0026#34;/run.sh\u0026#34; 2 days ago Up 42 hours 0.0.0.0:6379-\u0026gt;6379/tcp micro-service-redis 然后重新执行./install\n[Step 4]: starting Harbor ... Creating network \u0026#34;harbor_harbor\u0026#34; with the default driver Creating harbor-log ... done Creating redis ... done Creating harbor-db ... done Creating harbor-adminserver ... done Creating registry ... done Creating harbor-ui ... done Creating harbor-jobservice ... Creating nginx ... ERROR: for harbor-jobservice UnixHTTPConnectionPool(host=\u0026#39;localhost\u0026#39;, port=None): Read timed out. (read timeout=60) ERROR: for nginx UnixHTTPConnectionPool(host=\u0026#39;localhost\u0026#39;, port=None): Read timed out. (read timeout=60) ERROR: for jobservice UnixHTTPConnectionPool(host=\u0026#39;localhost\u0026#39;, port=None): Read timed out. (read timeout=60) ERROR: for proxy UnixHTTPConnectionPool(host=\u0026#39;localhost\u0026#39;, port=None): Read timed out. (read timeout=60) ERROR: An HTTP request took too long to complete. Retry with --verbose to obtain debug information. If you encounter this issue regularly because of slow network conditions, consider setting COMPOSE_HTTP_TIMEOUT to a hig 又报以上的错，可能是由于网络问题，导致失败，重新./install试试：\n[Step 4]: starting Harbor ... Creating network \u0026#34;harbor_harbor\u0026#34; with the default driver Creating harbor-log ... done Creating redis ... done Creating harbor-db ... done Creating harbor-adminserver ... done Creating registry ... done Creating harbor-ui ... done Creating nginx ... done Creating harbor-jobservice ... done ✔ ----Harbor has been installed and started successfully.---- Now you should be able to visit the admin portal at http://hub.smallsoup.com. For more details, please visit https://github.com/vmware/harbor . 成功了。\n可以访问harbor部署服务器IP:docker-compose.yml中80映射到宿主机上的端口；\n用户名是admin，密码是harbor.cfg中harbor_admin_password的值访问管理页面：\n可以创建一个私有仓库micro-service：\n在系统管理-\u0026gt;用户管理中添加用户，然后点开上一步创建的项目\u0026ndash;\u0026raquo;成员\u0026ndash;\u0026raquo;新建成员，并设置权限。\n项目管理员：有pull和push以及项目其他管理权限；\n开发人员：有pull和push权限；\n访客：只有pull权限。\n访客：只有pul\n将该项目的各个微服务image push到harbor的micro-service项目里：\n$ docker images |grep -v \u0026#34;vmware\u0026#34; REPOSITORY TAG IMAGE ID CREATED SIZE api-gateway-zuul latest 8a814cf9bb65 23 hours ago 476MB course-service latest 673d4501353e 23 hours ago 462MB course-edge-service latest 854d5d8bddaa 23 hours ago 484MB message-thrift-python-service latest 4317a76b387e 24 hours ago 926MB user-edge-service latest ff07d54a02ba 25 hours ago 469MB user-thrift-service latest 02dd6fd0f239 26 hours ago 456MB python-base latest 81ad8926a9d9 26 hours ago 926MB zookeeper 3.5 c41e1dcd86e4 2 weeks ago 128MB smallsoup/zookeeper 3.5 c41e1dcd86e4 2 weeks ago 128MB localhost:5000/zookeeper 3.5 c41e1dcd86e4 2 weeks ago 128MB elasticsearch latest 5acf0e8da90b 2 weeks ago 486MB registry 2.5.2 96ca477b7e56 3 weeks ago 37.8MB registry 2 2e2f252f3c88 3 weeks ago 33.3MB python 3.6 4f13b7f2138e 4 weeks ago 918MB openjdk 8-jre 66bf39162ea7 4 weeks ago 443MB mysql latest 6a834f03bd02 4 weeks ago 484MB hub.c.163.com/public/redis 2.8.4 4888527e1254 2 years ago 190MB 打标签：\ndocker tag openjdk:8-jre 192.168.1.103:80/micro-service/openjdk:8-jre 查看镜像：\n$ docker images |grep -v \u0026#34;vmware\u0026#34; | grep open openjdk 7-jre e4c851ec3393 4 weeks ago 329MB 192.168.1.103:80/micro-service/openjdk 8-jre 66bf39162ea7 4 weeks ago 443MB openjdk push镜像：\n$ docker push 192.168.1.103:80/micro-service/openjdk:8-jre The push refers to repository [192.168.1.103:80/micro-service/openjdk] Get https://192.168.1.103:80/v2/: http: server gave HTTP response to HTTPS client push报错。由于默认采用的是http协议，即harbor.cfg中的ui_url_protocol值。https的比较麻烦，需要生成证书等步骤，可以参考：\n为Harbor设置Https\nhttp://gapme.cn/2017/10/25/harbor-ui-https/\n这里暂且用http的方式。\n以上报错解决办法：\n在”/etc/docker/“目录下，创建”daemon.json“文件。在文件中写入：\n{ \u0026#34;insecure-registries\u0026#34;: [ \u0026#34;hub.smallsoup.com:80\u0026#34;, \u0026#34;192.168.1.103:80\u0026#34; ] } 重启docker：\nsystemctl restart docker docker重启后，./install或者docker-compose down;docker-compose up -d重启harbor即可。\n将基础镜像和各个服务镜像push到库上：\n题外话：\n在安装过程中，将80端口映射到宿主机的8081端口，push的时候遇到很多问题（报错80端口连接拒绝，大概就是这个issue\nhttps://github.com/goharbor/harbor/issues/192），查找了很多资料，还是放弃了，最后映射到宿主机80端口，push一切ok。\n由于用域名的方式push得设置hosts以及端口转发，比较麻烦，以上采用了IP:PORT方式：\n删除用域名打的标签：\ndocker rmi -f hub.smallsoup.com:80/micro-service/openjdk:8-jre harbor也可以在公众号后台回复【2】加小编微信索取。\n","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/%E6%90%AD%E5%BB%BA%E4%B8%AA%E7%A7%81%E6%9C%89docker%E9%95%9C%E5%83%8F%E4%BB%93%E5%BA%93/","section":"Posts","summary":"\u003cp\u003e\u003cstrong\u003e公有仓库和私有仓库：\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e**速度：**公有仓库走的公网，速度较慢；私有仓库走的是内网，即局域网；\u003c/p\u003e","title":"搭建个私有docker镜像仓库","type":"posts"},{"content":"Kubernetes 审计功能提供了与安全相关的按时间顺序排列的记录集，记录单个用户、管理员或系统其他组件影响系统的活动顺序。它能帮助集群管理员处理以下问题：\n发生了什么？\n什么时候发生的？\n谁触发的？\n为什么发生？\n在哪观察到的？\n它从哪触发的？\n它将产生什么后果？\nKube-apiserver 执行审计。每个执行阶段的每个请求都会生成一个事件，然后根据特定策略对事件进行预处理并写入后端。\n每个请求都可以用相关的 “stage” 记录。已知的 stage 有：\n**RequestReceived -**事件的 stage 将在审计处理器接收到请求后，并且在委托给其余处理器之前生成。\nResponseStarted - 在响应消息的头部发送后，但是响应消息体发送前。这个 stage 仅为长时间运行的请求生成（例如 watch）。\nResponseComplete - 当响应消息体完成并且没有更多数据需要传输的时候。\nPanic - 当 panic 发生时生成。\nNote:\n审计日志记录功能会增加 API server的内存消耗，因为需要为每个请求存储审计所需的某些上下文。此外，内存消耗取决于审计日志记录的配置。\n审计策略 # 审计政策定义了关于应记录哪些事件以及应包含哪些数据的规则。处理事件时，将按顺序与规则列表进行比较。第一个匹配规则设置事件的 [审计级别][auditing-level]。已知的审计级别有：\n**None -**符合这条规则的日志将不会记录。\n**Metadata -**记录请求的 metadata（请求的用户、timestamp、resource、verb 等等），但是不记录请求或者响应的消息体。\n**Request -**记录事件的 metadata 和请求的消息体，但是不记录响应的消息体。这不适用于非资源类型的请求。\n**RequestResponse -**记录事件的 metadata，请求和响应的消息体。这不适用于非资源类型的请求。\n您可以使用 \u0026ndash;audit-policy-file 标志将包含策略的文件传递给 kube-apiserver。如果不设置该标志，则不记录事件。注意 rules 字段必须在审计策略文件中提供。\n以下是一个审计策略文件的示例：\naudit/audit-policy.yaml apiVersion: audit.k8s.io/v1beta1 # This is required. kind: Policy # Don\u0026#39;t generate audit events for all requests in RequestReceived stage. omitStages: - \u0026#34;RequestReceived\u0026#34; rules: # Log pod changes at RequestResponse level - level: RequestResponse resources: - group: \u0026#34;\u0026#34; # Resource \u0026#34;pods\u0026#34; doesn\u0026#39;t match requests to any subresource of pods, # which is consistent with the RBAC policy. resources: [\u0026#34;pods\u0026#34;] # Log \u0026#34;pods/log\u0026#34;, \u0026#34;pods/status\u0026#34; at Metadata level - level: Metadata resources: - group: \u0026#34;\u0026#34; resources: [\u0026#34;pods/log\u0026#34;, \u0026#34;pods/status\u0026#34;] # Don\u0026#39;t log requests to a configmap called \u0026#34;controller-leader\u0026#34; - level: None resources: - group: \u0026#34;\u0026#34; resources: [\u0026#34;configmaps\u0026#34;] resourceNames: [\u0026#34;controller-leader\u0026#34;] # Don\u0026#39;t log watch requests by the \u0026#34;system:kube-proxy\u0026#34; on endpoints or services - level: None users: [\u0026#34;system:kube-proxy\u0026#34;] verbs: [\u0026#34;watch\u0026#34;] resources: - group: \u0026#34;\u0026#34; # core API group resources: [\u0026#34;endpoints\u0026#34;, \u0026#34;services\u0026#34;] # Don\u0026#39;t log authenticated requests to certain non-resource URL paths. - level: None userGroups: [\u0026#34;system:authenticated\u0026#34;] nonResourceURLs: - \u0026#34;/api*\u0026#34; # Wildcard matching. - \u0026#34;/version\u0026#34; # Log the request body of configmap changes in kube-system. - level: Request resources: - group: \u0026#34;\u0026#34; # core API group resources: [\u0026#34;configmaps\u0026#34;] # This rule only applies to resources in the \u0026#34;kube-system\u0026#34; namespace. # The empty string \u0026#34;\u0026#34; can be used to select non-namespaced resources. namespaces: [\u0026#34;kube-system\u0026#34;] # Log configmap and secret changes in all other namespaces at the Metadata level. - level: Metadata resources: - group: \u0026#34;\u0026#34; # core API group resources: [\u0026#34;secrets\u0026#34;, \u0026#34;configmaps\u0026#34;] # Log all other resources in core and extensions at the Request level. - level: Request resources: - group: \u0026#34;\u0026#34; # core API group - group: \u0026#34;extensions\u0026#34; # Version of group should NOT be included. # A catch-all rule to log all other requests at the Metadata level. - level: Metadata # Long-running requests like watches that fall under this rule will not # generate an audit event in RequestReceived. omitStages: - \u0026#34;RequestReceived\u0026#34; 也可以使用最低限度的审计策略文件在 Metadata 级别记录所有请求：\n# Log all requests at the Metadata level. apiVersion: audit.k8s.io/v1beta1 kind: Policy rules: - level: Metadata 审计日志后端 # k8s目前提供两种日志后端，Log后端和webhook后端，Log后端可以将日志输出到文件，webhook后端将日志发送到远端日志服务器，接下来暂且只对Log后端日志的记录配置和采集做一下实践。\n以下实践组件版本docker ce17，k8s 1.9.2\n可以使用以下 kube-apiserver 标志配置 Log 审计后端：\n\u0026ndash;audit-log-path指定用来写入审计事件的日志文件路径。不指定此标志会禁用日志后端。- 意味着标准化\n\u0026ndash;audit-log-maxage定义了保留旧审计日志文件的最大天数\n\u0026ndash;audit-log-maxbackup定义了要保留的审计日志文件的最大数量\n\u0026ndash;audit-log-maxsize定义审计日志文件的最大大小（兆字节）\n我司目前集群中kube-apiserver组件作为static pod方式运行，生命周期由kubelet直接管理，static pod由kebelet根据yaml文件创建，yaml存放路径为/etc/kubernetes/manifests/目录，其中apiserver由kubelet根据kube-apiserver.yaml创建，Log后端需要在kube-apiserver.yaml的启动参数里加以下参数：\n--feature-gates=AdvancedAuditing=true --audit-policy-file=/etc/kubernetes/pki/audit-policy.yaml --audit-log-format=json --audit-log-path=/var/log/kubernetes/kubernetes-audit --audit-log-maxage=30 --audit-log-maxbackup=3 --audit-log-maxsize=100 说明：\nAdvancedAuditing指明启用高级审计功能，即：可以使\u0026ndash;audit-policy-file参数指定审计策略，该参数从k8s 1.8版本以后默认为true；\naudit-policy-file指定策略文件的位置，该路径为kube-apiserver容器内的路径，所以得从宿主机挂载策略文件到容器内，故暂且放在/etc/kubernetes/pki/目录下；\naudit-log-format指定最终审计日志的格式为json，该参数默认为json；\naudit-log-path指定最终审计日志存放在容器内的位置，该位置会自动创建。上述表示最终的审计日志文件为kubernetes-audit\n最终配置如下：\n修改完成后，kubelet会自动删除重建kube-apiserver的pod（如果pod被删除后，过几分钟还不被创建，可以修改\u0026ndash;audit-log-maxbackup的值保存退出，等待pod被创建\u0026mdash;这可能是一个bug），重启状态变为running后可以进入容器查看生成的审计日志文件：\n查看该日志：\n达到100M后：\n因为后面要用fluentd作为agent去采集该日志，所以需要把容器内的日志挂载到宿主机目录下，修改kube-apiserver.yaml如下，即将容器内/var/log/kubernetes目录挂载到宿主机的/var/log/kubernetes目录。\n日志采集 # 目前集群中已部署了fluentd elasticsearch日志方案，所以选用fluentd作为 Logging-agent ，Elasticsearch作为 Logging Backend 。集群中的fluentd-es作为DaemonSet 方式运行，根据DaemonSet的特性，应该在每个Node上都会运行fluentd-es的pod，但实际情况是19环境上3个master节点都没有该pod。查看名为fluentd-es-v1.22的DaemonSet yaml可以发现，pod只会运行在有alpha.kubernetes.io/fluentd-ds-ready: “true”标签的node上：\n查看master节点的node yaml，发现确实没有该标签。故需要在master节点node上添加该标签：\n添加完label后，可以看到在docker-vm-6节点上pod会被自动创建。\nFluentd的配置文件在容器内的/etc/td-agent/td-agent.conf中配置，部分配置截图如下：\n该配置由名为fluentd的ConfigMap指定：\n可以看到配置里并不会去采集、转发审计日志/var/log/kubernetes/kubernetes-audit，所以需要在该ConfigMap中添加以下配置：\n添加后的截图如下：\n之后需要重启一下kube-apiserver节点的fluentd pod，fluentd采集时，也会输出日志到宿主机的/var/log/fluentd.log里，可以看到错误日志等信息，用于定位问题。如果该文件没有审计日志相关错误，日志应该就会被发送到logging-backend：elasticsearch，可以用以下命令验证：\n先查看elasticsearch的service IP和Port，然后用curl命令调用rest接口查询当前集群中所有index信息： 查询到审计日志信息如下，大概有220万条记录： 详细信息如下，和审计日志文件中记录的一样：\n后续可以用Kibana进行日志展示，Elasticsearch、Fluentd、Kibana即为大名鼎鼎的EFK日志收集方案，还有ELK等，可以根据项目的需求选择适当的组件。\n","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/kubeapiserver%E5%AE%A1%E8%AE%A1%E6%97%A5%E5%BF%97%E8%AE%B0%E5%BD%95%E5%92%8C%E9%87%87%E9%9B%86/","section":"Posts","summary":"\u003cp\u003eKubernetes 审计功能提供了与安全相关的按时间顺序排列的记录集，记录单个用户、管理员或系统其他组件影响系统的活动顺序。它能帮助集群管理员处理以下问题：\u003c/p\u003e","title":"kube-apiserver审计日志记录和采集","type":"posts"},{"content":"","date":"2019年10月18日","externalUrl":null,"permalink":"/tags/jwt/","section":"Tags","summary":"","title":"Jwt","type":"tags"},{"content":" Json Web Token (JWT)，是一个非常轻巧的规范，这个规范允许在网络应用环境间客户端和服务器间较安全的传递信息。该token被设计为紧凑且安全的，特别适用于分布式站点的单点登录（SSO）场景。JWT一般被用来在身份提供者和服务提供者间传递被认证的用户身份信息，以便于从资源服务器获取资源。\n在web应用中，我们提供的API接口，通过GET或者POST方式调用，在调用过程中，就存在着接口认证及数据的安全性问题。例如如下问题：\n1、请求来自哪里，身份是否合法？\n2、请求参数是否被篡改？\n3、客户端请求的唯一性，是否为重复请求攻击（RepeatAttack）？\n传统的Session认证方式 # 在传统的web应用中，服务端成功相应请求者，返回正常的response依赖于服务端通过一种存储机制把每个用户经过认证之后的会话信息（session）记录服务器端，一般记录到内存、磁盘、数据库中，这种方式在请求量和用户量增多的时候无疑会增大服务端的开销；如果是记录在内存中，那每次请求都分发登到该机器上才能授权获取资源，那在分布式系统中就存在着问题；因为是基于Cookie的，如果Cookie被截获，攻击者会盗用身份信息进行发送恶意请求，也就是“跨站请求伪造”（CSRF）。\n基于token的认证方式 # 客户端用用户名和密码经过服务器认证之后，服务器会签发一个token返回给客户端，客户端存储token（一般存在请求头里），并且在之后的请求里附带此token，服务器每次会解签名token，验证通过则返回资源。另外服务端要支持CORS跨来源资源共享）策略，服务器处理完请求之后，会再返回结果中加上Access-Control-Allow-Origin。\njwt的生成 # token是接口的令牌，好比去衙门办事，“衙门口朝南开，有理无钱莫进来”。没有令牌就别想办事。token的验证方法很多，也生成了很多标准，jwt就是一种基于json的RFC 7519。该标准由三部分组成：\nheader\npayload\nsignature\nheader和payload经过base64编码后用点拼接起来。signature是把header和payload编码和拼接后经过加密算法加密，加密时还要一个密码，这个密码保存在服务器端。大致示意图如下：\nHeader：\nhead由两部分组成，一个是token类型，一个是使用的算法，如下类型为jwt，使用的算法是HS256。当然，还有HS384、HS512算法。\n{ \u0026#34;typ\u0026#34;: \u0026#34;JWT\u0026#34;, \u0026#34;alg\u0026#34;: \u0026#34;HS256\u0026#34; } 将以上json进行base64编码，当然编码前将json去格式化，如图：\n生成的编码为：\neyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9 用go语言实现：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;encoding/base64\u0026#34; ) func main() { head1 := `{\u0026#34;typ\u0026#34;:\u0026#34;JWT\u0026#34;,\u0026#34;alg\u0026#34;:\u0026#34;HS256\u0026#34;}` fmt.Println(base64.StdEncoding.EncodeToString([]byte(head1))) } Payload：\npayload 里面是 token 的具体内容，这些内容里面有一些是标准字段，我们也可以添加自定义内容。如下：\n{ \u0026#34;iss\u0026#34;: \u0026#34;smallsoup\u0026#34;, \u0026#34;iat\u0026#34;: 1528902195, \u0026#34;exp\u0026#34;: 1528988638, \u0026#34;aud\u0026#34;: \u0026#34;www.smallsoup.com\u0026#34;, \u0026#34;sub\u0026#34;: \u0026#34;smallsoup@qq.com\u0026#34;, \u0026#34;userId\u0026#34;: \u0026#34;0418\u0026#34; } 这里面的前五个字段都是由JWT的标准所定义的，在jwt标准中都可以找到。\niss: 该JWT的签发者\nsub: 该JWT所面向的用户\naud: 接收该JWT的一方\nexp(expires): 什么时候过期，这里是一个Unix时间戳\niat(issued at): 在什么时候签发的\n最后一个userId表示了用户信息，为自定义字段，我们也可以定义角色等其他字段。以上的json去格式化后的base64编码如下：\neyJpc3MiOiJzbWFsbHNvdXAiLCJpYXQiOjE1Mjg5MDIxOTUsImV4cCI6MTUyODk4ODYzOCwiYXVkIjoid3d3LnNtYWxsc291cC5jb20iLCJzdWIiOiJzbWFsbHNvdXBAcXEuY29tIiwidXNlcklkIjoiMDQxOCJ9 Signature：\nJWT 的最后一部分是 Signature ，这部分内容有三个部分，先是用 Base64 编码的 header.payload ，再用加密算法加密一下，加密的时候要放进去一个 Secret ，这个相当于是一个密码，这个密码秘密地存储在服务端。\nheader\npayload\nsecret\n假设这里secret为mysecret，则用go语言实现代码如下：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;encoding/base64\u0026#34; \u0026#34;crypto/hmac\u0026#34; \u0026#34;crypto/sha256\u0026#34; \u0026#34;strings\u0026#34; ) func main() { head1 := `{\u0026#34;typ\u0026#34;:\u0026#34;JWT\u0026#34;,\u0026#34;alg\u0026#34;:\u0026#34;HS256\u0026#34;}` head1Base64 := base64.StdEncoding.EncodeToString([]byte(head1)) payload1 := `{\u0026#34;iss\u0026#34;:\u0026#34;smallsoup\u0026#34;,\u0026#34;iat\u0026#34;:1528902195,\u0026#34;exp\u0026#34;:1528988638,\u0026#34;aud\u0026#34;:\u0026#34;www.smallsoup.com\u0026#34;,\u0026#34;sub\u0026#34;:\u0026#34;smallsoup@qq.com\u0026#34;,\u0026#34;userId\u0026#34;:\u0026#34;0418\u0026#34;}` payload1Base64 := base64.StdEncoding.EncodeToString([]byte(payload1)) encodedstring := head1Base64 \u0026#34;.\u0026#34; payload1Base64 hash := hmac.New(sha256.New, []byte(\u0026#34;mysecret\u0026#34;)) hash.Write([]byte(encodedstring)) signature := strings.TrimRight(base64.URLEncoding.EncodeToString(hash.Sum(nil)), \u0026#34;=\u0026#34;) fmt.Printf(signature) } 运行结果为：\nfjjbA93FTcE71hz_cyIzCUFYdTdyl9hA0w7Pa0ltduc 最后这个在服务端生成并且要发送给客户端的 Token 看起来像这样：\neyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJzbWFsbHNvdXAiLCJpYXQiOjE1Mjg5MDIxOTUsImV4cCI6MTUyODk4ODYzOCwiYXVkIjoid3d3LnNtYWxsc291cC5jb20iLCJzdWIiOiJzbWFsbHNvdXBAcXEuY29tIiwidXNlcklkIjoiMDQxOCJ9.fjjbA93FTcE71hz_cyIzCUFYdTdyl9hA0w7Pa0ltduc 实际上https://jwt.io/这个网站提供了这个能力，以及各种语言的生成token和解密token的库。\ngo语言生成token和解析token：\n下面是go语言版的生成token和解析token的案例：\npackage main import ( \u0026#34;github.com/dgrijalva/jwt-go\u0026#34; \u0026#34;fmt\u0026#34; ) func main() { hmacSampleSecret := []byte(\u0026#34;mysecret\u0026#34;) // Create a new token object, specifying signing method and the claims // you would like it to contain. token := jwt.NewWithClaims(jwt.SigningMethodHS256, jwt.MapClaims{ \u0026#34;iss\u0026#34;: \u0026#34;smallsoup\u0026#34;, \u0026#34;iat\u0026#34;: 1528902195, \u0026#34;exp\u0026#34;: 1528988638, \u0026#34;aud\u0026#34;: \u0026#34;www.smallsoup.com\u0026#34;, \u0026#34;sub\u0026#34;: \u0026#34;smallsoup@qq.com\u0026#34;, \u0026#34;userId\u0026#34;: \u0026#34;0418\u0026#34;, }) // Sign and get the complete encoded token as a string using the secret tokenString, err := token.SignedString(hmacSampleSecret) fmt.Println(tokenString, err) token, err = jwt.Parse(tokenString, func(token *jwt.Token) (interface{}, error) { // Don\u0026#39;t forget to validate the alg is what you expect: if _, ok := token.Method.(*jwt.SigningMethodHMAC); !ok { return nil, fmt.Errorf(\u0026#34;Unexpected signing method: %v\u0026#34;, token.Header[\u0026#34;alg\u0026#34;]) } // hmacSampleSecret is a []byte containing your secret, e.g. []byte(\u0026#34;my_secret_key\u0026#34;) return hmacSampleSecret, nil }) if claims, ok := token.Claims.(jwt.MapClaims); ok \u0026amp;\u0026amp; token.Valid { fmt.Println(claims) } else { fmt.Println(err) } } 具体可以了解github上以下代码的实现。\ngo get github.com/dgrijalva/jwt-go ","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/%E6%B5%85%E8%B0%88jsonwebtoken%E5%8F%8A%E5%BA%94%E7%94%A8/","section":"Posts","summary":"\u003cblockquote\u003e\n\u003cp\u003eJson Web Token (JWT)，是一个非常轻巧的规范，这个规范允许在网络应用环境间客户端和服务器间较安全的传递信息。该token被设计为紧凑且安全的，特别适用于分布式站点的单点登录（SSO）场景。JWT一般被用来在身份提供者和服务提供者间传递被认证的用户身份信息，以便于从资源服务器获取资源。\u003c/p\u003e","title":"浅谈json web token及应用","type":"posts"},{"content":"","date":"2019年10月18日","externalUrl":null,"permalink":"/tags/beego/","section":"Tags","summary":"","title":"Beego","type":"tags"},{"content":"在开始环境搭建之前，我们先一起来看看：\nGo有什么优势：\n不用虚拟机，它可直接编译成机器码，除了glibc外没有其他外部依赖，部署十分方便，就是扔一个文件就完成了。\n天生支持并发，可以充分的利用多核，很容易实现并发。\n25个关键字，但是表达能力很强大，几乎支持大多数你在其他语言见过的特性：继承、重载、对象等。\n内置强大的工具，Go语言里面内置了很多工具链，最好的应该是gofmt工具，自动化格式化代码，能够让团队review变得更加简单。\n跨平台编译，如果你在windows上想生成linux上的可执行文件，只需要一条命令(set GOOS=linux)，即可以做到windows系统编译linux的应用。\nGo适合做什么\n服务器编程，用Go来做很合适，例如处理日志、数据打包、虚拟机处理、文件系统等\n分布式系统，数据库代理器等\n网络编程，这一块目前应用最广，包括Web应用、API应用、下载应用\nGo成功的项目\nnsq：bitly开源的消息队列系统，性能非常高，目前他们每天处理数十亿条的消息\ndocker:基于lxc的一个虚拟打包工具，能够实现PAAS平台的组建\npacker:用来生成不同平台的镜像文件，例如VM、vbox、AWS等，作者是vagrant的作者\nskynet：分布式调度框架\ndoozer：分布式同步工具，类似ZooKeeper\nheka：mazila开源的日志处理系统\ncbfs：couchbase开源的分布式文件系统\ntsuru：开源的PAAS平台，和SAE实现的功能一模一样\ngroupcache：memcahe作者写的用于Google下载系统的缓存系统\ngod：类似redis的缓存系统，但是支持分布式和扩展性\n如果你觉得Go语言很强大，也想去学习它，那么现在可以跟我一起来学习环境搭建过程。\n1、 相关软件准备：\nGit：一个开源的分布式版本控制系统，可以有效、高速的处理从很小到非常大的项目版本管理，分为32和64位安装包。\nGo：go语言安装包，分为32和64位。\nliteIde：国人开发的一款简单、开源、跨平台的 Go 语言IDE。\n2、 安装go安装包：\n1、根据操作系统是32位或64位选择对应的go1.8.3.windows-XXX.msi文件，双击开始安装，一路下一步，即可完成安装。安装到选择目标文件夹时，可以选D盘。\n2、配置环境变量。选择计算机 -\u0026gt; 属性 -\u0026gt; 高级系统设置 -\u0026gt; 环境变量，看系统环境变量里是否有GOROOT（默认刚才安装好后GOROOT是设置好了的，即刚才的安装目录）。为了后续工作的方便，这里配置一下GOPATH，在环境变量里新增一个GOPATH系统变量，如下图所示：\n最后在Path中在添加上” %GOPATH%bin”(默认go安装包安好，这个也是设置好的)如下图所示：\n然后确定就行。\n3、在控制台中查看Go语言环境是否安装完成，windows中，用快捷键\nwin R，输入cmd，打开命令提示符，输入“go”，出现下图即可：\n顺带说一句，Go程序的目录结构是在GOPATH文件夹下的，分为bin, pkg, 和src三个子文件夹 。\nbin文件夹：Go的每个项目生成的二进制可执行程序。windows下会生成.exe文件，linux下会生成可执行文件。Go的最大特色之一就是可移植性，就是说，当生成一个demo.exe之后，将这个exe文件放在任意一台windows系统上（即使没有安装go安装包），也是可以执行的。这是让PHP，Python等脚本语言望成莫及的。\npkg文件夹：第三方库。里面存放你的项目中引用的第三方库（非官方已经提供的库）\nsrc文件夹：每个次级文件夹就是代表一个go项目，里面存放源程序。\n3、 Go语言开发IDE工具LiteIDE的使用：\n解压我们下载好的 liteidex32.1.windows-qt5 ，把liteide文件夹放在你喜欢的位置，找到\\LiteIDE\\bin路径下的liteide.exe，非常帅气的一个太极图标，双击运行即可。\n对于LiteIDE，有一些简单的设置：（以windows10的64位版本为例）\n1、如下，选择win64，这个选项决定编译后生成哪个平台的可执行文件。这里选择win64，编译后将生成exe文件。\n2、点击如下图标，查看GOROOT的路径是否为Go的安装路径。\n3、点击如下图标查看GOPATH，确定系统GOPATH是否为刚才环境变量里设置的GOPATH，点击确定。\n然后重启liteIDE即可。\n国人大牛Visualfc制作的这个IDE真的很帅气，智能提示、各种调试都有，速度也很快。\n4、 Git工具安装：\n双击安装我们下载的Git-2.15.1.2-XX-bit.exe，一路下一步安装。安装完成后，鼠标右键可以看到如下图标即可：\n5、 Beego框架环境搭建：\nBeego这个框架是国人大牛谢孟军写的轻量级应用框架，在他的书《Go Web编程》中就有对这个框架的说明，各种写的好。\n项目地址如下:\nhttps://github.com/astaxie/beego\n在前面我们安装好了Git，这下要发挥作用了。\n1、安装beego\n右键点击“Git Bash”，输入go get -u -v github.com/astaxie/beego 如下图：\n等一会儿即可。安装完成后，在GOPATH路径下（我这里GOPATH的路径是\nD:\\SoftwareAndProgram\\program\\Go\\Development）在D:\\SoftwareAndProgram\\program\\Go\\Development\\pkg\\windows_amd64\\github.com\\和D:\\SoftwareAndProgram\\program\\Go\\Development\\src\\github.com\\路径下能看到astaxie文件夹，还有下级beego文件夹。\n2、安装bee工具（框架生成工具）\n为了方便的生成框架，右键点击“Git Bash”，输入go get -u -v github.com/beego/bee，如下图：\n同样也是等一会儿即可。完成后，在D:\\SoftwareAndProgram\\program\\Go\\Development\\src\\github.com\\beego路径下能看到bee文件夹。\n同时，在GOPATH路径下的src同级的bin中，有“bee.exe”文件。\n3、使用bee工具生成框架工程代码\n在“开始”中找到“命令提示符”，右键“以管理员身份运行”，先进入到GOPATH的bin路径下，再输入“bee new 工程名”，如下图所示:\n在GOPATH的src目录下会生成以刚才的工程名命名的文件夹。这样一个Beego框架的工程就生成成功了。\n4、使用LiteIDE打开运行。\nLiteIDE的“文件”中找到“打开目录”，找到刚才生成的工程文件夹，如下图：\n点击“选择文件夹”，加载整个工程。\n清晰的MVC一目了然。Ctrl R编译并执行。当然你也可以各种设置断点各种调试。\n打开浏览器，输入“http://127.0.0.1:8080”就看到了运行的结果。\n要结束运行，点击LiteIDE上的“编译输出”后面的红色小按钮即可。\n本文用到的软件，可以关注公众号后，后台回复：go环境搭建 ，获得。\n参考自：http://www.cnblogs.com/iflytek/p/3366282.html\n并加以修正。\n","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/go%E8%AF%AD%E8%A8%80%E5%8F%8Abeego%E6%A1%86%E6%9E%B6%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/","section":"Posts","summary":"\u003cp\u003e在开始环境搭建之前，我们先一起来看看：\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eGo有什么优势：\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e不用虚拟机，它可直接编译成机器码，除了glibc外没有其他外部依赖，部署十分方便，就是扔一个文件就完成了。\u003c/p\u003e","title":"Go语言及Beego框架环境搭建","type":"posts"},{"content":"平时编写代码过程中，经常会遇到对于全局角度只需运行一次的代码，比如全局初始化操作，设计模式中的单例模式。针对单例模式，java中又出现了饿汉模式、懒汉模式，再配合synchronized同步关键字来实现。其目的无非就是将对象只初始化一次，而且最好保证在用到的时候再进行初始化，以避免初始化太早浪费资源，或者两次初始化破坏单例模式的实例唯一性。\nGo语言的sync包中提供了一个Once类型来保证全局的唯一性操作，其通过Do(f func())方法来实现，即使 f 函数发生变化，其也不会被执行，下面我们来看一个小例子：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) var once sync.Once func main() { //once循环调用firstMethod函数10次,其实只执行一次 for i := 0; i \u0026lt; 10; i { once.Do(firstMethod) fmt.Println(\u0026#34;count:---\u0026#34;, i) } //起10个协程,虽然用once去调secondMethod函数,但该函数不会被执行 //只打印------i for i := 0; i \u0026lt; 10; i { go func(i int) { once.Do(secondMethod) fmt.Println(\u0026#34;-----\u0026#34;, i) }(i) } //主协程等1min,等上面的10个协程执行完 time.Sleep(1 * time.Second) } func firstMethod() { fmt.Println(\u0026#34;firstMethod\u0026#34;) } func secondMethod() { fmt.Println(\u0026#34;secondMethod\u0026#34;) } 运行程序输出如下结果：\nfirstMethod count:--- 0 count:--- 1 count:--- 2 count:--- 3 count:--- 4 count:--- 5 count:--- 6 count:--- 7 count:--- 8 count:--- 9 ----- 0 ----- 2 ----- 4 ----- 5 ----- 8 ----- 6 ----- 9 ----- 3 ----- 7 ----- 1 Process finished with exit code 0 然后我们来分析一下：\n程序中首先定义了一个名为once的sync.Once类型，然后main函数中第一个for循环10次，但是由于once.Do(f func)中的f函数全局只执行一次，所以firstMethod()函数只被执行一次；之后进入第二个for循环，这里once.Do(f func)方法的参数变为secondMethod函数。起10个协程去调，但由于once.Do(secondMethod)和once.Do(firstMethod)用的是Once类型的同一个实例，所以secondMethod函数实际上不会被执行。这解释了上面运行结果输出。\n查看源代码once.go，里面有这样的解释：\nif once.Do(f) is called multiple times, only the first call will invoke f,\neven if f has a different value in each invocation. A new instance of\nOnce is required for each function to execute.\n大概意思是：如果once.Do(f)被调用多次，只有第一次调用才会执行f函数，即使f是不同的函数。为了每一个函数都被执行，就需要不同的Once实例。\n我们查看Once类型的定义：\ntype Once struct { m Mutex done uint32 } 源码中其实用到了互斥锁m和标志位done。然后再看Do方法的实现：\nfunc (o *Once) Do(f func()) { if atomic.LoadUint32(\u0026amp;o.done) == 1 { return } // Slow-path. o.m.Lock() defer o.m.Unlock() if o.done == 0 { defer atomic.StoreUint32(\u0026amp;o.done, 1) f() } } 每次调用Do方法之前，用atomic包的LoadUint32函数获取标志位done的值，等于1则说明Do方法已经被调用过，直接return，什么都不做。否则利用互斥锁，保证协程安全的去调用f函数，之后把标志位done置为1。\n下面我们看一个例子，来实现单实例：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) var once sync.Once var mmp map[int]string func main() { for i := 0; i \u0026lt; 10; i { go func(i int) { once.Do(func (){ mmp = make(map[int]string, 10) }) fmt.Printf(\u0026#34;-----%d------%p\\n\u0026#34;, i, \u0026amp;mmp) }(i) } //主协程等1min,等上面的10个协程执行完 time.Sleep(1 * time.Second) } 我们起10个协程去竞争初始化类型为字典类型的mmp，然后打印每次mmp的地址，运行输出如下：\n-----1------0x50cca0 -----3------0x50cca0 -----2------0x50cca0 -----4------0x50cca0 -----7------0x50cca0 -----6------0x50cca0 -----8------0x50cca0 -----9------0x50cca0 -----5------0x50cca0 -----0------0x50cca0 Process finished with exit code 0 我们可以看到mmp每次地址都一样。如此就轻松优雅就实现了和java单例模式相似的效果。\n推荐文章：\njava单例模式\n","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/%E5%88%A9%E7%94%A8golang%E4%BC%98%E9%9B%85%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8D%95%E5%AE%9E%E4%BE%8B/","section":"Posts","summary":"\u003cp\u003e平时编写代码过程中，经常会遇到对于全局角度只需运行一次的代码，比如全局初始化操作，设计模式中的单例模式。针对单例模式，\u003cstrong\u003ejava\u003c/strong\u003e中又出现了饿汉模式、懒汉模式，再配合\u003cstrong\u003esynchronized\u003c/strong\u003e同步关键字来实现。其目的无非就是将对象只初始化一次，而且最好保证在用到的时候再进行初始化，以避免初始化太早浪费资源，或者两次初始化破坏单例模式的实例唯一性。\u003c/p\u003e","title":"利用golang优雅的实现单实例","type":"posts"},{"content":"小强最近在项目中遇到了一个很奇怪的问题：在整改日志规范时，为了避免影响现有的代码结构以及改动尽可能小的前提下，在调用记日志的SDK处将某一个字段值首字母改为大写，代码示例如下：\nfmt.Println(\u0026#34;--------SayHello begin------------\u0026#34;) //项目中这里的a实际是作为参数传入,只是可能为空串,不为空串,这样写肯定没问题 a := \u0026#34;\u0026#34; b := strings.ToUpper(a[:1]) a[1:] fmt.Println(\u0026#34;b is \u0026#34;, b) fmt.Println(\u0026#34;--------SayHello end------------\u0026#34;) this.Ctx.Output.Body(this.Ctx.Input.RequestBody) 项目中这里的a变量其实是作为参数传入，只是可能为空串。a变量不为空串时，这样写肯定没问题。但是当为空串时，即\u0026quot;\u0026ldquo;时，就会出问题，在java中，运行的时候肯定会报一个“数组下表越界”的异常。小强将工程编译后生成二进制文件，放到服务器上跑，测试修改后的日志是否符合规范，验了一遍，没有问题，然后就将代码提交了。\n之后版本出来测试时发现，有个奇怪的现象：接口不返回任何东西，状态码依然是 200 OK。这让小强很纳闷儿，还好，我们的小强经验丰富，还是解决过大bug的人，然后就根据接口走了一遍代码流程，眉头一皱，就知道问题所在了。原来就是a变量有时候传进来是空字符串，导致出现了slice下标越界的panic，说干就干，小强赶紧做了空串的判断逻辑，重新验了一把，问题就解决了。\n小强是爱思考的孩子，不止要解决问题，也要知其所以然。小强在想，出现了panic咋日志里面啥都不打呢，而且还返回200，甚是疑惑。然后就在网上查资料，然后自己又看了beego的源码，就明白了。不得不说，开源就是好啊。\n原来问题是这样，小强项目中使用的beego版本是1.6.1版。\n小强查到了beego的错误处理流程：beego通过beego.App.Server.Handler处理所有的HTTP请求，在beego.Run()函数中，这个Handler就被设置为app.Handlers，可以参见beego1.6.1版本app.go的第95行：\napp.Server.Handler = app.Handlers 而app在一开始就被初始化，可以看app.go中的init()函数，其中调用了NewApp()函数：\n// NewApp returns a new beego application. func NewApp() *App { cr := NewControllerRegister() app := \u0026amp;App{Handlers: cr, Server: \u0026amp;http.Server{}} return app } 可以看出，把cr赋值给Handler，其实cr是ControllerRegister类型，ControllerRegister类型实现了http.Handler接口，具体实现可以看router.go的第600行ServeHTTP方法。该方法中（第612行）有如下语句：\ndefer p.recoverPanic(context) golang语言的错误处理机制是，当在某处调用panic(string)后，panic之后的语句将不再执行，而是通过调用关系逐级退出，在每一级调用处都通过defer处理函数检查是否panic被recover()函数捕获处理，如果没有则继续往上扔panic信息，如果已经被捕获则结束此次panic过程，由捕获panic的函数处继续往下执行。\n出现异常会执行recoverPanic方法，该方法中（第864行）有这样的代码段：\nif BConfig.RunMode == DEV { showErr(err, context, stack) } showErr函数中会对错误进行模板渲染，而小强项目早在现网中投入使用，RunMode为prod，而非dev，所以recover()后不会有错误提示。\n当RunMode为prod时：\n当RunMode为prod时：\ndev模式好歹会返回错误信息：slice bounds out of range\nprod模式没有任何提示。下标越界这种问题看似简单，但是真正遇到了有时候也会摸不着头脑。\n","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/%E4%B8%80%E4%B8%AA%E7%A5%9E%E7%A7%98%E7%8E%B0%E8%B1%A1%E5%BC%95%E5%8F%91%E5%AF%B9beego%E6%A1%86%E6%9E%B6%E7%9A%84%E6%80%9D%E8%80%83/","section":"Posts","summary":"\u003cp\u003e小强最近在项目中遇到了一个很奇怪的问题：在整改日志规范时，为了避免影响现有的代码结构以及改动尽可能小的前提下，在调用记日志的SDK处将某一个字段值首字母改为大写，代码示例如下：\u003c/p\u003e","title":"一个神秘现象引发对beego框架的思考","type":"posts"},{"content":"我们前两节课爬取珍爱网的时候，用到了很多正则表达式去匹配城市列表、城市、用户信息，其实除了正则表达式去匹配，还可以利用goquery和xpath第三方库匹配有用信息。而我利用了更优雅的正则表达式匹配。下来大概介绍下正则表达式。\n比如我们匹配城市列表的时候，会取匹配所有城市的url，如下：\n可以看到图片后是小写字母加数字，那么就可以用以下方式提取：\n\u0026lt;a href=\u0026#34;(http://www.zhenai.com/zhenghun/[0-9a-z] )\u0026#34;[^\u0026gt;]*\u0026gt;([^\u0026lt;] )\u0026lt;/a\u0026gt; [0-9a-z] 表示匹配小写字母或者数字至少一次，[^\u0026gt;]*表示匹配非\u0026gt;的字符任意次，然后[^\u0026lt;] 表示匹配非\u0026lt;字符至少一次。我们要取到城市的url和城市名，所以对进行了分组。\n通过以下方式就可以拿到url和city\nconst ( cityListReg = `\u0026lt;a href=\u0026#34;(http://www.zhenai.com/zhenghun/[0-9a-z] )\u0026#34;[^\u0026gt;]*\u0026gt;([^\u0026lt;] )\u0026lt;/a\u0026gt;` ) compile := regexp.MustCompile(cityListReg) submatch := compile.FindAllSubmatch(contents, -1) for _, m := range submatch { fmt.Println(\u0026#34;url:\u0026#34; , string(m[1]), \u0026#34;city:\u0026#34;, string(m[2])) } 匹配包含g g,且gg中间至少一个小写字母：\n//匹配包含g g,且gg中间至少一个小写字母 match, _ := regexp.MatchString(\u0026#34;g([a-z] )g\u0026#34;, \u0026#34;11golang11\u0026#34;) //true fmt.Println(match) 上面我们直接使用了字符串匹配的正则表达式，但是对于其他的正则匹配任务，需要使用一个优化过的正则对象：\ncompile, err := regexp.Compile(\u0026#34;smallsoup@gmail.com\u0026#34;) if err != nil { //....正则语法错误，需要处理错误 fmt.Println(err) } //smallsoup@gmail.com fmt.Println(compile.FindString(text)) compile, err :=regexp.Compile(\u0026ldquo;smallsoup@gmail.com\u0026rdquo;)\n函数返回一个正则表达式匹配器和错误，当参数正则表达式不符合正则语法时返回error，比如说regexp.Compile(\u0026quot;[smallsoup@gmail.com\u0026quot;)就会报错missing closing ]\n一般正则表达式是用户输入的才需要处理错误，而自己写的一般是不会有错的，所以可以使用compile:= regexp.MustCompile(\u0026ldquo;smallsoup@gmail.com\u0026rdquo;)，如果语法错误，就会发生panic。\ntext1 := `my email is aa@qq.com aa email is aa@gmail.com bb email is bb@qq.com cc email is cc@qq.com.cn ` //如果要提取A@B.C中的A、B、C，需要用到正则表达式的提取功能。 comp := regexp.MustCompile(`([a-zA-Z0-9] )@([a-zA-Z0-9.] )\\.([a-zA-Z0-9] )`) //利用自匹配获取正则表达式里括号中的匹配内容 submatchs := comp.FindAllStringSubmatch(text1, -1) //submatchs其实是一个二维数组 fmt.Println(submatchs) //去除每个匹配,submatch其实还是个slice for _, submatch := range submatchs { fmt.Println(submatch) } 结果输出如下：\n[[aa@qq.com aa qq com] [aa@gmail.com aa gmail com] [bb@qq.com bb qq com] [cc@qq.com.cn cc qq.com cn]] [aa@qq.com aa qq com] [aa@gmail.com aa gmail com] [bb@qq.com bb qq com] [cc@qq.com.cn cc qq.com cn] r := regexp.MustCompile(\u0026#34;p([a-z] )ch\u0026#34;) fmt.Println(r) //-----\u0026gt;p([a-z] )ch //regexp 包也可以用来替换部分字符串为其他值。 fmt.Println(r.ReplaceAllString(\u0026#34;a peach\u0026#34;, \u0026#34;\u0026lt;smallsoup\u0026gt;\u0026#34;)) //-----\u0026gt;a \u0026lt;smallsoup\u0026gt; //Func 变量允许传递匹配内容到一个给定的函数中， in := []byte(\u0026#34;a smallsoup\u0026#34;) out := r.ReplaceAllFunc(in, bytes.ToUpper) fmt.Println(string(out)) //-----\u0026gt;a PEACH /*#######################常见表达式###########################*/ // 查找汉字 testText := \u0026#34;Hello 你好吗, I like golang!\u0026#34; reg := regexp.MustCompile(`[\\p{Han}] `) fmt.Println(reg.FindAllString(testText, -1)) // -----\u0026gt;[你好] reg = regexp.MustCompile(`[\\P{Han}] `) fmt.Println(reg.FindAllString(testText, -1)) // -----\u0026gt;[\u0026#34;Hello \u0026#34; \u0026#34;, I li golang!\u0026#34;] fmt.Printf(\u0026#34;%q\\n\u0026#34;, reg.FindAllString(testText, -1)) // -----\u0026gt;[\u0026#34;Hello \u0026#34; \u0026#34;, I lm golang!\u0026#34;] //Email reg = regexp.MustCompile(`\\w ([- .]\\w )*@\\w ([-.]\\w )*\\.\\w ([-.]\\w )*`) fmt.Println(reg.MatchString(\u0026#34;smallsoup@qq.com\u0026#34;)) //用户名密码： reg = regexp.MustCompile(`[a-zA-Z]|\\w{6,18}`) fmt.Println(reg.MatchString(\u0026#34;w_dy_246\u0026#34;)) 运行结果如下：\np([a-z] )ch a \u0026lt;smallsoup\u0026gt; a smallsoup [你好吗] [Hello , I like golang!] [\u0026#34;Hello \u0026#34; \u0026#34;, I like golang!\u0026#34;] true true Process finished with exit code 0 ","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/go%E8%AF%AD%E8%A8%80%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/","section":"Posts","summary":"\u003cp\u003e我们前两节课爬取珍爱网的时候，用到了很多正则表达式去匹配城市列表、城市、用户信息，其实除了正则表达式去匹配，还可以利用goquery和xpath第三方库匹配有用信息。而我利用了更优雅的正则表达式匹配。下来大概介绍下正则表达式。\u003c/p\u003e","title":"go语言正则表达式","type":"posts"},{"content":"","date":"2019年10月18日","externalUrl":null,"permalink":"/tags/%E7%88%AC%E8%99%AB/","section":"Tags","summary":"","title":"爬虫","type":"tags"},{"content":" 我们来用go语言爬取“珍爱网”用户信息。\n首先分析到请求url为：\nhttp://www.zhenai.com/zhenghun\n接下来用go请求该url，代码如下：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { //返送请求获取返回结果 resp, err := http.Get(\u0026#34;http://www.zhenai.com/zhenghun\u0026#34;) if err != nil { panic(fmt.Errorf(\u0026#34;Error: http Get, err is %v\\n\u0026#34;, err)) } //关闭response body defer resp.Body.Close() if resp.StatusCode != http.StatusOK { fmt.Println(\u0026#34;Error: statuscode is \u0026#34;, resp.StatusCode) return } body, err := ioutil.ReadAll(resp.Body) if err != nil { fmt.Println(\u0026#34;Error read body, error is \u0026#34;, err) } //打印返回值 fmt.Println(\u0026#34;body is \u0026#34;, string(body)) } 运行后会发现返回体里有很多乱码：\n在返回体里可以找到 即编码为gbk，而go默认编码为utf-8，所以就会出现乱码。接下来用第三方库将其编码格式转为utf-8。\n由于访问golang.org/x/text需要梯子，不然报错：\n所以在github上下载：\nmkdir -p $GOPATH/src/golang.org/x cd $GOPATH/src/golang.org/x git clone https://github.com/golang/text.git 然后将gbk编码转换为utf-8，需要修改代码如下：\nutf8Reader := transform.NewReader(resp.Body, simplifiedchinese.GBK.NewDecoder()) body, err := ioutil.ReadAll(utf8Reader) 考虑到通用性，返回的编码格式不一定是gbk，所以需要对实际编码做判断，然后将判断结果转为utf-8，需要用到第三方库golang.org/x/net/html，同样的在github上下载：\nmkdir -p $GOPATH/src/golang.org/x cd $GOPATH/src/golang.org/x git clone https://github.com/golang/net 那么代码就变成这样：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;golang.org/x/text/transform\u0026#34; //\u0026#34;golang.org/x/text/encoding/simplifiedchinese\u0026#34; \u0026#34;io\u0026#34; \u0026#34;golang.org/x/text/encoding\u0026#34; \u0026#34;bufio\u0026#34; \u0026#34;golang.org/x/net/html/charset\u0026#34; ) func main() { //返送请求获取返回结果 resp, err := http.Get(\u0026#34;http://www.zhenai.com/zhenghun\u0026#34;) if err != nil { panic(fmt.Errorf(\u0026#34;Error: http Get, err is %v\\n\u0026#34;, err)) } //关闭response body defer resp.Body.Close() if resp.StatusCode != http.StatusOK { fmt.Println(\u0026#34;Error: statuscode is \u0026#34;, resp.StatusCode) return } //utf8Reader := transform.NewReader(resp.Body, simplifiedchinese.GBK.NewDecoder()) utf8Reader := transform.NewReader(resp.Body, determinEncoding(resp.Body).NewDecoder()) body, err := ioutil.ReadAll(utf8Reader) if err != nil { fmt.Println(\u0026#34;Error read body, error is \u0026#34;, err) } //打印返回值 fmt.Println(\u0026#34;body is \u0026#34;, string(body)) } func determinEncoding(r io.Reader) encoding.Encoding { //这里的r读取完得保证resp.Body还可读 body, err := bufio.NewReader(r).Peek(1024) if err != nil { fmt.Println(\u0026#34;Error: peek 1024 byte of body err is \u0026#34;, err) } //这里简化,不取是否确认 e, _, _ := charset.DetermineEncoding(body, \u0026#34;\u0026#34;) return e } 运行后就看不到乱码了：\n今天先爬到这里，明天将提取返回体中的地址URL和城市，下一节见。\n","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/%E7%94%A8go%E8%AF%AD%E8%A8%80%E7%88%AC%E5%8F%96%E7%8F%8D%E7%88%B1%E7%BD%91%E7%AC%AC%E4%B8%80%E5%9B%9E/","section":"Posts","summary":"\u003cp\u003e\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"image\" src=\"https://img-blog.csdnimg.cn/20191018002129589.jpeg\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e我们来用go语言爬取“珍爱网”用户信息。\u003c/p\u003e\n\u003cp\u003e首先分析到请求url为：\u003c/p\u003e","title":"用go语言爬取珍爱网 | 第一回","type":"posts"},{"content":" 昨天我们一起爬取珍爱网首页，拿到了城市列表页面，接下来在返回体城市列表中提取城市和url，即下图中的a标签里的href的值和innerText值。\n提取a标签，可以通过CSS选择器来选择，如下：\n$(\u0026rsquo;#cityList\u0026gt;dd\u0026gt;a\u0026rsquo;);就可以获取到470个a标签：\n这里只提供一个思路，go语言标准库里没有CSS解析库，通过第三方库可以实现。具体可以参考文章：\nhttps://my.oschina.net/2xixi/blog/488811\nhttp://liyangliang.me/posts/2016/03/zhihu-go-insight-parsing-html-with-goquery/\n这两篇文章都是用goquery解析 HTML，用到了库：\nhttps://github.com/PuerkitoBio/goquery\n也可以用xpath去解析html，可以参考：\nhttps://github.com/antchfx/xquery\nxpath和goquery相比还是比较麻烦的，通过以下这张图可以看出来goquery要活跃的多：\n我们这里不用xpath，也不用goquery提取，用更加通用的正则表达式来提取。\n从上图可以看出，返回体中的a标签里都是这种形式，XXX表示城市拼音，XX表示城市中文，其他的都一样。\n\u0026lt;a href=\u0026#34;http://www.zhenai.com/zhenghun/XXX\u0026#34; class=\u0026#34;\u0026#34;\u0026gt;XX\u0026lt;/a\u0026gt; 所以可以写出以下的正则表达式来匹配：\ncompile := regexp.MustCompile(`\u0026lt;a href=\u0026#34;http://www.zhenai.com/zhenghun/[0-9a-z] \u0026#34;[^\u0026gt;]*\u0026gt;[^\u0026lt;] \u0026lt;/a\u0026gt;`) 正则表达式说明：\n1、href的值都类似http://www.zhenai.com/zhenghun/XX 2、XX可以是数字和小写字母,所以[0-9a-z], 表示至少有一个 3、[^\u0026gt;]*表示匹配不是\u0026gt;的其他字符任意次 4、[^\u0026lt;] 表示匹配不是\u0026lt;的其他字符至少一次 然后利用分组获取url和城市，代码如下：\nfunc printAllCityInfo(body []byte){ //href的值都类似http://www.zhenai.com/zhenghun/XX //XX可以是数字和小写字母,所以[0-9a-z], 表示至少有一个 //[^\u0026gt;]*表示匹配不是\u0026gt;的其他字符任意次 //[^\u0026lt;] 表示匹配不是\u0026lt;的其他字符至少一次 compile := regexp.MustCompile(`\u0026lt;a href=\u0026#34;(http://www.zhenai.com/zhenghun/[0-9a-z] )\u0026#34;[^\u0026gt;]*\u0026gt;([^\u0026lt;] )\u0026lt;/a\u0026gt;`) submatch := compile.FindAllSubmatch(body, -1) for _, matches := range submatch { //打印 fmt.Printf(\u0026#34;City:%s URL:%s\\n\u0026#34;, matches[2], matches[1]) } //可以看到匹配个数为470个 fmt.Printf(\u0026#34;Matches count: %d\\n\u0026#34;, len(submatch)) } 那么提取URL和City的完整代码如下：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;golang.org/x/text/transform\u0026#34; //\u0026#34;golang.org/x/text/encoding/simplifiedchinese\u0026#34; \u0026#34;io\u0026#34; \u0026#34;golang.org/x/text/encoding\u0026#34; \u0026#34;bufio\u0026#34; \u0026#34;golang.org/x/net/html/charset\u0026#34; \u0026#34;regexp\u0026#34; ) func main() { //返送请求获取返回结果 resp, err := http.Get(\u0026#34;http://www.zhenai.com/zhenghun\u0026#34;) if err != nil { panic(fmt.Errorf(\u0026#34;Error: http Get, err is %v\\n\u0026#34;, err)) } //关闭response body defer resp.Body.Close() if resp.StatusCode != http.StatusOK { fmt.Println(\u0026#34;Error: statuscode is \u0026#34;, resp.StatusCode) return } //utf8Reader := transform.NewReader(resp.Body, simplifiedchinese.GBK.NewDecoder()) utf8Reader := transform.NewReader(resp.Body, determinEncoding(resp.Body).NewDecoder()) body, err := ioutil.ReadAll(utf8Reader) if err != nil { fmt.Println(\u0026#34;Error read body, error is \u0026#34;, err) } printAllCityInfo(body) //打印返回值 //fmt.Println(\u0026#34;body is \u0026#34;, string(body)) } func determinEncoding(r io.Reader) encoding.Encoding { //这里的r读取完得保证resp.Body还可读 body, err := bufio.NewReader(r).Peek(1024) if err != nil { fmt.Println(\u0026#34;Error: peek 1024 byte of body err is \u0026#34;, err) } //这里简化,不取是否确认 e, _, _ := charset.DetermineEncoding(body, \u0026#34;\u0026#34;) return e } func printAllCityInfo(body []byte){ //href的值都类似http://www.zhenai.com/zhenghun/XX //XX可以是数字和小写字母,所以[0-9a-z], 表示至少有一个 //[^\u0026gt;]*表示匹配不是\u0026gt;的其他字符任意次 //[^\u0026lt;] 表示匹配不是\u0026lt;的其他字符至少一次 compile := regexp.MustCompile(`\u0026lt;a href=\u0026#34;(http://www.zhenai.com/zhenghun/[0-9a-z] )\u0026#34;[^\u0026gt;]*\u0026gt;([^\u0026lt;] )\u0026lt;/a\u0026gt;`) /*matches := compile.FindAll(body, -1) //matches是二维数组[][]byte for _, m := range matches { fmt.Printf(\u0026#34;%s\\n\u0026#34;, m) } */ submatch := compile.FindAllSubmatch(body, -1) //submatch是三维数组[][][]byte /* for _, matches := range submatch { //[][]byte for _, m := range matches { fmt.Printf(\u0026#34;%s \u0026#34;, m) } fmt.Println() }*/ for _, matches := range submatch { //打印 fmt.Printf(\u0026#34;City:%s URL:%s\\n\u0026#34;, matches[2], matches[1]) } //可以看到匹配个数为470个 fmt.Printf(\u0026#34;Matches count: %d\\n\u0026#34;, len(submatch)) //打印abc //fmt.Printf(\u0026#34;%s\\n\u0026#34;, []byte{97,98,99}) } 运行后，可以看到输出了URL和City：\n今天我们完成了URL和城市的提取，明天我们将利用URL，来进一步分析城市的男女性个人信息。\n","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/%E7%94%A8go%E8%AF%AD%E8%A8%80%E7%88%AC%E5%8F%96%E7%8F%8D%E7%88%B1%E7%BD%91%E7%AC%AC%E4%BA%8C%E5%9B%9E/","section":"Posts","summary":"\u003cp\u003e\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"image\" src=\"https://img-blog.csdnimg.cn/20191018002356226.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9saWFiaW8uYmxvZy5jc2RuLm5ldA==,size_16,color_FFFFFF,t_70\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"image\" src=\"https://img-blog.csdnimg.cn/20191018002355495.gif\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e昨天我们一起爬取珍爱网首页，拿到了城市列表页面，接下来在返回体城市列表中提取城市和url，即下图中的a标签里的href的值和innerText值。\u003c/p\u003e","title":"用go语言爬取珍爱网 | 第二回","type":"posts"},{"content":"前两节我们获取到了城市的URL和城市名，今天我们来解析用户信息。\n用go语言爬取珍爱网 | 第一回\n用go语言爬取珍爱网 | 第二回\n爬虫的算法：\n我们要提取返回体中的城市列表，需要用到城市列表解析器；\n需要把每个城市里的所有用户解析出来，需要用到城市解析器；\n还需要把每个用户的个人信息解析出来，需要用到用户解析器。\n爬虫整体架构：\nSeed把需要爬的request送到engine，engine负责将request里的url送到fetcher去爬取数据，返回utf-8的信息，然后engine将返回信息送到解析器Parser里解析有用信息，返回更多待请求requests和有用信息items，任务队列用于存储待请求的request，engine驱动各模块处理数据，直到任务队列为空。\n代码实现：\n按照上面的思路，设计出城市列表解析器citylist.go代码如下：\npackage parser import ( \u0026#34;crawler/engine\u0026#34; \u0026#34;regexp\u0026#34; \u0026#34;log\u0026#34; ) const ( //\u0026lt;a href=\u0026#34;http://album.zhenai.com/u/1361133512\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;怎么会迷上你\u0026lt;/a\u0026gt; cityReg = `\u0026lt;a href=\u0026#34;(http://album.zhenai.com/u/[0-9] )\u0026#34;[^\u0026gt;]*\u0026gt;([^\u0026lt;] )\u0026lt;/a\u0026gt;` ) func ParseCity(contents []byte) engine.ParserResult { compile := regexp.MustCompile(cityReg) submatch := compile.FindAllSubmatch(contents, -1) //这里要把解析到的每个URL都生成一个新的request result := engine.ParserResult{} for _, m := range submatch { name := string(m[2]) log.Printf(\u0026#34;UserName:%s URL:%s\\n\u0026#34;, string(m[2]), string(m[1])) //把用户信息人名加到item里 result.Items = append(result.Items, name) result.Requests = append(result.Requests, engine.Request{ //用户信息对应的URL,用于之后的用户信息爬取 Url : string(m[1]), //这个parser是对城市下面的用户的parse ParserFunc : func(bytes []byte) engine.ParserResult { //这里使用闭包的方式;这里不能用m[2],否则所有for循环里的用户都会共用一个名字 //需要拷贝m[2] ---- name := string(m[2]) return ParseProfile(bytes, name) }, }) } return result } 城市解析器city.go如下：\npackage parser import ( \u0026#34;crawler/engine\u0026#34; \u0026#34;regexp\u0026#34; \u0026#34;log\u0026#34; ) const ( //\u0026lt;a href=\u0026#34;http://album.zhenai.com/u/1361133512\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;怎么会迷上你\u0026lt;/a\u0026gt; cityReg = `\u0026lt;a href=\u0026#34;(http://album.zhenai.com/u/[0-9] )\u0026#34;[^\u0026gt;]*\u0026gt;([^\u0026lt;] )\u0026lt;/a\u0026gt;` ) func ParseCity(contents []byte) engine.ParserResult { compile := regexp.MustCompile(cityReg) submatch := compile.FindAllSubmatch(contents, -1) //这里要把解析到的每个URL都生成一个新的request result := engine.ParserResult{} for _, m := range submatch { name := string(m[2]) log.Printf(\u0026#34;UserName:%s URL:%s\\n\u0026#34;, string(m[2]), string(m[1])) //把用户信息人名加到item里 result.Items = append(result.Items, name) result.Requests = append(result.Requests, engine.Request{ //用户信息对应的URL,用于之后的用户信息爬取 Url : string(m[1]), //这个parser是对城市下面的用户的parse ParserFunc : func(bytes []byte) engine.ParserResult { //这里使用闭包的方式;这里不能用m[2],否则所有for循环里的用户都会共用一个名字 //需要拷贝m[2] ---- name := string(m[2]) return ParseProfile(bytes, name) }, }) } return result } 用户解析器profile.go如下：\npackage parser import ( \u0026#34;crawler/engine\u0026#34; \u0026#34;crawler/model\u0026#34; \u0026#34;regexp\u0026#34; \u0026#34;strconv\u0026#34; ) var ( // \u0026lt;td\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;年龄：\u0026lt;/span\u0026gt;25岁\u0026lt;/td\u0026gt; ageReg = regexp.MustCompile(`\u0026lt;td\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;年龄：\u0026lt;/span\u0026gt;([\\d] )岁\u0026lt;/td\u0026gt;`) // \u0026lt;td\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;身高：\u0026lt;/span\u0026gt;182CM\u0026lt;/td\u0026gt; heightReg = regexp.MustCompile(`\u0026lt;td\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;身高：\u0026lt;/span\u0026gt;(. )CM\u0026lt;/td\u0026gt;`) // \u0026lt;td\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;月收入：\u0026lt;/span\u0026gt;5001-8000元\u0026lt;/td\u0026gt; incomeReg = regexp.MustCompile(`\u0026lt;td\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;月收入：\u0026lt;/span\u0026gt;([0-9-] )元\u0026lt;/td\u0026gt;`) //\u0026lt;td\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;婚况：\u0026lt;/span\u0026gt;未婚\u0026lt;/td\u0026gt; marriageReg = regexp.MustCompile(`\u0026lt;td\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;婚况：\u0026lt;/span\u0026gt;(. )\u0026lt;/td\u0026gt;`) //\u0026lt;td\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;学历：\u0026lt;/span\u0026gt;大学本科\u0026lt;/td\u0026gt; educationReg = regexp.MustCompile(`\u0026lt;td\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;学历：\u0026lt;/span\u0026gt;(. )\u0026lt;/td\u0026gt;`) //\u0026lt;td\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;工作地：\u0026lt;/span\u0026gt;安徽蚌埠\u0026lt;/td\u0026gt; workLocationReg = regexp.MustCompile(`\u0026lt;td\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;工作地：\u0026lt;/span\u0026gt;(. )\u0026lt;/td\u0026gt;`) // \u0026lt;td\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;职业： \u0026lt;/span\u0026gt;--\u0026lt;/td\u0026gt; occupationReg = regexp.MustCompile(`\u0026lt;td\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;职业： \u0026lt;/span\u0026gt;\u0026lt;span field=\u0026#34;\u0026#34;\u0026gt;(. )\u0026lt;/span\u0026gt;\u0026lt;/td\u0026gt;`) // \u0026lt;td\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;星座：\u0026lt;/span\u0026gt;射手座\u0026lt;/td\u0026gt; xinzuoReg = regexp.MustCompile(`\u0026lt;td\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;星座：\u0026lt;/span\u0026gt;\u0026lt;span field=\u0026#34;\u0026#34;\u0026gt;(. )\u0026lt;/span\u0026gt;\u0026lt;/td\u0026gt;`) //\u0026lt;td\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;籍贯：\u0026lt;/span\u0026gt;安徽蚌埠\u0026lt;/td\u0026gt; hokouReg = regexp.MustCompile(`\u0026lt;td\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;民族：\u0026lt;/span\u0026gt;\u0026lt;span field=\u0026#34;\u0026#34;\u0026gt;(. )\u0026lt;/span\u0026gt;\u0026lt;/td\u0026gt;`) // \u0026lt;td\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;住房条件：\u0026lt;/span\u0026gt;\u0026lt;span field=\u0026#34;\u0026#34;\u0026gt;--\u0026lt;/span\u0026gt;\u0026lt;/td\u0026gt; houseReg = regexp.MustCompile(`\u0026lt;td\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;住房条件：\u0026lt;/span\u0026gt;\u0026lt;span field=\u0026#34;\u0026#34;\u0026gt;(. )\u0026lt;/span\u0026gt;\u0026lt;/td\u0026gt;`) // \u0026lt;td width=\u0026#34;150\u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;grayL\u0026#34;\u0026gt;性别：\u0026lt;/span\u0026gt;男\u0026lt;/td\u0026gt; genderReg = regexp.MustCompile(`\u0026lt;td width=\u0026#34;150\u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;grayL\u0026#34;\u0026gt;性别：\u0026lt;/span\u0026gt;(. )\u0026lt;/td\u0026gt;`) // \u0026lt;td\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;体重：\u0026lt;/span\u0026gt;\u0026lt;span field=\u0026#34;\u0026#34;\u0026gt;67KG\u0026lt;/span\u0026gt;\u0026lt;/td\u0026gt; weightReg = regexp.MustCompile(`\u0026lt;td\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;体重：\u0026lt;/span\u0026gt;\u0026lt;span field=\u0026#34;\u0026#34;\u0026gt;(. )KG\u0026lt;/span\u0026gt;\u0026lt;/td\u0026gt;`) //\u0026lt;h1 class=\u0026#34;ceiling-name ib fl fs24 lh32 blue\u0026#34;\u0026gt;怎么会迷上你\u0026lt;/h1\u0026gt; //nameReg = regexp.MustCompile(`\u0026lt;h1 class=\u0026#34;ceiling-name ib fl fs24 lh32 blue\u0026#34;\u0026gt;([^\\d] )\u0026lt;/h1\u0026gt; `) //\u0026lt;td\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;是否购车：\u0026lt;/span\u0026gt;\u0026lt;span field=\u0026#34;\u0026#34;\u0026gt;未购车\u0026lt;/span\u0026gt;\u0026lt;/td\u0026gt; carReg = regexp.MustCompile(`\u0026lt;td\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;是否购车：\u0026lt;/span\u0026gt;\u0026lt;span field=\u0026#34;\u0026#34;\u0026gt;(. )\u0026lt;/span\u0026gt;\u0026lt;/td\u0026gt;`) ) func ParseProfile(contents []byte, name string) engine.ParserResult { profile := model.Profile{} age, err := strconv.Atoi(extractString(contents, ageReg)) if err != nil { profile.Age = 0 }else { profile.Age = age } height, err := strconv.Atoi(extractString(contents, heightReg)) if err != nil { profile.Height = 0 }else { profile.Height = height } weight, err := strconv.Atoi(extractString(contents, weightReg)) if err != nil { profile.Weight = 0 }else { profile.Weight = weight } profile.Income = extractString(contents, incomeReg) profile.Car = extractString(contents, carReg) profile.Education = extractString(contents, educationReg) profile.Gender = extractString(contents, genderReg) profile.Hokou = extractString(contents, hokouReg) profile.Income = extractString(contents, incomeReg) profile.Marriage = extractString(contents, marriageReg) profile.Name = name profile.Occupation = extractString(contents, occupationReg) profile.WorkLocation = extractString(contents, workLocationReg) profile.Xinzuo = extractString(contents, xinzuoReg) result := engine.ParserResult{ Items: []interface{}{profile}, } return result } //get value by reg from contents func extractString(contents []byte, re *regexp.Regexp) string { m := re.FindSubmatch(contents) if len(m) \u0026gt; 0 { return string(m[1]) } else { return \u0026#34;\u0026#34; } } engine代码如下：\npackage engine import ( \u0026#34;crawler/fetcher\u0026#34; \u0026#34;log\u0026#34; ) func Run(seeds ...Request){ //这里维持一个队列 var requestsQueue []Request requestsQueue = append(requestsQueue, seeds...) for len(requestsQueue) \u0026gt; 0 { //取第一个 r := requestsQueue[0] //只保留没处理的request requestsQueue = requestsQueue[1:] log.Printf(\u0026#34;fetching url:%s\\n\u0026#34;, r.Url) //爬取数据 body, err := fetcher.Fetch(r.Url) if err != nil { log.Printf(\u0026#34;fetch url: %s; err: %v\\n\u0026#34;, r.Url, err) //发生错误继续爬取下一个url continue } //解析爬取到的结果 result := r.ParserFunc(body) //把爬取结果里的request继续加到request队列 requestsQueue = append(requestsQueue, result.Requests...) //打印每个结果里的item,即打印城市名、城市下的人名... for _, item := range result.Items { log.Printf(\u0026#34;get item is %v\\n\u0026#34;, item) } } } Fetcher用于发起http get请求，这里有一点注意的是：珍爱网可能做了反爬虫限制手段，所以直接用http.Get(url)方式发请求，会报403拒绝访问；故需要模拟浏览器方式：\nclient := \u0026amp;http.Client{} req, err := http.NewRequest(\u0026#34;GET\u0026#34;, url, nil) if err != nil { log.Fatalln(\u0026#34;NewRequest is err \u0026#34;, err) return nil, fmt.Errorf(\u0026#34;NewRequest is err %v\\n\u0026#34;, err) } req.Header.Set(\u0026#34;User-Agent\u0026#34;, \u0026#34;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36\u0026#34;) //返送请求获取返回结果 resp, err := client.Do(req) 最终fetcher代码如下：\npackage fetcher import ( \u0026#34;bufio\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;golang.org/x/net/html/charset\u0026#34; \u0026#34;golang.org/x/text/encoding\u0026#34; \u0026#34;golang.org/x/text/encoding/unicode\u0026#34; \u0026#34;golang.org/x/text/transform\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; ) /** 爬取网络资源函数 */ func Fetch(url string) ([]byte, error) { client := \u0026amp;http.Client{} req, err := http.NewRequest(\u0026#34;GET\u0026#34;, url, nil) if err != nil { log.Fatalln(\u0026#34;NewRequest is err \u0026#34;, err) return nil, fmt.Errorf(\u0026#34;NewRequest is err %v\\n\u0026#34;, err) } req.Header.Set(\u0026#34;User-Agent\u0026#34;, \u0026#34;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36\u0026#34;) //返送请求获取返回结果 resp, err := client.Do(req) //直接用http.Get(url)进行获取信息，爬取时可能返回403，禁止访问 //resp, err := http.Get(url) if err != nil { return nil, fmt.Errorf(\u0026#34;Error: http Get, err is %v\\n\u0026#34;, err) } //关闭response body defer resp.Body.Close() if resp.StatusCode != http.StatusOK { return nil, fmt.Errorf(\u0026#34;Error: StatusCode is %d\\n\u0026#34;, resp.StatusCode) } //utf8Reader := transform.NewReader(resp.Body, simplifiedchinese.GBK.NewDecoder()) bodyReader := bufio.NewReader(resp.Body) utf8Reader := transform.NewReader(bodyReader, determineEncoding(bodyReader).NewDecoder()) return ioutil.ReadAll(utf8Reader) } /** 确认编码格式 */ func determineEncoding(r *bufio.Reader) encoding.Encoding { //这里的r读取完得保证resp.Body还可读 body, err := r.Peek(1024) //如果解析编码类型时遇到错误,返回UTF-8 if err != nil { log.Printf(\u0026#34;determineEncoding error is %v\u0026#34;, err) return unicode.UTF8 } //这里简化,不取是否确认 e, _, _ := charset.DetermineEncoding(body, \u0026#34;\u0026#34;) return e } main方法如下：\npackage main import ( \u0026#34;crawler/engine\u0026#34; \u0026#34;crawler/zhenai/parser\u0026#34; ) func main() { request := engine.Request{ Url: \u0026#34;http://www.zhenai.com/zhenghun\u0026#34;, ParserFunc: parser.ParseCityList, } engine.Run(request) } 最终爬取到的用户信息如下，包括昵称、年龄、身高、体重、工资、婚姻状况等。\n如果你想要哪个妹子的照片，可以点开url查看，然后打招呼进一步发展。\n至此单任务版的爬虫就做完了，后面我们将对单任务版爬虫做性能分析，然后升级为多任务并发版，把爬取到的信息存到ElasticSearch中，在页面上查询\n本公众号免费**提供csdn下载服务，海量IT学习资源，**如果你准备入IT坑，励志成为优秀的程序猿，那么这些资源很适合你，包括但不限于java、go、python、springcloud、elk、嵌入式 、大数据、面试资料、前端 等资源。同时我们组建了一个技术交流群，里面有很多大佬，会不定时分享技术文章，如果你想来一起学习提高，可以公众号后台回复【2】，免费邀请加技术交流群互相学习提高，会不定期分享编程IT相关资源。\n扫码关注，精彩内容第一时间推给你\n","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/%E7%94%A8go%E8%AF%AD%E8%A8%80%E7%88%AC%E5%8F%96%E7%8F%8D%E7%88%B1%E7%BD%91%E7%AC%AC%E4%B8%89%E5%9B%9E/","section":"Posts","summary":"\u003cp\u003e前两节我们获取到了城市的URL和城市名，今天我们来解析用户信息。\u003c/p\u003e","title":"用go语言爬取珍爱网 | 第三回","type":"posts"},{"content":"前两天我们写了单任务版爬虫爬取了珍爱网用户信息，那么它的性能如何呢？\n我们可以通过网络利用率看一下，我们用任务管理器中的性能分析窗口可以看到下载速率大概是保持在了200kbps左右，这可以说是相当慢了。\n我们针对来通过分析单任务版爬虫的设计来看下：\n从上图我们可以看出，engine将request从任务队列取出来，送到Fetcher取获取资源，等待数据返回，然后将返回的数据送到Parser去解析，等待其返回，把返回的request再加到任务队列里，同时把item打印出来。\n慢就慢在了没有充分利用网络资源，其实我们可以同时发送多个Fetcher和Pareser，等待其返回的同时，可以去做其他的处理。这一点利用go的并发语法糖很容易实现。\n上图中，Worker是Fetcher和Parser的合并，Scheduler将很多Request分发到不同的Worker，Worker将Request和Items返回到Engine，Items打印出来，再把Request放到调度器里。\n基于此用代码实现：\nEngine：\npackage engine import ( \u0026#34;log\u0026#34; ) type ConcurrentEngine struct { Scheduler Scheduler WokerCount int } type Scheduler interface { Submit(Request) ConfigureMasterWorkerChan(chan Request) } func (e *ConcurrentEngine) Run(seeds ...Request) { in := make(chan Request) out := make(chan ParserResult) e.Scheduler.ConfigureMasterWorkerChan(in) //创建Worker for i := 0; i \u0026lt; e.WokerCount; i { createWorker(in, out) } //任务分发给Worker for _, r := range seeds { e.Scheduler.Submit(r) } for { //打印out的items result := \u0026lt;- out for _, item := range result.Items { log.Printf(\u0026#34;Get Items: %v\\n\u0026#34;, item) } //将out里的Request送给Scheduler for _, r := range result.Requests { e.Scheduler.Submit(r) } } } //workerConut goroutine to exec worker for Loop func createWorker(in chan Request, out chan ParserResult) { go func() { for { request := \u0026lt;-in parserResult, err := worker(request) //发生了错误继续下一个 if err != nil { continue } //将parserResult送出 out \u0026lt;- parserResult } }() } Scheduler：\npackage scheduler import \u0026#34;crawler/engine\u0026#34; //SimpleScheduler one workChan to multi worker type SimpleScheduler struct { workChan chan engine.Request } func (s *SimpleScheduler) ConfigureMasterWorkerChan(r chan engine.Request) { s.workChan = r } func (s *SimpleScheduler) Submit(r engine.Request) { go func() { s.workChan \u0026lt;- r }() } Worker：\nfunc worker(r Request) (ParserResult, error) { log.Printf(\u0026#34;fetching url:%s\\n\u0026#34;, r.Url) //爬取数据 body, err := fetcher.Fetch(r.Url) if err != nil { log.Printf(\u0026#34;fetch url: %s; err: %v\\n\u0026#34;, r.Url, err) //发生错误继续爬取下一个url return ParserResult{}, err } //解析爬取到的结果 return r.ParserFunc(body), nil } main函数：\npackage main import ( \u0026#34;crawler/engine\u0026#34; \u0026#34;crawler/zhenai/parser\u0026#34; \u0026#34;crawler/scheduler\u0026#34; ) func main() { e := \u0026amp;engine.ConcurrentEngine{ Scheduler: \u0026amp;scheduler.SimpleScheduler{}, WokerCount :100, } e.Run( engine.Request{ Url: \u0026#34;http://www.zhenai.com/zhenghun\u0026#34;, ParserFunc: parser.ParseCityList, }) } 这里开启100个Worker，运行后再次查看网络利用率，变为3M以上。\n由于代码篇幅较长，需要的同学可以关注公众号回复：go爬虫 获取。\n","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/%E7%88%AC%E8%99%AB%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%8F%8A%E4%BC%98%E5%8C%96/","section":"Posts","summary":"\u003cp\u003e前两天我们写了单任务版爬虫爬取了珍爱网用户信息，那么它的性能如何呢？\u003c/p\u003e","title":"爬虫性能分析及优化","type":"posts"},{"content":" 正文 # golang爬珍爱网代码优化后，运行报了如下的错，找了半小时才找到原因，在此记录一下。\n代码是这样的：\n有一个interface类型的Parser：\ntype Parser interface { Parser(contents []byte, url string) ParserResult Serialize() (funcName string, args interface{}) } 有一个struct类型的FuncParser：\ntype FuncParser struct { parser ParserFunc funcName string } FuncParser 实现了Parser 接口：\nfunc (f *FuncParser) Parser(contents []byte, url string) ParserResult { return f.Parser(contents, url) } func (f *FuncParser) Serialize() (funcName string, args interface{}) { return f.funcName, nil } 抛开爬虫代码整体的复杂度，将代码简化到如下这样：\ntype ParserFunc func(url string) string type FuncParser struct { parser ParserFunc } func (f *FuncParser) Parser(url string) string { return f.Parser(url) } func main() { funcParse := FuncParser{ func(url string) string { return url }, } funcParse.Parser(\u0026#34;http://www.zhenai.com/zhenghun\u0026#34;) } 同样运行代码后同样会报错：\nruntime: goroutine stack exceeds 1000000000-byte limit fatal error: stack overflow runtime stack: runtime.throw(0x467297, 0xe) D:/Program Files/Go/go103/src/runtime/panic.go:616 +0x88 runtime.newstack() D:/Program Files/Go/go103/src/runtime/stack.go:1054 +0x72d runtime.morestack() D:/Program Files/Go/go103/src/runtime/asm_amd64.s:480 +0x91 这个示例就很明显了，FuncParser的Parser里形成了递归调用（自己调自己），\n递归调用自身导致栈溢出，导致报错。应该改成这样：（小写的parser）\n实际上goland里已经提示了Recursive Call\n一不小心就会写出这种代码，再看如下代码：\npackage main import ( \u0026#34;fmt\u0026#34; ) type Str string func (s Str) String() string { return fmt.Sprintf(\u0026#34;Str: %s\u0026#34;, s) } func main() { var s Str = \u0026#34;hi\u0026#34; fmt.Println(s) } 同样报错：\nYou are implementing Str.String in terms of itself. return fmt.Sprintf(\u0026ldquo;Str: %s\u0026rdquo;, s) will call s.String(), resulting in infinite recursion. Convert s to string first.\nThis is working as intended, you are using the %s verb to call Str\u0026rsquo;s String method, which uses fmt.Sprint to call Str\u0026rsquo;s String method, and so on.\n正常代码应该如下：\n实际上，goland里也会警告该问题的：\n看来平时编写代码，警告还是得注意的。\n项目代码见：https://github.com/ll837448792/crawler\n","date":"2019年10月18日","externalUrl":null,"permalink":"/posts/%E7%88%AC%E8%99%AB%E9%81%87%E5%88%B0%E4%BA%86%E7%82%B9%E9%97%AE%E9%A2%98/","section":"Posts","summary":"\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003egolang爬珍爱网代码优化后，运行报了如下的错，找了半小时才找到原因，在此记录一下。\u003c/p\u003e","title":"爬虫遇到了点问题","type":"posts"},{"content":" 正文 # golang爬取珍爱网，爬到了3万多用户信息，并存到了elasticsearch中，如下图，查询到了3万多用户信息。\n先来看看最终效果：\n利用到了go语言的html模板库：\n执行模板渲染：\nfunc (s SearchResultView) Render (w io.Writer, data model.SearchResult) error { return s.template.Execute(w, data) } model.SearchResult数据结构如下：\ntype SearchResult struct { Hits int64 Start int Query string PrevFrom int NextFrom int CurrentPage int TotalPage int64 Items []interface{} //Items []engine.Item } ```html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html xmlns:javascript=\u0026#34;http://www.w3.org/1999/xhtml\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;--- title\u0026gt;Love Search\u0026lt;/--- title\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1\u0026#34;\u0026gt; \u0026lt;link href=\u0026#34;./css/style.css\u0026#34; rel=\u0026#34;stylesheet\u0026#34;\u0026gt; \u0026lt;link href=\u0026#34;https://maxcdn.bootstrapcdn.com/bootstrap/3.3.0/css/bootstrap.min.css\u0026#34; rel=\u0026#34;stylesheet\u0026#34; id=\u0026#34;bootstrap-css\u0026#34;\u0026gt; \u0026lt;script src=\u0026#34;https://code.jquery.com/jquery-1.11.1.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://maxcdn.bootstrapcdn.com/bootstrap/3.3.0/js/bootstrap.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;./js/page.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;demo\u0026#34;\u0026gt; \u0026lt;div id=\u0026#34;searchblank\u0026#34;\u0026gt; \u0026lt;form method=\u0026#34;get\u0026#34; class=\u0026#34;form-inline\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;form-group\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; class=\u0026#34;form-control\u0026#34; style=\u0026#34;width: 500px\u0026#34; value=\u0026#34;{{.Query}}\u0026#34; name=\u0026#34;q\u0026#34;\u0026gt; \u0026lt;button class=\u0026#34;btn btn-default\u0026#34; type=\u0026#34;submit\u0026#34; maxlength=\u0026#34;100\u0026#34;\u0026gt;搜索\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;h4 style=\u0026#34;text-align: center\u0026#34;\u0026gt;共为你找到相关结果为{{.Hits}}个。显示从{{.Start}}起共{{len .Items}}个\u0026lt;/h4\u0026gt; \u0026lt;div id=\u0026#34;customers\u0026#34; class=\u0026#34;table-responsive-vertical shadow-z-1\u0026#34;\u0026gt; \u0026lt;table id=\u0026#34;table\u0026#34; class=\u0026#34;table table-striped table-hover table-mc-indigo\u0026#34;\u0026gt; \u0026lt;thead\u0026gt; \u0026lt;tr\u0026gt; \u0026lt;th\u0026gt;昵称\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;性别\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;年龄\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;身高\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;体重\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;收入\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;学历\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;职位\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;所在地\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;星座\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;购房情况\u0026lt;/th\u0026gt; \u0026lt;th\u0026gt;购车情况\u0026lt;/th\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/thead\u0026gt; \u0026lt;tbody\u0026gt; {{range .Items}} \u0026lt;tr\u0026gt; \u0026lt;td\u0026gt;\u0026lt;a href=\u0026#34;{{.Url}}\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;{{.Payload.Name}}\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt; {{with .Payload}} \u0026lt;td\u0026gt;{{.Gender}}\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;{{.Age}}\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;{{.Height}}CM\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;{{.Weight}}KG\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;{{.Income}}\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;{{.Education}}\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;{{.Occupation}}\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;{{.Hukou}}\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;{{.Xinzuo}}\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;{{.House}}\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;{{.Car}}\u0026lt;/td\u0026gt; {{end}} \u0026lt;/tr\u0026gt; {{else}} \u0026lt;tr\u0026gt; \u0026lt;td colspan=\u0026#34;12\u0026#34;\u0026gt;没有找到相关用户\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; {{end}} \u0026lt;/tbody\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;div align=\u0026#34;middle\u0026#34;\u0026gt; {{if gt .CurrentPage 1}} \u0026lt;a href=\u0026#34;search?q={{.Query}}\u0026amp;current={{Sub .CurrentPage 1}}\u0026#34;\u0026gt;上一页\u0026lt;/a\u0026gt; {{end}} {{if lt .CurrentPage .TotalPage}} \u0026lt;a href=\u0026#34;search?q={{.Query}}\u0026amp;current={{Add .CurrentPage 1}}\u0026#34;\u0026gt;下一页\u0026lt;/a\u0026gt; {{end}} \u0026lt;span\u0026gt;共{{.TotalPage}}页,当前第{{.CurrentPage}}页\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 其中用到了模板语法中的变量、函数、判断、循环；\n模板函数的定义：\n上面模板代码中的上一页、下一页的a标签href里用到了自定义模板函数Add和Sub分别用于获取上一页和下一页的页码，传到后台（这里并没有用JavaScript去实现）。\nhtml/template包中提供的功能有限，所以很多时候需要使用用户定义的函数来辅助渲染页面。下面讲讲模板函数如何使用。template包创建新的模板的时候，支持.Funcs方法来将自定义的函数集合导入到该模板中，后续通过该模板渲染的文件均支持直接调用这些函数。\n函数声明\n// Funcs adds the elements of the argument map to the template\u0026#39;s function map. // It panics if a value in the map is not a function with appropriate return // type. However, it is legal to overwrite elements of the map. The return // value is the template, so calls can be chained. func (t *Template) Funcs(funcMap FuncMap) *Template { t.text.Funcs(template.FuncMap(funcMap)) return t } Funcs方法就是用来创建我们模板函数了，它需要一个FuncMap类型的参数：\n// FuncMap is the type of the map defining the mapping from names to // functions. Each function must have either a single return value, or two // return values of which the second has type error. In that case, if the // second (error) argument evaluates to non-nil during execution, execution // terminates and Execute returns that error. FuncMap has the same base type // as FuncMap in \u0026#34;text/template\u0026#34;, copied here so clients need not import // \u0026#34;text/template\u0026#34;. type FuncMap map[string]interface{} 使用方法：\n在go代码中定义两个函数Add和Sub：\n//减法，为了在模板里用减1 func Sub(a, b int) int { return a - b } //加法，为了在模板里用加1 func Add(a, b int) int { return a + b } 模板绑定模板函数：\n创建一个FuncMap类型的map，key是模板函数的名字，value是刚才定义函数名。\n将 FuncMap注入到模板中。\nfilename := \u0026#34;../view/template_test.html\u0026#34; template, err := template.New(path.Base(filename)).Funcs(template.FuncMap{\u0026#34;Add\u0026#34;: Add, \u0026#34;Sub\u0026#34;: Sub}).ParseFiles(filename) if err != nil { t.Fatal(err) } 模板中如何使用：\n如上面html模板中上一页处的：\n{{Sub .CurrentPage 1}} 把渲染后的CurrentPage值加1\n注意：\n1、函数的注入，必须要在parseFiles之前，因为解析模板的时候，需要先把函数编译注入。\n2、Template object can have multiple templates in it and each one has a name. If you look at the implementation of ParseFiles, you see that it uses the filename as the template name inside of the template object. So, name your file the same as the template object, (probably not generally practical) or else use ExecuteTemplate instead of just Execute.\n3、The name of the template is the bare filename of the template, not the complete path。如果模板名字写错了，执行的时候会出现：\nerror: template: “…” is an incomplete or empty template 尤其是第三点，我今天就遇到了，模板名要用文件名，不能是带路径的名字，看以下代码：\nfunc TestTemplate3(t *testing.T) { //filename := \u0026#34;crawler/frontend/view/template.html\u0026#34; filename := \u0026#34;../view/template_test.html\u0026#34; //file, _ := os.Open(filename) t.Logf(\u0026#34;baseName:%s\\n\u0026#34;, path.Base(filename)) tpl, err := template.New(filename).Funcs(template.FuncMap{\u0026#34;Add\u0026#34;: Add, \u0026#34;Sub\u0026#34;: Sub}).ParseFiles(filename) if err != nil { t.Fatal(err) } page := common.SearchResult{} page.Hits = 123 page.Start = 0 item := engine.Item { Url: \u0026#34;http://album.zhenai.com/u/107194488\u0026#34;, Type: \u0026#34;zhenai\u0026#34;, Id: \u0026#34;107194488\u0026#34;, Payload: model.Profile{ Name: \u0026#34;霓裳\u0026#34;, Age: 28, Height: 157, Marriage: \u0026#34;未婚\u0026#34;, Income: \u0026#34;5001-8000元\u0026#34;, Education: \u0026#34;中专\u0026#34;, Occupation: \u0026#34;程序媛\u0026#34;, Gender: \u0026#34;女\u0026#34;, House: \u0026#34;已购房\u0026#34;, Car: \u0026#34;已购车\u0026#34;, Hukou: \u0026#34;上海徐汇区\u0026#34;, Xinzuo: \u0026#34;水瓶座\u0026#34;, }, } page.CurrentPage = 1 page.TotalPage = 10 page.Items = append(page.Items, item) afterHtml, err := os.Create(\u0026#34;template_test1.html\u0026#34;) if err != nil { t.Fatal(err) } tpl.Execute(afterHtml, page) } 这里在template.New(filename)传入的是文件名（上面定义时是带路径的文件名），导致执行完代码后template_test1.html文件是空的，当然测试类的通过的，但是将此渲染到浏览器的时候，就会报：\ntemplate: “…” is an incomplete or empty template 所以，要使用文件的baseName，即：\ntpl, err := template.New(path.Base(filename)).Funcs(template.FuncMap{\u0026#34;Add\u0026#34;: Add, \u0026#34;Sub\u0026#34;: Sub}).ParseFiles(filename) 这样运行代码后template_test1.html就是被渲染有内容的。\n其他语法：变量、判断、循环用法比较简单，我没遇到问题；其他语法，如：模板的嵌套，我目前没用到，在此也不做赘述。\n查询遇到的问题：\n因为查询每页显示10条记录，查询第1000页是正常的，当查询大于等于1001页的时候，会报如下错误：\n用restclient工具调，错误更明显了：\n{ \u0026#34;error\u0026#34; : { \u0026#34;root_cause\u0026#34; : [ { \u0026#34;type\u0026#34; : \u0026#34;query_phase_execution_exception\u0026#34;, \u0026#34;reason\u0026#34; : \u0026#34;Result window is too large, from + size must be less than or equal to: [10000] but was [10010]. See the scroll api for a more efficient way to request large data sets. This limit can be set by changing the [index.max_result_window] index level setting.\u0026#34; } ], \u0026#34;type\u0026#34; : \u0026#34;search_phase_execution_exception\u0026#34;, \u0026#34;reason\u0026#34; : \u0026#34;all shards failed\u0026#34;, \u0026#34;phase\u0026#34; : \u0026#34;query\u0026#34;, \u0026#34;grouped\u0026#34; : true, \u0026#34;failed_shards\u0026#34; : [ { \u0026#34;shard\u0026#34; : 0, \u0026#34;index\u0026#34; : \u0026#34;dating_profile\u0026#34;, \u0026#34;node\u0026#34; : \u0026#34;bJhldvT6QeaRTvHmBKHT4Q\u0026#34;, \u0026#34;reason\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;query_phase_execution_exception\u0026#34;, \u0026#34;reason\u0026#34; : \u0026#34;Result window is too large, from + size must be less than or equal to: [10000] but was [10010]. See the scroll api for a more efficient way to request large data sets. This limit can be set by changing the [index.max_result_window] index level setting.\u0026#34; } } ] }, \u0026#34;status\u0026#34; : 500 } 问了谷哥后发现，是由于ElasticSearch的默认 深度翻页 机制的限制造成的。ES默认的分页机制一个不足的地方是，比如有5010条数据，当你仅想取第5000到5010条数据的时候，ES也会将前5000条数据加载到内存当中，所以ES为了避免用户的过大分页请求造成ES服务所在机器内存溢出，默认对深度分页的条数进行了限制，默认的最大条数是10000条，这是正是问题描述中当获取第10000条数据的时候报Result window is too large异常的原因。（因为页面为1001页的时候后台1001-1然后乘以10作为from的值取查询ES，而ES默认需要from+size要小于index.max_result_window： 最大窗口值）。\n要解决这个问题，可以使用下面的方式来改变ES默认深度分页的index.max_result_window 最大窗口值\ncurl -XPUT http://127.0.0.1:9200/dating_profile/_settings -d \u0026#39;{ \u0026#34;index\u0026#34; : { \u0026#34;max_result_window\u0026#34; : 50000}}\u0026#39; 这里的dating_profile为index。\n其中my_index为要修改的index名，50000为要调整的新的窗口数。将该窗口调整后，便可以解决无法获取到10000条后数据的问题。\n注意事项 # 通过上述的方式解决了我们的问题，但也引入了另一个需要我们注意的问题，窗口值调大了后，虽然请求到分页的数据条数更多了，但它是用牺牲更多的服务器的内存、CPU资源来换取的。要考虑业务场景中过大的分页请求，是否会造成集群服务的OutOfMemory问题。在ES的官方文档中对深度分页也做了讨论\nhttps://www.elastic.co/guide/en/elasticsearch/guide/current/pagination.html\nhttps://www.elastic.co/guide/en/elasticsearch/guide/current/pagination.html\n核心的观点如下：\nDepending on the size of your documents, the number of shards, and the hardware you are using, paging 10,000 to 50,000 results (1,000 to 5,000 pages) deep should be perfectly doable. But with big-enough from values, the sorting process can become very heavy indeed, using vast amounts of CPU, memory, and bandwidth. For this reason, we strongly advise against deep paging.\n这段观点表述的意思是：根据文档的大小，分片的数量以及使用的硬件，分页10,000到50,000个结果（1,000到5,000页）应该是完全可行的。 但是，从价值观上来看，使用大量的CPU，内存和带宽，分类过程确实会变得非常重要。 为此，我们强烈建议不要进行深度分页。\nES作为一个搜索引擎，更适合的场景是使用它进行搜索，而不是大规模的结果遍历。 大部分场景下，没有必要得到超过10000个结果项目， 例如，只返回前1000个结果。如果的确需要大量数据的遍历展示，考虑是否可以用其他更合适的存储。或者根据业务场景看能否用ElasticSearch的 滚动API (类似于迭代器，但有时间窗口概念)来替代。\n到此展示的问题就解决了：\n项目代码见：https://github.com/ll837448792/crawler\n","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/%E7%88%AC%E5%8F%96%E7%8F%8D%E7%88%B1%E7%BD%91%E5%90%8E%E7%94%A8%E6%88%B7%E4%BF%A1%E6%81%AF%E5%B1%95%E7%A4%BA/","section":"Posts","summary":"\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003egolang爬取珍爱网，爬到了3万多用户信息，并存到了elasticsearch中，如下图，查询到了3万多用户信息。\u003c/p\u003e","title":"爬取珍爱网后用户信息展示","type":"posts"},{"content":" 正文 # MySQL在5.7.8开始对json原生支持，本文将对MySQL中json类型的用法简单说明，希望对你有用。\nCREATE TABLE testproject ( `id` int(10) unsigned NOT NULL AUTO_INCREMENT, `skill` JSON NOT NULL, `student` JSON NOT NULL, PRIMARY KEY (`id`) ); 查看表结构：\n这样JSON的字段就被创建好了\n**注：**JSON类型不能有默认值。\n插入JSON # 插入 json 格式的字符串，可以是对象的形式，也可以是数组的形式，\nINSERT INTO `testproject` (student, skill) VALUES (\u0026#39;{\u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;ggjg\u0026#34;}\u0026#39;, \u0026#39;[\u0026#34;java\u0026#34;, \u0026#34;go\u0026#34;, \u0026#34;vue\u0026#34;]\u0026#39;); INSERT INTO `testproject` (student, skill) VALUES (\u0026#39;{\u0026#34;id\u0026#34;: 5, \u0026#34;name\u0026#34;: \u0026#34;guogege\u0026#34;}\u0026#39;, \u0026#39;[]\u0026#39;); 插入json时，数据库会对json做校验，不符合json规范就会报错。\n查询JSON： # 查询 json 中的数据用 column-\u0026gt;path 的形式，其中对象类型 path 这样表示 $.path, 而数组类型则是 $[index]\n查询testproject表student字段中json对象id为1的记录：\nSELECT * FROM testproject WHERE student-\u0026gt;\u0026#39;$.id\u0026#39;= 1; 查询testproject表student字段中json对象id为1或者5的记录：\nSELECT * FROM testproject WHERE student-\u0026gt;\u0026#39;$.id\u0026#39; in (1,5); SELECT * FROM testproject WHERE student-\u0026gt;\u0026#39;$.id\u0026#39; = 1 or student-\u0026gt;\u0026#39;$.id\u0026#39; = 5; [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-ShdsDUDU-1571306793566)(http://upload-images.jianshu.io/upload_images/9134763-cda653c6a30e3965?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)]\n也可以用函数json_extract：\ncolumn-\u0026gt;path方法有限制，数据源必须是表字段，否则就报错：\n以下这样查询，查出来student-\u0026gt;\u0026rsquo;$.name\u0026rsquo;包含双引号：\nSELECT id, student-\u0026gt;\u0026#39;$.id\u0026#39;, student-\u0026gt;\u0026#39;$.name\u0026#39;, skill-\u0026gt;\u0026#39;$[0]\u0026#39;, skill-\u0026gt;\u0026#39;$[2]\u0026#39; FROM testproject; 这不是我们想要的，可以用 JSON_UNQUOTE 函数将双引号去掉，从 MySQL 5.7.13 起也可以通过这个操作符 -\u0026raquo; 这个和 JSON_UNQUOTE 是等价的。\n因为 JSON 不同于字符串，所以如果用字符串和 JSON 字段比较，是不会相等的：\nmysql\u0026gt; SELECT * FROM testproject WHERE student = \u0026#39;{\u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;ggjg\u0026#34;}\u0026#39;; Empty set (0.00 sec) 此时可以通过 CAST 将字符串转成 JSON 的形式：\nmysql\u0026gt; SELECT * FROM testproject WHERE student = CAST(\u0026#39;{\u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;ggjg\u0026#34;}\u0026#39; as JSON); +----+-----------------------+---------------------------+ | id | skill | student | +----+-----------------------+---------------------------+ | 10 | [\u0026#34;java\u0026#34;, \u0026#34;go\u0026#34;, \u0026#34;vue\u0026#34;] | {\u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;ggjg\u0026#34;} | +----+-----------------------+---------------------------+ 1 row in set (0.01 sec) 要特别注意的是，JSON 中的元素搜索是严格区分变量类型的，比如说整型和字符串是严格区分的：\nmysql\u0026gt; SELECT * FROM testproject WHERE student-\u0026gt;\u0026#39;$.id\u0026#39; = \u0026#39;1\u0026#39;; Empty set (0.00 sec) mysql\u0026gt; mysql\u0026gt; SELECT * FROM testproject WHERE student-\u0026gt;\u0026#39;$.id\u0026#39; = 1; +----+-----------------------+---------------------------+ | id | skill | student | +----+-----------------------+---------------------------+ | 10 | [\u0026#34;java\u0026#34;, \u0026#34;go\u0026#34;, \u0026#34;vue\u0026#34;] | {\u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;ggjg\u0026#34;} | +----+-----------------------+---------------------------+ 1 row in set (0.00 sec) 可以看到搜索字符串 1 和整型 1 的结果是不一样的。\n除了用以上 column-\u0026gt;path 的形式搜索，还可以用JSON_CONTAINS 函数，但和 column-\u0026gt;path 的形式有点相反的是，JSON_CONTAINS 第二个参数是不接受整数的，无论 json 元素是整型还是字符串，否则会出现这个错误：\nmysql\u0026gt; SELECT * FROM testproject WHERE JSON_CONTAINS(student, 1, \u0026#39;$.id\u0026#39;); ERROR 3146 (22032): Invalid data type for JSON data in argument 2 to function json_contains; a JSON string or JSON type is required. mysql\u0026gt; 这里必须要使用字符串：\nmysql\u0026gt; SELECT * FROM testproject WHERE JSON_CONTAINS(student, \u0026#39;1\u0026#39;, \u0026#39;$.id\u0026#39;); +----+-----------------------+---------------------------+ | id | skill | student | +----+-----------------------+---------------------------+ | 10 | [\u0026#34;java\u0026#34;, \u0026#34;go\u0026#34;, \u0026#34;vue\u0026#34;] | {\u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;ggjg\u0026#34;} | +----+-----------------------+---------------------------+ 1 row in set (0.00 sec) 对于数组类型的 JSON 的查询，比如说 skill 中包含有 3 的数据，同样要用 JSON_CONTAINS 函数，同样第二个参数也需要是字符串：\nmysql\u0026gt; SELECT * FROM testproject WHERE JSON_CONTAINS(skill, \u0026#39;\u0026#34;go\u0026#34;\u0026#39;); +----+-----------------------+---------------------------+ | id | skill | student | +----+-----------------------+---------------------------+ | 10 | [\u0026#34;java\u0026#34;, \u0026#34;go\u0026#34;, \u0026#34;vue\u0026#34;] | {\u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;ggjg\u0026#34;} | +----+-----------------------+---------------------------+ 1 row in set (0.00 sec) mysql\u0026gt; SELECT * FROM testproject WHERE JSON_CONTAINS(skill, \u0026#39;1\u0026#39;); +----+-----------+------------------------------+ | id | skill | student | +----+-----------+------------------------------+ | 12 | [1, 2, 3] | {\u0026#34;id\u0026#34;: 4, \u0026#34;name\u0026#34;: \u0026#34;guogege\u0026#34;} | +----+-----------+------------------------------+ 1 row in set (0.00 sec) 更新数据 # MySQL 并不支持 column-\u0026gt;path 的形式进行更新操作。\n如果是整个 json 更新的话，和插入时类似的：\nmysql\u0026gt; select * from testproject where id = 10; +----+-----------------------+---------------------------+ | id | skill | student | +----+-----------------------+---------------------------+ | 10 | [\u0026#34;java\u0026#34;, \u0026#34;go\u0026#34;, \u0026#34;vue\u0026#34;] | {\u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;ggjg\u0026#34;} | +----+-----------------------+---------------------------+ 1 row in set (0.00 sec) mysql\u0026gt; UPDATE testproject SET skill = \u0026#39;[\u0026#34;js\u0026#34;, \u0026#34;java\u0026#34;]\u0026#39; WHERE id = 10; Query OK, 1 row affected (0.01 sec) Rows matched: 1 Changed: 1 Warnings: 0 mysql\u0026gt; select * from testproject where id = 10; +----+----------------+---------------------------+ | id | skill | student | +----+----------------+---------------------------+ | 10 | [\u0026#34;js\u0026#34;, \u0026#34;java\u0026#34;] | {\u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;ggjg\u0026#34;} | +----+----------------+---------------------------+ 1 row in set (0.00 sec) json_array_append和json_array_insert函数使用：\njson_array_append是在json后面追加；\njson_array_insert是在指定下标插入。\nmysql\u0026gt; select * from testproject; +----+----------------+------------------------------+ | id | skill | student | +----+----------------+------------------------------+ | 10 | [\u0026#34;js\u0026#34;, \u0026#34;java\u0026#34;] | {\u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;ggjg\u0026#34;} | | 11 | [] | {\u0026#34;id\u0026#34;: 5, \u0026#34;name\u0026#34;: \u0026#34;guogege\u0026#34;} | | 12 | [1, 2, 3] | {\u0026#34;id\u0026#34;: 4, \u0026#34;name\u0026#34;: \u0026#34;guogege\u0026#34;} | +----+----------------+------------------------------+ 3 rows in set (0.00 sec) mysql\u0026gt; SELECT json_array_append(skill, \u0026#39;$\u0026#39;, \u0026#39;c\u0026#39;) from testproject; +------------------------------------+ | json_array_append(skill, \u0026#39;$\u0026#39;, \u0026#39;c\u0026#39;) | +------------------------------------+ | [\u0026#34;js\u0026#34;, \u0026#34;java\u0026#34;, \u0026#34;c\u0026#34;] | | [\u0026#34;c\u0026#34;] | | [1, 2, 3, \u0026#34;c\u0026#34;] | +------------------------------------+ 3 rows in set (0.00 sec) mysql\u0026gt; SELECT json_array_insert(skill, \u0026#39;$[1]\u0026#39;, \u0026#39;php\u0026#39;) from testproject; +-----------------------------------------+ | json_array_insert(skill, \u0026#39;$[1]\u0026#39;, \u0026#39;php\u0026#39;) | +-----------------------------------------+ | [\u0026#34;js\u0026#34;, \u0026#34;php\u0026#34;, \u0026#34;java\u0026#34;] | | [\u0026#34;php\u0026#34;] | | [1, \u0026#34;php\u0026#34;, 2, 3] | +-----------------------------------------+ 3 rows in set (0.00 sec) mysql\u0026gt; json_replace、json_set、json_insert和json_remove函数用法：\njson_replace：只替换已经存在的旧值，不存在则忽略；\njson_set：替换旧值，并插入不存在的新值；\njson_insert：插入新值，但不替换已经存在的旧值；\njson_remove() 删除元素。\njson_replace：\nmysql\u0026gt; select * from testproject; +----+----------------+--------------------------------+ | id | skill | student | +----+----------------+--------------------------------+ | 10 | [\u0026#34;js\u0026#34;, \u0026#34;java\u0026#34;] | {\u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;smallsoup\u0026#34;} | | 11 | [] | {\u0026#34;id\u0026#34;: 5, \u0026#34;name\u0026#34;: \u0026#34;guogege\u0026#34;} | | 12 | [1, 2, 3] | {\u0026#34;id\u0026#34;: 4, \u0026#34;name\u0026#34;: \u0026#34;guogege\u0026#34;} | +----+----------------+--------------------------------+ 3 rows in set (0.00 sec) mysql\u0026gt; mysql\u0026gt; UPDATE testproject SET student-\u0026gt;\u0026#39;$.name\u0026#39; = \u0026#39;smallsoup\u0026#39; where student-\u0026gt;\u0026#39;$.id\u0026#39; = 1; ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server versio n for the right syntax to use near \u0026#39;-\u0026gt;\u0026#39;$.name\u0026#39; = \u0026#39;smallsoup\u0026#39; where student-\u0026gt;\u0026#39;$.id\u0026#39; = 1\u0026#39; at line 1 mysql\u0026gt; mysql\u0026gt; UPDATE testproject SET student = json_replace(student, \u0026#39;$.name\u0026#39;, \u0026#39;soup\u0026#39;) WHERE student-\u0026gt;\u0026#39;$.id\u0026#39; = 1; Query OK, 1 row affected (0.01 sec) Rows matched: 1 Changed: 1 Warnings: 0 mysql\u0026gt; select * from testproject; +----+----------------+------------------------------+ | id | skill | student | +----+----------------+------------------------------+ | 10 | [\u0026#34;js\u0026#34;, \u0026#34;java\u0026#34;] | {\u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;soup\u0026#34;} | | 11 | [] | {\u0026#34;id\u0026#34;: 5, \u0026#34;name\u0026#34;: \u0026#34;guogege\u0026#34;} | | 12 | [1, 2, 3] | {\u0026#34;id\u0026#34;: 4, \u0026#34;name\u0026#34;: \u0026#34;guogege\u0026#34;} | +----+----------------+------------------------------+ 3 rows in set (0.00 sec) json_set：\nmysql\u0026gt; select * from testproject; +----+----------------+------------------------------+ | id | skill | student | +----+----------------+------------------------------+ | 10 | [\u0026#34;js\u0026#34;, \u0026#34;java\u0026#34;] | {\u0026#34;id\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;soup\u0026#34;} | | 11 | [] | {\u0026#34;id\u0026#34;: 5, \u0026#34;name\u0026#34;: \u0026#34;guogege\u0026#34;} | | 12 | [1, 2, 3] | {\u0026#34;id\u0026#34;: 4, \u0026#34;name\u0026#34;: \u0026#34;guogege\u0026#34;} | +----+----------------+------------------------------+ 3 rows in set (0.00 sec) mysql\u0026gt; UPDATE testproject SET student = json_set(student, \u0026#39;$.name\u0026#39;, \u0026#39;small\u0026#39;, \u0026#39;$.age\u0026#39;, 22) WHERE student-\u0026gt;\u0026#39;$.id\u0026#39;= 1; Query OK, 1 row affected (0.01 sec) Rows matched: 1 Changed: 1 Warnings: 0 mysql\u0026gt; select * from testproject; +----+----------------+---------------------------------------+ | id | skill | student | +----+----------------+---------------------------------------+ | 10 | [\u0026#34;js\u0026#34;, \u0026#34;java\u0026#34;] | {\u0026#34;id\u0026#34;: 1, \u0026#34;age\u0026#34;: 22, \u0026#34;name\u0026#34;: \u0026#34;small\u0026#34;} | | 11 | [] | {\u0026#34;id\u0026#34;: 5, \u0026#34;name\u0026#34;: \u0026#34;guogege\u0026#34;} | | 12 | [1, 2, 3] | {\u0026#34;id\u0026#34;: 4, \u0026#34;name\u0026#34;: \u0026#34;guogege\u0026#34;} | +----+----------------+---------------------------------------+ 3 rows in set (0.00 sec) json_insert：\nmysql\u0026gt; select * from testproject; +----+----------------+---------------------------------------+ | id | skill | student | +----+----------------+---------------------------------------+ | 10 | [\u0026#34;js\u0026#34;, \u0026#34;java\u0026#34;] | {\u0026#34;id\u0026#34;: 1, \u0026#34;age\u0026#34;: 22, \u0026#34;name\u0026#34;: \u0026#34;small\u0026#34;} | | 11 | [] | {\u0026#34;id\u0026#34;: 5, \u0026#34;name\u0026#34;: \u0026#34;guogege\u0026#34;} | | 12 | [1, 2, 3] | {\u0026#34;id\u0026#34;: 4, \u0026#34;name\u0026#34;: \u0026#34;guogege\u0026#34;} | +----+----------------+---------------------------------------+ 3 rows in set (0.00 sec) mysql\u0026gt; UPDATE testproject SET student = json_insert(student, \u0026#39;$.name\u0026#39;, \u0026#39;soup\u0026#39;, \u0026#39;$.addr\u0026#39;, \u0026#39;苏州\u0026#39;) WHERE student-\u0026gt;\u0026#39;$.id\u0026#39;= 1; Query OK, 1 row affected (0.00 sec) Rows matched: 1 Changed: 1 Warnings: 0 mysql\u0026gt; select * from testproject; +----+----------------+---------------------------------------------------------+ | id | skill | student | +----+----------------+---------------------------------------------------------+ | 10 | [\u0026#34;js\u0026#34;, \u0026#34;java\u0026#34;] | {\u0026#34;id\u0026#34;: 1, \u0026#34;age\u0026#34;: 22, \u0026#34;addr\u0026#34;: \u0026#34;苏州\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;small\u0026#34;} | | 11 | [] | {\u0026#34;id\u0026#34;: 5, \u0026#34;name\u0026#34;: \u0026#34;guogege\u0026#34;} | | 12 | [1, 2, 3] | {\u0026#34;id\u0026#34;: 4, \u0026#34;name\u0026#34;: \u0026#34;guogege\u0026#34;} | +----+----------------+---------------------------------------------------------+ 3 rows in set (0.00 sec) json_remove() :\nmysql\u0026gt; select * from testproject; +----+----------------+---------------------------------------------------------+ | id | skill | student | +----+----------------+---------------------------------------------------------+ | 10 | [\u0026#34;js\u0026#34;, \u0026#34;java\u0026#34;] | {\u0026#34;id\u0026#34;: 1, \u0026#34;age\u0026#34;: 22, \u0026#34;addr\u0026#34;: \u0026#34;苏州\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;small\u0026#34;} | | 11 | [] | {\u0026#34;id\u0026#34;: 5, \u0026#34;name\u0026#34;: \u0026#34;guogege\u0026#34;} | | 12 | [1, 2, 3] | {\u0026#34;id\u0026#34;: 4, \u0026#34;name\u0026#34;: \u0026#34;guogege\u0026#34;} | +----+----------------+---------------------------------------------------------+ 3 rows in set (0.00 sec) mysql\u0026gt; UPDATE testproject SET student = json_remove(student, \u0026#39;$.name\u0026#39;, \u0026#39;$.age\u0026#39;) WHERE student-\u0026gt;\u0026#39;$.id\u0026#39; = 1; Query OK, 1 row affected (0.01 sec) Rows matched: 1 Changed: 1 Warnings: 0 mysql\u0026gt; select * from testproject; +----+----------------+------------------------------+ | id | skill | student | +----+----------------+------------------------------+ | 10 | [\u0026#34;js\u0026#34;, \u0026#34;java\u0026#34;] | {\u0026#34;id\u0026#34;: 1, \u0026#34;addr\u0026#34;: \u0026#34;苏州\u0026#34;} | | 11 | [] | {\u0026#34;id\u0026#34;: 5, \u0026#34;name\u0026#34;: \u0026#34;guogege\u0026#34;} | | 12 | [1, 2, 3] | {\u0026#34;id\u0026#34;: 4, \u0026#34;name\u0026#34;: \u0026#34;guogege\u0026#34;} | +----+----------------+------------------------------+ 3 rows in set (0.00 sec) 可以看到name和age就被移除了。\n以上只列出了部分函数的说明，mysql官方提供的函数列表如下：\n更多用法请查看官方文档：\nhttps://dev.mysql.com/doc/refman/5.7/en/json-function-reference.html\n","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/mysql%E6%94%AF%E6%8C%81%E5%8E%9F%E7%94%9Fjson%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/","section":"Posts","summary":"\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eMySQL在5.7.8开始对json原生支持，本文将对MySQL中json类型的用法简单说明，希望对你有用。\u003c/p\u003e","title":"mysql支持原生json使用说明","type":"posts"},{"content":"","date":"2019年10月17日","externalUrl":null,"permalink":"/tags/springmvc/","section":"Tags","summary":"","title":"Springmvc","type":"tags"},{"content":" 正文 # 今天来试着用SpringMVC发送邮件，主要需要依赖以下两个包；\n\u0026lt;!--spring发送邮件依赖spring.version=4.3.8.RELEASE--\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-context-support\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- Javamail API --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.mail\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mail\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.4.5\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; spring-mail.xml配置文件如下：\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:context=\u0026#34;http://www.springframework.org/schema/context\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.2.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.2.xsd\u0026#34;\u0026gt; \u0026lt;!-- 引入属性文件 --\u0026gt; \u0026lt;context:property-placeholder location=\u0026#34;classpath:config/email.properties\u0026#34; ignore-unresolvable=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;!-- \u0026lt;bean id=\u0026#34;local\u0026#34; class=\u0026#34;org.springframework.beans.factory.config.PropertyPlaceholderConfigurer\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;location\u0026#34; value=\u0026#34;classpath:config/email.properties\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;ignoreUnresolvablePlaceholders\u0026#34; value=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt;--\u0026gt; \u0026lt;!-- 下面列出网易的SMTP服务器名和端口号: 网易邮箱 SMTP服务器 SMTP端口 POP3服务器 POP3端口 @126.com smtp.126.com 25 pop3.126.com 110 @163.com smtp.163.com 25 pop3.163.com 110 @yeah.net smtp.yeah.net 25 pop3.yeah.net 110 --\u0026gt; \u0026lt;bean id=\u0026#34;javaMailSender\u0026#34; class=\u0026#34;org.springframework.mail.javamail.JavaMailSenderImpl\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;protocol\u0026#34; value=\u0026#34;${email.protocol}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;host\u0026#34; value=\u0026#34;${email.host}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;port\u0026#34; value=\u0026#34;${email.port}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;username\u0026#34; value=\u0026#34;${email.username}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;password\u0026#34; value=\u0026#34;${email.password}\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;defaultEncoding\u0026#34; value=\u0026#34;UTF-8\u0026#34;\u0026gt;\u0026lt;/property\u0026gt; \u0026lt;property name=\u0026#34;javaMailProperties\u0026#34;\u0026gt; \u0026lt;props\u0026gt; \u0026lt;prop key=\u0026#34;mail.auth\u0026#34;\u0026gt;${email.auth}\u0026lt;/prop\u0026gt; \u0026lt;prop key=\u0026#34;mail.smtp.timeout\u0026#34;\u0026gt;${email.timout}\u0026lt;/prop\u0026gt; \u0026lt;/props\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;simpleMailMessage\u0026#34; class=\u0026#34;org.springframework.mail.SimpleMailMessage\u0026#34;\u0026gt; \u0026lt;!-- 发件人email --\u0026gt; \u0026lt;property name=\u0026#34;from\u0026#34; value=\u0026#34;${email.username}\u0026#34; /\u0026gt; \u0026lt;!--收件人email--\u0026gt; \u0026lt;property name=\u0026#34;to\u0026#34; value=\u0026#34;${email.default.to}\u0026#34; /\u0026gt; \u0026lt;!--email主题(标题)--\u0026gt; \u0026lt;property name=\u0026#34;subject\u0026#34; value=\u0026#34;${email.default.subject}\u0026#34; /\u0026gt; \u0026lt;!--email主题内容--\u0026gt; \u0026lt;property name=\u0026#34;text\u0026#34;\u0026gt; \u0026lt;value\u0026gt;${email.default.text}\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;emailService\u0026#34; class=\u0026#34;com.website.service.impl.EmailServiceImpl\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;javaMailSender\u0026#34; ref=\u0026#34;javaMailSender\u0026#34;/\u0026gt; \u0026lt;property name=\u0026#34;simpleMailMessage\u0026#34; ref=\u0026#34;simpleMailMessage\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/beans\u0026gt; 这里加载了发送邮件相关的配置文件email.properties：\nemail.protocol=smtp email.host=smtp.163.com email.port=25 email.username=132312312@163.com email.password=yourpassword email.default.to=123121@126.com email.default.subject=Hello email.default.text=how are you email.auth=true email.timout=25000 发送简单邮件代码：\npublic class EmailServiceImpl implements EmailService { private static final Logger LOGGER = LoggerFactory.getLogger(EmailServiceImpl.class); private JavaMailSender javaMailSender; private SimpleMailMessage simpleMailMessage; /** * @方法名: sendMailSimple * @参数名：@param subject 邮件主题 * @参数名：@param content 邮件内容 * @参数名：@param to 收件人Email地址 * @描述语: 发送邮件 */ @Override public void sendMailSimple(String to, String subject, String content) throws Exception { try { //用于接收邮件的邮箱 simpleMailMessage.setTo(to); //邮件的主题 simpleMailMessage.setSubject(subject); //邮件的正文，第二个boolean类型的参数代表html格式 simpleMailMessage.setText(content); LOGGER.info(\u0026#34;---------------------------{}\u0026#34;, simpleMailMessage); //发送 javaMailSender.send(simpleMailMessage); } catch (Exception e) { throw new MessagingException(\u0026#34;failed to send mail!\u0026#34;, e); } } public void setJavaMailSender(JavaMailSender javaMailSender) { this.javaMailSender = javaMailSender; } public void setSimpleMailMessage(SimpleMailMessage simpleMailMessage) { this.simpleMailMessage = simpleMailMessage; } } 跑单元测试的时候报：Could not resolve placeholder异常，不可以解析email.protocol\nCaused by: org.springframework.beans.factory.BeanDefinitionStoreException: Invalid bean definition with name \u0026#39;javaMailSender\u0026#39; defined in class path resource [config/spring-mail.xml]: Could not resolve placeholder \u0026#39;email.protocol\u0026#39; in value \u0026#34;${email.protocol}\u0026#34;; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder \u0026#39;email.protocol\u0026#39; in value \u0026#34;${email.protocol}\u0026#34; 可能的原因：\n1、location中的属性文件配置错误；\n2、location中定义的配置文件里面没有对应的placeholder值；\n3、Spring容器的配置问题，很有可能是使用了多个PropertyPlaceholderConfigurer或者多个context:property-placeholder的原因。\n排查以后发现，\napplicationContext.xml和spring-mail.xml两个文件都使用了context:property-placeholder，前者加载数据库连接配置，后者加载发送邮件相关配置。\n\u0026lt;context:property-placeholder location=\u0026#34;classpath:config/db.properties\u0026#34;/\u0026gt; \u0026lt;context:property-placeholder location=\u0026#34;classpath:config/email.properties\u0026#34;/\u0026gt; 这个是Spring容器采用反射扫描的发现机制决定的，在Spring 3.0中，可以加ignore-unresolvable=\u0026ldquo;true\u0026quot;解决。\n\u0026lt;context:property-placeholder location=\u0026#34;classpath:config/db.properties\u0026#34; ignore-unresolvable=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;context:property-placeholder location=\u0026#34;classpath:config/email.properties\u0026#34; ignore-unresolvable=\u0026#34;true\u0026#34;/\u0026gt; 注意：必须两个都要加，加一个也不行。\n在Spring 2.5中，context:property-placeholder没有ignore-unresolvable属性，此时可以改用PropertyPlaceholderConfigurer。其实\u0026lt;context:property-placeholder location=\u0026ldquo;xxx.properties\u0026rdquo; ignore-unresolvable=\u0026ldquo;true\u0026rdquo; /\u0026gt;与下面的配置是等价的。\n\u0026lt;bean id=\u0026#34;local\u0026#34; class=\u0026#34;org.springframework.beans.factory.config.PropertyPlaceholderConfigurer\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;location\u0026#34; value=\u0026#34;classpath:config/email.properties\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;ignoreUnresolvablePlaceholders\u0026#34; value=\u0026#34;true\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; 修改以后，测试用类运行成功：\n发送邮件成功：\n其实发送邮件还可以用JavaMail实现，需要依赖两个包：\nactivation-1.1.jar\nmail-1.4.2.jar\n","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/springmvc%E5%AE%9E%E7%8E%B0%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6/","section":"Posts","summary":"\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e今天来试着用SpringMVC发送邮件，主要需要依赖以下两个包；\u003c/p\u003e","title":"SpringMVC实现发送邮件","type":"posts"},{"content":" 正文 # 1、 设置WriteHeader的顺序问题\n之前遇到个问题，在一段代码中这样设置WriteHeader,最后在header中取Name时怎么也取不到。\nw.WriteHeader(201) w.Header().Set(\u0026#34;Name\u0026#34;, \u0026#34;my name is smallsoup\u0026#34;) 用 golang 写 http server 时，可以很方便可通过 w.Header.Set(k, v) 来设置 http response 中 header 的内容。但是需要特别注意的是：某些时候不仅要修改 response的header ，还要修改 response的StatusCode。修改response的StatusCode 可以通过：w.WriteHeader(code) 来实现，例如：\nw.WriteHeader(404) 如果这两种修改一起做，就必须让 w.WriteHeader 在所有的 w.Header.Set 之后，因为 w.WriteHeader 后 Set Header 是无效的。\n而且必须是在 w.Write([]byte(\u0026ldquo;HelloWorld\u0026rdquo;)) 之前，否则会报 http: multiple response.WriteHeader calls 因为其实调用w.Write的时候也会调用WriteHeader()方法，然后将w.wroteHeader置为true，再次调WriteHeader()则会判断wroteHeader，如果是true则会报错，而且本次调用不生效。\n可以看以下源码说明WriteHeader必须在Write之前调用。\nfunc (w *response) WriteHeader(code int) { if w.conn.hijacked() { w.conn.server.logf(\u0026#34;http: response.WriteHeader on hijacked connection\u0026#34;) return } //第二次WriteHeader()进来满足if条件就报错直接return if w.wroteHeader { w.conn.server.logf(\u0026#34;http: multiple response.WriteHeader calls\u0026#34;) return } //第一次write()进来这里会将w.wroteHeader置为true w.wroteHeader = true w.status = code if w.calledHeader \u0026amp;\u0026amp; w.cw.header == nil { w.cw.header = w.handlerHeader.clone() } if cl := w.handlerHeader.get(\u0026#34;Content-Length\u0026#34;); cl != \u0026#34;\u0026#34; { v, err := strconv.ParseInt(cl, 10, 64) if err == nil \u0026amp;\u0026amp; v \u0026gt;= 0 { w.contentLength = v } else { w.conn.server.logf(\u0026#34;http: invalid Content-Length of %q\u0026#34;, cl) w.handlerHeader.Del(\u0026#34;Content-Length\u0026#34;) } } } 2、 go会对Header中的key进行规范化处理\ngo会对Header中的key进行规范化处理，所以在获取response的Header中的K,V值时一定要小心。\nreader.go中非导出方法canonicalMIMEHeaderKey中有这样一段，会将header的key进行规范化处理。\n1）reader.go中定义了isTokenTable数组，如果key的长度大于127或者包含不在isTokenTable中的字符，则该key不会被处理。\n2）将key的首字母大写，字符 - 后的单词的首字母也大写。\n分析如下源码，可以解释对key的大写处理：\nfor i, c := range a { // 规范化:首字母大写 // - 之后单子的首字母大写 // 如:(Host, User-Agent, If-Modified-Since). if upper \u0026amp;\u0026amp; \u0026#39;a\u0026#39; \u0026lt;= c \u0026amp;\u0026amp; c \u0026lt;= \u0026#39;z\u0026#39; { //大写转小写 c -= toLower } else if !upper \u0026amp;\u0026amp; \u0026#39;A\u0026#39; \u0026lt;= c \u0026amp;\u0026amp; c \u0026lt;= \u0026#39;Z\u0026#39; { //小写转大写 c += toLower } //重新给key数组赋值 a[i] = c //设置大小写标志位 upper = c == \u0026#39;-\u0026#39; // for next time } 正确的调用方式：\n服务器：myServer.go\npackage main import ( \u0026#34;net/http\u0026#34; ) func main() { http.HandleFunc(\u0026#34;/\u0026#34;, func (w http.ResponseWriter, r *http.Request){ w.Header().Set(\u0026#34;name\u0026#34;, \u0026#34;my name is smallsoup\u0026#34;) w.WriteHeader(500) w.Write([]byte(\u0026#34;hello world\\n\u0026#34;)) }) http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil) } 客户端：\nmyHttp.go：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { myHttpGet() } func myHttpGet() { rsp, err := http.Get(\u0026#34;http://localhost:8080\u0026#34;) if err != nil { fmt.Println(\u0026#34;myHttpGet error is \u0026#34;, err) return } defer rsp.Body.Close() body, err := ioutil.ReadAll(rsp.Body) if err != nil { fmt.Println(\u0026#34;myHttpGet error is \u0026#34;, err) return } fmt.Println(\u0026#34;response statuscode is \u0026#34;, rsp.StatusCode, \u0026#34;\\nhead[name]=\u0026#34;, rsp.Header[\u0026#34;Name\u0026#34;], \u0026#34;\\nbody is \u0026#34;, string(body)) } 1.运行服务器\ngo run myServer.go\n2.运行客户端\ngo run myHttp.go\n输出如下：statuscode是我们设置的500，Name也取到了值。\n","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/golang%E8%AE%BE%E7%BD%AEhttpresponse%E5%93%8D%E5%BA%94%E5%A4%B4%E4%B8%8E%E5%9D%91/","section":"Posts","summary":"\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e1、 设置WriteHeader的顺序问题\u003c/strong\u003e\u003c/p\u003e","title":"golang 设置 http response 响应头与坑","type":"posts"},{"content":" 正文 # 今天来用java实现手机验证码的发送。\n短信平台有很多，中国网建提供的SMS短信通，注册免费5条短信，3条彩信，\nhttp://sms.webchinese.cn/\n但是刚才试了，第一次用官方提供的demo发送成功，然后整合到自己项目中，调试时由于参数配置错误导致发送了几次失败后，5次就用完了。按理说成功才能算一次，果断放弃。\n然后试了一下腾讯云SMS平台，每月可以免费发送100条国内短信\nhttps://cloud.tencent.com/product/sms\n首先需要注册腾讯云账号，注册时可以微信认证，认证时支付1分钱验证是人为操作，这一分钱注册成功后会放到账户中。\n注册后，需要添加一个应用，这个随便写，创建好后点击 -\u0026gt; 应用名称，然看AppID和AppKey，这个比较重要，调用短信API接口时需要提供。\n然后需要在 -\u0026gt; 国内短信 -\u0026gt; 短信内容配置 -\u0026gt; 短信签名中创建签名和短信正文中创建正文模板。\n一个完整的短信由短信签名和短信正文内容两部分组成，您可以根据业务需求分别设置不同的短信正文内容模板，然后进行组合形成最终展示。短信签名+短信正文内容=最终显示内容\n审核可能得需要花一段时间，我创建后，审核只花了2小时不到。这些步骤做完之后，就可以根据官方提供的API接口发送短信了。\nhttps://cloud.tencent.com/document/product/382/5808\n官方提供了java、python、c#、node.js的SDK，这里用java的SDK调用，这里有详细说明：\nhttps://github.com/qcloudsms/qcloudsms_java\n首先加入maven依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.qcloudsms\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;qcloudsms\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.4\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 编写调用SDK的代码：\n/** * 腾讯云短信,100条一个月 * 方法说明 * * @param phone * @return void * @Discription:扩展说明 * @throws HTTPException http status exception * @throws IOException network problem */ public static void sendMsgByTxPlatform(String phone) throws Exception { // 短信应用SDK AppID // 1400开头 int appId = 1402126548; // 短信应用SDK AppKey String appKey = \u0026#34;b67d0bf7876c1d42121ca561953532\u0026#34;; // 需要发送短信的手机号码 // String[] phoneNumbers = {\u0026#34;15212111830\u0026#34;}; // 短信模板ID，需要在短信应用中申请 //NOTE: 这里的模板ID`7839`只是一个示例，真实的模板ID需要在短信控制台中申请 int templateId = 148464; // 签名 // NOTE: 这里的签名\u0026#34;腾讯云\u0026#34;只是一个示例，真实的签名需要在短信控制台中申请，另外签名参数使用的是`签名内容`，而不是`签名ID` String smsSign = \u0026#34;我的小碗汤\u0026#34;; SmsSingleSender sSender = new SmsSingleSender(appId, appKey); //第一个参数0表示普通短信,1表示营销短信 SmsSingleSenderResult result = sSender.send(0, \u0026#34;86\u0026#34;, phone, RandomCodeUtils.getSixValidationCode() + \u0026#34;为您的登录验证码，请于\u0026#34; + 10 + \u0026#34;分钟内填写。如非本人操作，请忽略本短信。\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;); if (result.result != 0) { throw new Exception(\u0026#34;send phone validateCode is error\u0026#34; + result.errMsg); } } 参数说明：\n@param type 短信类型，0 为普通短信，1 营销短信,需要和刚才页面上提交的短信正文下的类型一致 @param nationCode 国家码，如 86 为中国 @param phoneNumber 不带国家码的手机号 @param msg 信息内容，必须与申请的模板格式一致，否则将返回错误，{1}占位符可在代码中用实际需要发送的值替换 @param extend 扩展码，可填空 @param ext 服务端原样返回的参数，可填空 编写好以后用测试类测试时，返回错误码1014，可以点击错误描述中的链接去查看可能的原因。我是由于正文内容和刚才页面上提交的正文不一样导致的。\nhttps://cloud.tencent.com/document/product/382/3771\n以下有很多错误码，可以供排查问题参考：\n正常情况下，返回的result为0时表示发送成功，这也是100条次数减1的参考。按照接口要求修改参数后，发送短信成功。\n也有很多其他平台提供的短信服务，比如阿里云可以参考以下文章：\nhttps://blog.csdn.net/u014520797/article/details/54411392\n","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/java%E5%8F%91%E9%80%81%E6%89%8B%E6%9C%BA%E9%AA%8C%E8%AF%81%E7%A0%81%E5%AE%9E%E7%8E%B0/","section":"Posts","summary":"\u003cp\u003e\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"\" src=\"https://img.hacpai.com/bing/20180526.jpg?imageView2/1/w/960/h/540/interlace/1/q/100\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e\n\n\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e今天来用java实现手机验证码的发送。\u003c/p\u003e","title":"java发送手机验证码实现","type":"posts"},{"content":"","date":"2019年10月17日","externalUrl":null,"permalink":"/tags/%E7%9F%AD%E4%BF%A1/","section":"Tags","summary":"","title":"短信","type":"tags"},{"content":" 正文 # 今天来学习下图形验证码的生成，首先依赖开源组件：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.penggle\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;kaptcha\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在web.xml中配置名为Kaptcha的servlet：\n\u0026lt;servlet\u0026gt; \u0026lt;!-- 生成图片的Servlet --\u0026gt; \u0026lt;servlet-name\u0026gt;Kaptcha\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;com.google.code.kaptcha.servlet.KaptchaServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;!-- 是否有边框 --\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;kaptcha.border\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;no\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;!-- 字体颜色 --\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;kaptcha.textproducer.font.color\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;red\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;!-- 图片宽度 --\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;kaptcha.image.width\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;135\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;!-- 使用哪些字符生成验证码 --\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;kaptcha.textproducer.char.string\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;ACDEFHKPRSTWX345679\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;!-- 图片高度 --\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;kaptcha.image.height\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;50\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;!-- 字体大小 --\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;kaptcha.textproducer.font.size\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;43\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;!-- 干扰线的颜色 --\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;kaptcha.noise.color\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;black\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;!-- 字符个数 --\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;kaptcha.textproducer.char.length\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;4\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;!-- 使用哪些字体 --\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;kaptcha.textproducer.font.names\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;Arial\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;!-- 映射的url --\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;Kaptcha\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;/Kaptcha\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; html中添加验证码标签，并绑定javascript事件：\n\u0026lt;!--验证码--\u0026gt; \u0026lt;li class=\u0026#34;align-top\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;item-content\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;item-inner\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;item---- title label\u0026#34;\u0026gt;验证码\u0026lt;/div\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; id=\u0026#34;j_captcha\u0026#34; placeholder=\u0026#34;验证码\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;item-input\u0026#34;\u0026gt; \u0026lt;img id=\u0026#34;captcha_img\u0026#34; alt=\u0026#34;点击更换\u0026#34; --- title=\u0026#34;点击更换\u0026#34; src=\u0026#34;../Kaptcha\u0026#34; onclick=\u0026#34;changeVerifyCode(this)\u0026#34;/\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; function changeVerifyCode(img) { // alert(\u0026#34;asssssssssss\u0026#34;); img.src = \u0026#34;../Kaptcha?\u0026#34; + Math.floor(Math.random() * 100); }; \u0026lt;/script\u0026gt; 效果图：\n","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/java%E5%9B%BE%E5%BD%A2%E9%AA%8C%E8%AF%81%E7%A0%81%E5%AE%9E%E7%8E%B0/","section":"Posts","summary":"\u003cp\u003e\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"\" src=\"https://img.hacpai.com/bing/20190705.jpg?imageView2/1/w/960/h/540/interlace/1/q/100\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e\n\n\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e今天来学习下图形验证码的生成，首先依赖开源组件：\u003c/p\u003e","title":"java图形验证码实现","type":"posts"},{"content":"","date":"2019年10月17日","externalUrl":null,"permalink":"/tags/%E9%AA%8C%E8%AF%81%E7%A0%81/","section":"Tags","summary":"","title":"验证码","type":"tags"},{"content":" 正文 # 今天在tomcat里部署运行了一个小工程，工程结构如下：\n运行tomcat服务器后，访问index.html，发现报404：\n但是后台接口是正常返回的：\n去看webapps里工程目录下，index.html文件是有的，见鬼了，是哪儿出了问题？\n然后看到控制台日志（或者tomcat_home/logs/catalina.log）报错如下：\norg.springframework.web.servlet.PageNotFound.noHandlerFound No mapping fo und for HTTP request with URI [/artmuseum/index.html] in DispatcherServlet with name \u0026#39;springmvc\u0026#39; 大致意思是springmvc这个servlet处理不了index.html。原来是配置有问题。\n看看web.xml配置，是这样写的：\n\u0026lt;!-- 注册前端控制器 --\u0026gt; \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;springmvc\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;org.springframework.web.servlet.DispatcherServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;contextConfigLocation\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;classpath*:config/spring-*.xml\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;springmvc\u0026lt;/servlet-name\u0026gt; \u0026lt;!--默认匹配所有的请求--\u0026gt; \u0026lt;url-pattern\u0026gt;/\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; 这里url-pattern匹配所有请求，可以实现现在很流行的REST风格，但是会导致js、html、css等静态资源被拦截，拦截后找不到对应的Handler去处理，就会报404\n可以通过以下几种方式去解决：\n1、\n在web.xml中配置默认servlet，去处理静态资源，配置如下：\n\u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;default\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;*.html\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;default\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;*.css\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;default\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;*.xml\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;default\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;*.swf\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; 这样配置后，匹配到的静态资源会被Servlet名称是\u0026quot;default\u0026quot;的DefaultServletHttpRequestHandler去处理，这样就可以找到了。但是该方式每种静态资源文件都得配置一个。\n2、\n在spring3.0.4以后版本提供了mvc:resources,使用方法：\n\u0026lt;!-- 对静态资源文件的访问 --\u0026gt; \u0026lt;mvc:resources mapping=\u0026#34;/css/**\u0026#34; location=\u0026#34;/css/\u0026#34; /\u0026gt; \u0026lt;mvc:resources mapping=\u0026#34;/js/**\u0026#34; location=\u0026#34;/js/\u0026#34; /\u0026gt; 使用mvc:resources/元素,把mapping的URI注册到SimpleUrlHandlerMapping的urlMap中,\nkey为mapping的URI pattern值,而value为ResourceHttpRequestHandler,\n这样就巧妙的把对静态资源的访问由HandlerMapping转到ResourceHttpRequestHandler处理并返回,所以就支持classpath目录,jar包内静态资源的访问。\n3、\n使用mvc:default-servlet-handler/\n\u0026lt;mvc:default-servlet-handler/\u0026gt; 该标签会把\u0026quot;/**\u0026quot; url,注册到SimpleUrlHandlerMapping的urlMap中,把对静态资源的访问由HandlerMapping转到DefaultServletHttpRequestHandler 处理并返回，\nDefaultServletHttpRequestHandler使用就是各个Servlet容器自己的默认Servlet\n按照最简单的第三种方式，修改以后，index.html页面访问正常：\n总结一下，归根结底还是自己对SpringMVC不熟悉。\n","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/java%E8%BF%99%E4%B8%AA404%E4%BD%A0%E8%83%BD%E8%A7%A3%E5%86%B3%E5%90%97/","section":"Posts","summary":"\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e今天在tomcat里部署运行了一个小工程，工程结构如下：\u003c/p\u003e","title":"java这个404你能解决吗？","type":"posts"},{"content":" 正文 # 今天利用java发邮件，本地windows上测试时发送ok的，部署到服务器上却报异常，让我们走进异常，探索到底坑在哪里，并填之。\n利用outlook发邮件代码如下：\npackage com.website.service.impl; import com.alibaba.fastjson.JSON; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.beans.factory.annotation.Qualifier; import org.springframework.mail.javamail.JavaMailSenderImpl; import org.springframework.mail.javamail.MimeMessageHelper; import javax.mail.internet.MimeMessage; import java.util.Properties; /** * @program: WebSite * @description: SpringMvc实现的发送email * @author: smallsoup * @create: 2018-06-30 20:29 **/ public class EmailServiceImpl { private static final Logger LOGGER = LoggerFactory.getLogger(Test.class); @Autowired @Qualifier(\u0026#34;javaMailSender\u0026#34;) private JavaMailSenderImpl sender; /** * @方法名: sendMail * @参数名：@param subject 邮件主题 * @参数名：@param content 邮件内容 * @参数名：@param to 收件人Email地址 * @描述语: 发送邮件 */ public void sendMailHtml(String to, String subject, String content) throws Exception { sender.setUsername(\u0026#34;yourusername@outlook.com\u0026#34;); sender.setPassword(\u0026#34;your_password\u0026#34;); sender.setPort(587); Properties props = new Properties(); props.setProperty(\u0026#34;mail.transport.protocol\u0026#34;, \u0026#34;smtp\u0026#34;); props.setProperty(\u0026#34;mail.smtp.host\u0026#34;, \u0026#34;smtp-mail.outlook.com\u0026#34;); props.setProperty(\u0026#34;mail.smtp.starttls.enable\u0026#34;, \u0026#34;true\u0026#34;); props.setProperty(\u0026#34;mail.smtp.auth\u0026#34;, \u0026#34;true\u0026#34;); props.setProperty(\u0026#34;mail.smtp.socketFactory.class\u0026#34;, \u0026#34;javax.net.ssl.SSLSocketFactory\u0026#34;); props.setProperty(\u0026#34;mail.smtp.socketFactory.port\u0026#34;, \u0026#34;587\u0026#34;); props.setProperty(\u0026#34;mail.smtp.socketFactory.fallback\u0026#34;, \u0026#34;true\u0026#34;); props.setProperty(\u0026#34;mail.smtp.auth.ntlm.domain\u0026#34;, \u0026#34;THING\u0026#34;); sender.setJavaMailProperties(props); //建立邮件消息,发送简单邮件和html邮件的区别 MimeMessage mailMessage = sender.createMimeMessage(); MimeMessageHelper messageHelper = new MimeMessageHelper(mailMessage); messageHelper.setFrom(\u0026#34;smallsoup@outlook.com\u0026#34;); //用于接收邮件的邮箱 messageHelper.setTo(to); //邮件的主题 messageHelper.setSubject(subject); //邮件的正文，第二个boolean类型的参数代表html格式 messageHelper.setText(content, true); LOGGER.info(\u0026#34;----------sendMailHtml-----------------\u0026#34;); LOGGER.info(\u0026#34;----------mailMessage is------------FROM:{}, Subject:{}, content:{}, AllRecipients:{}\u0026#34;, mailMessage.getFrom(), mailMessage.getSubject(), mailMessage.getContent(), JSON.toJSONString(mailMessage.getAllRecipients())); //发送 sender.send(mailMessage); } } 上面的代码打包在本地tomcat上运行，可以发送邮件成功。但是将war包部署到亚马逊云服务器上发送邮件报错：\n网上说是由于用户名和密码不正确导致验证失败。但是这不能解释本地能发出去邮件的事实。继续排查、google，实在找不到解决办法。那就试着登陆下outlook邮件看能不能登进去，登陆正常，有一封最近的一次登录存在某些异常的邮件。\n然后点击查看最新活动状态。异常显示最近一次登陆在美国。\n这么一来就知道问题了，由于亚马逊云实际位置在美国，所以发邮件时相当于在异地登陆被拒绝。当点击了“是我本人”之后，重新发邮件，就发出去了。\n之所以不用163发邮件，是因为本地部署也可以发出去，放到服务器上也发不出，报554 DT:SPM 163 smtp3，网上说是因为邮件主题和正文中又非法字符导致，目前还没解决，之后再填此坑。\n","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/java%E5%8F%91%E9%82%AE%E4%BB%B6%E8%BF%99%E4%B8%AA%E5%9D%91%E4%BD%A0%E8%83%BD%E5%A1%AB%E5%90%97/","section":"Posts","summary":"\u003cp\u003e\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"\" src=\"https://img.hacpai.com/bing/20190601.jpg?imageView2/1/w/960/h/540/interlace/1/q/100\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e\n\n\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e今天利用java发邮件，本地windows上测试时发送ok的，部署到服务器上却报异常，让我们走进异常，探索到底坑在哪里，并填之。\u003c/p\u003e","title":"java发邮件，这个坑你能填吗？","type":"posts"},{"content":" 正文 # 我们来用java代码爬取csdn博客网站，然后自动评论，这一波操作可以说是相当风骚了，话不多说，咱上代码。\n第一步是登录代码，这个网上一大把，代码中用到了jsoup依赖包，用于解析html获取相应元素，相当于css选择器，很强大的三方件。\n/** * 登录csdn页面,评论当然需要登录了 * * @throws Exception */ public static void loginCsdnPager() throws Exception { String html = HttpUtils.sendGet(\u0026#34;https://passport.csdn.net/account/login?ref=toolbar\u0026#34;); try { Thread.currentThread().sleep(3000); } catch (InterruptedException e) { // TODO Auto-generated catch block e.printStackTrace(); } Document doc = Jsoup.parse(html); Element form = doc.select(\u0026#34;.user-pass\u0026#34;).get(0); String lt = form.select(\u0026#34;input[name=lt]\u0026#34;).get(0).val(); String execution = form.select(\u0026#34;input[name=execution]\u0026#34;).get(0).val(); String _eventId = form.select(\u0026#34;input[name=_eventId]\u0026#34;).get(0).val(); List\u0026lt;NameValuePair\u0026gt; nvps = new ArrayList\u0026lt;NameValuePair\u0026gt;(); nvps.add(new BasicNameValuePair(\u0026#34;username\u0026#34;, CSDNACCOUNT)); nvps.add(new BasicNameValuePair(\u0026#34;password\u0026#34;, CSDNPASSWORD)); nvps.add(new BasicNameValuePair(\u0026#34;lt\u0026#34;, lt)); nvps.add(new BasicNameValuePair(\u0026#34;execution\u0026#34;, execution)); nvps.add(new BasicNameValuePair(\u0026#34;_eventId\u0026#34;, _eventId)); System.out.println(nvps); // 开始请求CSDN服务器进行登录操作。一个简单封装，直接获取返回结果 String ret = HttpUtils.sendPost(\u0026#34;https://passport.csdn.net/account/login\u0026#34;, nvps); System.out.println(\u0026#34;ret is \u0026#34; + ret); // ret中会包含以下信息，进行判断即可。 if (ret.indexOf(\u0026#34;redirect_back\u0026#34;) \u0026gt; -1) { System.out.println(\u0026#34;登陆成功。。。。。\u0026#34;); } else if (ret.indexOf(\u0026#34;登录太频繁\u0026#34;) \u0026gt; -1) { throw new Exception(\u0026#34;登录太频繁，请稍后再试。。。。。\u0026#34;); } else { throw new Exception(\u0026#34;登录太频繁，请稍后再试。。。。。\u0026#34;); } } 有了登录代码我们还得获取博客文章列表，这是我们爬取的源头。下面以博客首页为起点往其他网络节点爬：\nhttps://blog.csdn.net\n我们可以把自己当做一个虫子，接下来将在蜘蛛网上从A节点到B节点，一直爬到目的地。\n首先进入首页，然后获取到首页左侧栏的分类列表的url，点开这些url，就是分类下的所有文章了。这里我们只取每个分类下初始页的文章列表url（当然还可以自行实现鼠标下拉时的分页，以获取到更多的文章列表），这里定义了一个名为FETCHPAGES的数组常量，管理所需爬取的分类列表。\nString html = HttpUtils.sendGet(\u0026#34;https://blog.csdn.net/\u0026#34;); Document doc = Jsoup.parse(html); Elements as = doc.select(\u0026#34;.nav_com\u0026#34;).select(\u0026#34;li\u0026#34;).select(\u0026#34;a\u0026#34;); // 收集文章a标签 List\u0026lt;Elements\u0026gt; blogList = Lists.newArrayListWithCapacity(as.size()); for (Element a : as) { if (!FETCHPAGES.contains(a.text())) { continue; } String fetcheUrl = \u0026#34;https://blog.csdn.net\u0026#34; + a.attr(\u0026#34;href\u0026#34;); System.out.println(fetcheUrl); String blogHtml = HttpUtils.sendGet(fetcheUrl); Document blogDoc = Jsoup.parse(blogHtml); Elements blogAs = blogDoc.select(\u0026#34;.--- title\u0026#34;).select(\u0026#34;h2\u0026#34;).select(\u0026#34;a\u0026#34;); System.out.println(blogAs); blogList.add(blogAs); } 收集好文章列表之后，我们就需要登录了（登录后收集列表会出问题，具体原因不明），这里登录只是接下来评论时必须。\n// 收集完a标签后再登陆,否则会丢掉很多a标签,具体原因不名 loginCsdnPager(); BufferedOutputStream bos = null; // 评论成功计数器 int count = 0; try { // 将评论成功的url打印到文件里 File file = new File(\u0026#34;D:/tmp/successLog/success.log\u0026#34;); bos = new BufferedOutputStream(new FileOutputStream(file)); // 爬取所有a标签 for (Elements blogs : blogList) { for (Element blog : blogs) { // 拿到文章url String href = blog.attr(\u0026#34;href\u0026#34;); // 获取文章url后的ID,在评论时需要用到 String commitSuffixUrl = href.substring(href.lastIndexOf(\u0026#34;/\u0026#34;) + 1); // 打开文章 String blogHtml = HttpUtils.sendGet(href); System.out.println(blog.text() + \u0026#34;------------\u0026#34; + blog.attr(\u0026#34;href\u0026#34;)); Document blogDoc = Jsoup.parse(blogHtml); Elements --- titleAs = blogDoc.select(\u0026#34;.--- title-box\u0026#34;).select(\u0026#34;a\u0026#34;); System.out.println(--- titleAs); if (--- titleAs != null \u0026amp;\u0026amp; !--- titleAs.isEmpty()) { // 评论请求url前缀 String commitPrefixUrl = --- titleAs.get(0).attr(\u0026#34;href\u0026#34;); // System.out.println(--- titleAs.text() + \u0026#34;-----------\u0026#34; + commitPrefixUrl); // 拼接评论请求url String commitUrl = commitPrefixUrl + \u0026#34;/phoenix/comment/submit?id=\u0026#34; + commitSuffixUrl; System.out.println(\u0026#34;commitUrl ==\u0026#34; + commitUrl); // 构造评论请求所需body体 List\u0026lt;NameValuePair\u0026gt; nvps = new ArrayList\u0026lt;NameValuePair\u0026gt;(); nvps.add(new BasicNameValuePair(\u0026#34;replyId\u0026#34;, \u0026#34;\u0026#34;)); nvps.add(new BasicNameValuePair(\u0026#34;content\u0026#34;, \u0026#34;加Wei信ammlysouw 免费领取java、python、前端、安卓、数据库、大数据、IOS等学习资料\u0026#34;)); // 发起评论 String postRequest = HttpUtils.sendPost(commitUrl, nvps); JSONObject jsonObj = JSONObject.parseObject(postRequest); System.out.println(postRequest); // 评论结果,成功为1 if (jsonObj.getInteger(\u0026#34;result\u0026#34;) == 1) { String articalUrl = commitPrefixUrl + \u0026#34;/article/details/\u0026#34; + commitSuffixUrl + \u0026#34;\\n\u0026#34;; System.out.println(\u0026#34;success articalUrl is \u0026#34; + articalUrl); // 将评论成功的url记录到文件 bos.write(articalUrl.getBytes()); bos.flush(); count++; } else { // 不成功说明请求太快,线程休眠2秒,这里会丢掉评论失败的文章 try { Thread.currentThread().sleep(2 * 60 * 1000); } catch (InterruptedException e) { // TODO Auto-generated catch block e.printStackTrace(); } } } else { continue; } } } } catch (IOException e) { System.out.println(\u0026#34;error is \u0026#34; + e); } finally { if (bos != null) { try { // 把成功的送书记录到文件 bos.write((count + \u0026#34;\\n\u0026#34;).getBytes()); bos.flush(); System.out.println(\u0026#34;bos will colse\u0026#34;); bos.close(); } catch (IOException e) { // TODO Auto-generated catch block System.out.println(\u0026#34;error is \u0026#34; + e); } } } 登录后就是解析收集到的文章url，然后打开url，拼接评论请求url，以及请求参数，发起post请求，评论上三次以后就会被网站服务器限制，提示评论太快，需要睡眠2秒钟再继续，最后会把评论成功的url和数量记录到本地文件中，便于查看。\n","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/%E8%87%AA%E5%8A%A8%E8%AF%84%E8%AE%BAcsdn%E5%8D%9A%E5%AE%A2%E6%96%87%E7%AB%A0%E5%AE%9E%E7%8E%B0/","section":"Posts","summary":"\u003cp\u003e\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"\" src=\"https://img.hacpai.com/bing/20181123.jpg?imageView2/1/w/960/h/540/interlace/1/q/100\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e\n\n\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e我们来用java代码爬取csdn博客网站，然后自动评论，这一波操作可以说是相当风骚了，话不多说，咱上代码。\u003c/p\u003e","title":"自动评论csdn博客文章实现","type":"posts"},{"content":"","date":"2019年10月17日","externalUrl":null,"permalink":"/tags/ditto/","section":"Tags","summary":"","title":"Ditto","type":"tags"},{"content":" 正文 # Ditto 是一款开源、免费、强大的剪贴板增强工具。可以把复制过的所有内容保存起来（可以设定保存日期或条目总数），快捷地供后续调用。还可以合并粘贴，纯文本粘贴，支持分组、置顶、快速搜索、热键粘贴功能。并且，还可以通过网络共享剪贴板内容。\n平常情况下，Ditto只是系统托盘中的图标。按下热键（默认 ctrl+`）后，会出现的粘贴主界面；再点击右键会弹出功能丰富的菜单\nDitto中可以保留大量（取决于数据库容量）的历史记录。如果想搜索某条记录，只须在主界面的搜索框中输入文字，过滤后的结果会实时展现出来。\nDitto允许合并粘贴，就是把多条记录，一次性粘贴到目标窗口。在收集资料时，这点尤其有用。\n如果复制了带格式文本（比如，来自网页、office文件），默认是带格式粘贴，但 Shift+Enter 表示纯文本粘贴。以前很多人还要通过记事本中转来消除格式，有了Ditto后，一切简单了。\nDitto比通常工具更为强大的是，它能输入的不仅是一个“词条”，而可以是“多行文本、带格式的文本、图片和文件”。\n当然，Ditto也支持网络分享即一个组内，多人共享剪贴板。还可以切换主题，功能强大，各位请自行占坑尝鲜。\n该工具可以关注文末公众号，在后台回复【1】获取。\n","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/%E4%B8%80%E6%AC%BE%E6%95%88%E7%8E%87%E7%A5%9E%E5%99%A8ditto/","section":"Posts","summary":"\u003cp\u003e\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"\" src=\"https://img.hacpai.com/bing/20181202.jpg?imageView2/1/w/960/h/540/interlace/1/q/100\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e\n\n\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eDitto 是一款开源、免费、强大的剪贴板增强工具。可以把复制过的所有内容保存起来（可以设定保存日期或条目总数），快捷地供后续调用。还可以合并粘贴，纯文本粘贴，支持分组、置顶、快速搜索、热键粘贴功能。并且，还可以通过网络共享剪贴板内容。\u003c/p\u003e","title":"一款效率神器Ditto","type":"posts"},{"content":" 正文 # 1、\n通过util包中的ResourceBundle加载：\n首先国际化资源文件放在了classpath下的i18n目录下：\nmymessage_en_US.properties：\ncom.website.operation=\\u67e5\\u8be2\\u64cd\\u4f5c\\u65e5\\u5fd7 com.website.write=\\u5199\\u65e5\\u5fd7 com.website.writeLog=\\u5199 {0} \\u65e5\\u5fd7 mymessage_en_US.properties：\ncom.website.operation=queryOperationLog com.website.write=recordLog com.website.writeLog=record {0} Log 利用ResourceBundle加载国际化文件，这里列出四个方法，分别是利用默认Locale、zh_CN、en_US以及带占位符的处理方式。这里需要注意的是BaseName为classpath下的目录+/+国际化文件名前缀，即i18n/mymessage\npackage com.website.controller.utils; import java.text.MessageFormat; import java.util.Locale; import java.util.ResourceBundle; /** * @program: website * @description: 获取国际化配置文件 * @author: smallsoup * @create: 2018-07-27 22:32 **/ public class ResourceUtils { public static String getEnglishValueByKey(String key){ Locale locale = new Locale(\u0026#34;en\u0026#34;, \u0026#34;US\u0026#34;); //使用指定的英文Locale ResourceBundle mySource = ResourceBundle.getBundle(\u0026#34;i18n/mymessage\u0026#34;, locale); return mySource.getString(key); } public static String getChineseValueByKey(String key){ Locale locale = new Locale(\u0026#34;zh\u0026#34;, \u0026#34;CN\u0026#34;); //使用指定的中文Locale ResourceBundle mySource = ResourceBundle.getBundle(\u0026#34;i18n/mymessage\u0026#34;, locale); return mySource.getString(key); } public static String getDeafultValueByKey(String key){ //使用默认的Locale ResourceBundle mySource = ResourceBundle.getBundle(\u0026#34;i18n/mymessage\u0026#34;); return mySource.getString(key); } public static String getValueAndPlaceholder(String key){ //使用默认的Locale ResourceBundle mySource = ResourceBundle.getBundle(\u0026#34;i18n/mymessage\u0026#34;); String beforeValue = mySource.getString(key); //填充国家化文件中的占位符 String afterValue = MessageFormat.format(beforeValue, \u0026#34;安全\u0026#34;); return afterValue; } } 在controller里面调用ResourceUtils里的方法：\n@RequestMapping(value = \u0026#34;/projectadd\u0026#34;) public String projectAdd(){ LOGGER.warn(\u0026#34;projectAdd getChineseValueByKey is {}\u0026#34;, ResourceUtils.getChineseValueByKey(\u0026#34;com.website.operation\u0026#34;)); LOGGER.warn(\u0026#34;projectAdd getDeafultValueByKey is {}\u0026#34;, ResourceUtils.getDeafultValueByKey(\u0026#34;com.website.operation\u0026#34;)); LOGGER.warn(\u0026#34;projectAdd getEnglishValueByKey is {}\u0026#34;, ResourceUtils.getEnglishValueByKey(\u0026#34;com.website.operation\u0026#34;)); LOGGER.warn(\u0026#34;projectAdd getValueAndPlaceholder is {}\u0026#34;, ResourceUtils.getValueAndPlaceholder(\u0026#34;com.website.writeLog\u0026#34;)); return \u0026#34;project/projectadd\u0026#34;; } 启动tomcat打印日志：\n2、\n利用spring的ResourceBundleMessageSource\nResourceBundleMessageSource是基于JDK ResourceBundle的MessageSource接口实现类。它会将访问过的ResourceBundle缓存起来，以便于下次直接从缓存中获取进行使用。\n和上面不同的是ResourceUtils的实现，实现如下：\npackage com.website.controller.utils; import org.springframework.context.support.ResourceBundleMessageSource; import java.util.Locale; /** * @program: website * @description: 获取国际化配置文件 * @author: smallsoup * @create: 2018-07-27 22:32 **/ public class ResourceUtils { private static ResourceBundleMessageSource messageSource = new ResourceBundleMessageSource(); static { //指定国家化资源文件路径 messageSource.setBasename(\u0026#34;i18n/mymessage\u0026#34;); //指定将用来加载对应资源文件时使用的编码，默认为空，表示将使用默认的编码进行获取。 messageSource.setDefaultEncoding(\u0026#34;UTF-8\u0026#34;); } public static String getChineseValueByKey(String key){ return messageSource.getMessage(key, null, Locale.CHINA); } public static String getDeafultValueByKey(String key){ return messageSource.getMessage(key, null, null); } public static String getEnglishValueByKey(String key){ return messageSource.getMessage(key, null, Locale.US); } public static String getValueAndPlaceholder(String key){ return messageSource.getMessage(key, new Object[]{\u0026#34;安全\u0026#34;}, null); } } 3、\n利用spring的ReloadableResourceBundleMessageSource\nReloadableResourceBundleMessageSource也是MessageSource的一种实现，其用法配置等和ResourceBundleMessageSource基本一致。所不同的是ReloadableResourceBundleMessageSource内部是使用PropertiesPersister来加载对应的文件，这包括properties文件和xml文件，然后使用java.util.Properties来保存对应的数据。\npackage com.website.controller.utils; import org.springframework.context.support.ReloadableResourceBundleMessageSource; import java.util.Locale; /** * @program: website * @description: 获取国际化配置文件 * @author: smallsoup * @create: 2018-07-27 22:32 **/ public class ResourceUtils { private static ReloadableResourceBundleMessageSource messageSource = new ReloadableResourceBundleMessageSource(); static { //指定国家化资源文件路径 messageSource.setBasename(\u0026#34;i18n/mymessage\u0026#34;); //指定将用来加载对应资源文件时使用的编码，默认为空，表示将使用默认的编码进行获取。 messageSource.setDefaultEncoding(\u0026#34;UTF-8\u0026#34;); //是否允许并发刷新 messageSource.setConcurrentRefresh(true); //ReloadableResourceBundleMessageSource也是支持缓存对应的资源文件的，默认的缓存时间为永久，即获取了一次资源文件后就将其缓存起来，以后再也不重新去获取该文件。这个可以通过setCacheSeconds()方法来指定对应的缓存时间，单位为秒 messageSource.setCacheSeconds(1200); } public static String getChineseValueByKey(String key){ return messageSource.getMessage(key, null, Locale.CHINA); } public static String getDeafultValueByKey(String key){ return messageSource.getMessage(key, null, null); } public static String getEnglishValueByKey(String key){ return messageSource.getMessage(key, null, Locale.US); } public static String getValueAndPlaceholder(String key){ return messageSource.getMessage(key, new Object[]{\u0026#34;安全\u0026#34;}, null); } } 这三种方式最后结果是一样的。\n参考：\n国际化MessageSource\nhttp://elim.iteye.com/blog/2392583\n","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/java%E5%8A%A0%E8%BD%BD%E5%9B%BD%E9%99%85%E5%8C%96%E6%96%87%E4%BB%B6%E7%9A%84%E5%87%A0%E7%A7%8D%E5%A7%BF%E5%8A%BF/","section":"Posts","summary":"\u003cp\u003e\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"\" src=\"https://img.hacpai.com/bing/20190316.jpg?imageView2/1/w/960/h/540/interlace/1/q/100\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e\n\n\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e\u003cem\u003e\u003cstrong\u003e1、\u003c/strong\u003e\u003c/em\u003e\u003c/p\u003e","title":"java加载国际化文件的几种姿势","type":"posts"},{"content":" 正文 # 今天首先来看个问题，用原生servlet实现的接口，大家看下控制台输出结果是什么？\nweb.xml如下：\n\u0026lt;!DOCTYPE web-app PUBLIC \u0026#34;-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN\u0026#34; \u0026#34;http://java.sun.com/dtd/web-app_2_3.dtd\u0026#34; \u0026gt; \u0026lt;web-app\u0026gt; \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;myServlet\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;com.smallsoup.servlet.SonServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;myServlet\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;/rest/v3/access/*\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; \u0026lt;/web-app\u0026gt; SonServlet.java如下：\npackage com.smallsoup.servlet; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; /** * @program: myServlet * @description: SonServlet * @author: smallsoup * @create: 2018-08-01 20:46 **/ public class SonServlet extends ParentServlet{ @Override public void handleGet(HttpServletRequest req, HttpServletResponse resp) { System.out.println(\u0026#34;I am SonServlet handleGet\u0026#34;); } } ParentServlet.java如下：\npackage com.smallsoup.servlet; import javax.servlet.ServletException; import javax.servlet.http.HttpServlet; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import java.io.IOException; /** * @program: myServlet * @description: ParentServlet * @author: smallsoup * @create: 2018-08-01 20:47 **/ public class ParentServlet extends HttpServlet { @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { System.out.println(\u0026#34;I am ParentServlet doGet\u0026#34;); this.handleGet(req, resp); } public void handleGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { System.out.println(\u0026#34;I am ParentServlet handleGet\u0026#34;); super.doGet(req, resp); } } 启动tomcat，用postman发请求：\nGET：http://localhost:8080/rest/v3/access/1212 控制台会输出什么呢？答案是：\nI am ParentServlet doGet I am SonServlet handleGet 我相信很多小伙伴应该会答错，以为会输出：\nI am ParentServlet doGet I am ParentServlet handleGet 或者别的答案。小编今天遇到这个问题也懵逼了，基础掌握不扎实，还得回过头来补补。\n首先根据url匹配到web.xml中定义的name为myServlet的servlet，所以会到SonServlet中去处理，但是SonServlet没有重写HttpServlet的doGet()方法，它的父类ParentServlet重写了，所以请求会到ParentServlet的doGet()方法，但是这里的doGet方法中的this.handleGet中的this指的是什么呢？我们通过debug看到this其实是SonServlet的实例。\n由此看来，this.handleGet会去调用SonServlet的方法，这就解释了控制台的输出。\n这个问题，主要包含两个知识点：\n1、servlet处理请求的流程；\n2、this关键字指什么？\n下面这篇对this关键字讲的非常好，出自：\nhttps://www.cnblogs.com/zheting/p/7751752.html\nJava中this关键字使用小结： # 当一个对象创建后，Java虚拟机（JVM）就会给这个对象分配一个引用自身的指针，这个指针的名字就是 this。\n因此，this只能在类中的非静态方法中使用，静态方法和静态的代码块中绝对不能出现this，并且this只和特定的对象关联，而不和类关联，同一个类的不同对象有不同的this。\n1、使用this来区分当前对象\nJava中为解决变量的命名冲突和不确定性问题，引入关键字this代表其所在方法的当前对象的引用：\n构造方法中指该构造器所创建的新对象；\n方法中指调用该方法的对象；\n在类本身的方法或构造器中引用该类的实例变量（全局变量）和方法。\nthis只能用在构造器或者方法中，用于获得调用当前的构造器方法的对象引用。可以和任何的对象引用一样来处理这个this对象。\n说明：\n当实例变量和局部变量重名，JAVA平台会按照先局部变量、后实例变量的顺序寻找。即，方法中使用到的变量的寻找规律是先找局部变量，再找实例变量。如果没用找到，将会有一个编译错误而无法通过编译。\n如果使用this.a，则不会在方法（局部变量）中寻找变量a,而是直接去实例变量中去寻找，如果寻找不到，则会有一个编译错误。\n在一个方法内，如果没有出现局部变量和实例变量重名的情况下，是否使用this关键字是没有区别的。\n在同一个类中，Java普通方法的互相调用可以省略this+点号，而直接使用方法名+参数。因为Java编译器会帮我们加上。\n2、 在构造器中使用this来调用对象本身的其他构造器\n在构造器中使用this（[args_list]）；可以调用对象本身的其他的构造器。直接使用this()加上类构造器所需要的参数。就可以调用类本身的其他构造器了。如果类中有多个其他构造器定义，系统将自动根据this()中的参数个数和类型来找出类中相匹配的构造器。\n注意： 在构造器中可以通过this()方式来调用其他的构造器。但在一个构造器中最多只能调用一个其他的构造器。并且，对其他构造器的调用动作必须放在构造器的起始处（也就是构造器的首行），否则编译的时候将会出现错误，另外不能在构造器以外的地方以这种方式调用构造器。\n3、 this关键字还有一个重大的作用就是返回类的引用。如在代码中，可以使用return this来返回某个类的引用。此时，这个this关键字就代表类的名称。\n例1、把this作为参数传递\n当你要把自己作为参数传递给别的对象时，也可以用this。如：\npackage com.smallsoup.servlet; /** * @program: myServlet * @description: A * @author: smallsoup * @create: 2018-08-01 22:58 **/ public class A { public A(){ new B(this).print(); } public void print(){ System.out.println(\u0026#34;From A!\u0026#34;); } public static void main(String[] args) { new A(); } } class B{ A a; public B(A a){ this.a = a; } public void print(){ a.print(); System.out.println(\u0026#34;From B!\u0026#34;); } } 运行结果：\nFrom A! From B! 在这个例子中，对象A的构造函数中，用new B(this)把对象A自己作为参数传递给了对象B的构造函数。\n例2、注意匿名类和内部类中的中的this\n有时候，我们会用到一些内部类和匿名类，如事件处理。当在匿名类中出现this时，这个this则指的是匿名类或内部类本身。这时如果我们要使用外部类的方法和变量的话，则应该加上外部类的类名。如下面这个例子：\npackage com.smallsoup.servlet; /** * @program: myServlet * @description: C * @author: smallsoup * @create: 2018-08-01 23:00 **/ public class C { int i = 1; public C(){ Thread thread = new Thread(){ @Override public void run(){ for(;;){//表示是死循环 C.this.run();//调用外部方法run() try { sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } } } };//注意这里有分号; thread.start(); } public void run(){ System.out.println(\u0026#34;i = \u0026#34; + i); i++; } public static void main(String[] args) throws Exception { new C(); } } 运行结果：每一秒产生一个数：1,2,3 ……\n在上面这个例子中, thread 是一个匿名类对象，在它的定义中，它的 run 函数里用到了外部类的 run 函数。这时由于函数同名，直接调用就不行了。这时有两种办法，一种就是把外部的 run 函数换一个名字，但这种办法对于一个开发到中途的应用来说是不可取的。那么就可以用这个例子中的办法用外部类的类名加上 this 引用来说明要调用的是外部类的方法 run。\n例3 、this关键字最大的作用是，让类的一个方法，访问该类的另一个方法或者属性。\n先看一个不好的例子:\npackage com.smallsoup.servlet; /** * @program: myServlet * @description: Baby * @author: smallsoup * @create: 2018-08-01 23:03 **/ public class Baby { public void wakeUp(){ System.out.println(\u0026#34;宝宝醒啦\u0026#34;); } public void eat(){ Baby baby = new Baby(); baby.wakeUp(); System.out.println(\u0026#34;吃东西\u0026#34;); } } 这样不符合逻辑。这就相当于本对象的eat方法，需要调用另一个对象的wakeUp方法。\n我们看这个例子:\npublic class Baby { public void wakeUp() { System.out.println(\u0026#34;宝宝醒啦\u0026#34;); } public void eat() { this.wakeUp(); System.out.println(\u0026#34;吃东西\u0026#34;); } } 这样就符合逻辑了。自己的eat方法，还需要自己的一个wakeUp方法。\njava允许同一个对象的方法直接调用该对象的属性或者方法，所以this可以省略。\n注意：java中为什么在static中不能使用this关键字？\nStatic方法是类方法，先于任何的实例（对象）存在。即Static方法在类加载时就已经存在了，但是对象是在创建时才在内存中生成。而this指代的是当前的对象在方法中定义使用的this关键字,它的值是当前对象的引用。也就是说你只能用它来调用属于当前对象的方法或者使用this处理方法中成员变量和局部变量重名的情况，而且，更为重要的是this和super都无法出现在static 修饰的方法中，static 修饰的方法是属于类的，该方法的调用者可能是一个类,而不是对象。如果使用的是类来调用而不是对象，则 this就无法指向合适的对象.所以static 修饰的方法中不能使用this\n","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/java%E4%B8%ADthis%E5%85%B3%E9%94%AE%E5%AD%97%E6%98%93%E9%94%99%E7%82%B9%E5%92%8C%E8%AF%B4%E6%98%8E/","section":"Posts","summary":"\u003cp\u003e\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"\" src=\"https://img.hacpai.com/bing/20180324.jpg?imageView2/1/w/960/h/540/interlace/1/q/100\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e\n\n\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e今天首先来看个问题，用原生servlet实现的接口，大家看下控制台输出结果是什么？\u003c/p\u003e","title":"java中this关键字易错点和说明","type":"posts"},{"content":" 正文 # 大家在使用mysql过程中，可能会遇到类似以下的问题：\n模糊匹配 jg%，结果以JG开头的字符串也出现在结果集中，大家很自然的认为是大小写敏感的问题。那么mysql中大小写敏感是如何控制的；数据库名，表名，字段名这些字典对象以及字段值的大小敏感是如何控制的；以及校验规则与索引的关系，这是本文要讨论的内容。\n数据库名、表名：\nwindows建库：\nwindows建表：\nlinux建库：\nlinux建表：\n以上可以看出windows下大小写不敏感，linux下是敏感的，故前者不可以同时建test和TEST，而后者可以。\n大小写区分规则： # Linux下：\n数据库名与表名是严格区分大小写的；\n表的别名是严格区分大小写的；\n列名与列的别名在所有的情况下均是忽略大小写的；\n变量名也是严格区分大小写的；\nWindows下：\n都不区分大小写。 Mac OS下，文件系统类型HFS+，非UFS卷：\n都不区分大小写。 mysql中控制数据库名和表名的大小写敏感由参数lower_case_table_names控制，为0时表示区分大小写，为1时，表示将名字转化为小写后存储，不区分大小写。\n在mysql中，数据库对应数据目录中的目录。数据库中的每个表至少对应数据库目录中的一个文件(也可能是多个，取决于存储引擎)。因此，所使用操作系统的大小写敏感性决定了数据库名和表名的大小写敏感性。\nlower_case_file_system：\n变量说明是否数据目录所在的文件系统对文件名的大小写敏感。ON说明对文件名的大小写不敏感，OFF表示敏感。\nlower_case_table_names：\nunix下默认值为 0 ；Windows下默认值是 1 ；Mac OS X下默认值是 2\n***0：***使用CREATE TABLE或CREATE DATABASE语句指定的大小写字母在硬盘上保存表名和数据库名。名称比较对大小写敏感。在大小写不敏感的操作系统如windows或Mac OS x上我们不能将该参数设为0，如果在大小写不敏感的文件系统上将此参数强制设为0，并且使用不同的大小写访问MyISAM表名，可能会导致索引破坏。\n***1：***表名在硬盘上以小写保存，名称比较对大小写不敏感。MySQL将所有表名转换为小写在存储和查找表上。该行为也适合数据库名和表的别名。该值为Windows的默认值。\n***2：***表名和数据库名在硬盘上使用CREATE TABLE或CREATE DATABASE语句指定的大小写字母进行保存，但MySQL将它们转换为小写在查找表上。名称比较对大小写不敏感，即按照大小写来保存，按照小写来比较。注释：只在对大小写不敏感的文件系统上适用innodb表名用小写保存。\nwindows上：\nlinux上：\n为了避免大小写引发的问题，一种推荐的命名规则是：在定义数据库、表、列的时候全部采用小写字母加下划线的方式，不使用任何大写字母。\n字段名和字段值：\n字段名通常都是不区分大小写的。\n字段值的大小写由mysql的校对规则来控制。提到校对规则，就不得不说字符集。字符集是一套符号和编码，校对规则是在字符集内用于比较字符的一套规则，比如定义\u0026rsquo;A\u0026rsquo;\u0026lt;\u0026lsquo;B\u0026rsquo;这样的关系的规则。不同的字符集有多种校对规则，一般而言，校对规则以其相关的字符集名开始，通常包括一个语言名，并且以_ci（大小写不敏感）、_cs（大小写敏感）或_bin（二元）结束 。比如 utf8字符集，utf8_general_ci,表示不区分大小写，这个是utf8字符集默认的校对规则；utf8_general_cs表示区分大小写，utf8_bin表示二进制比较，同样也区分大小写。\n校对规则通过关键字collate指定，比如创建数据库test2，指定字符集为utf8，校对规则为utf8_bin\ncreate database test2 default character set utf8 collate utf8_bin; 通过上述语句说明数据库test2中的数据按utf8编码，并且是对大小写敏感的。\n有时候我们建库时，没有指定校对规则校对时字符大小写敏感，但是我们查询时，又需要对字符比较大小写敏感，就比如开篇中的例子，只想要jg开头的字符串。没关系，mysql提供了collate语法，通过指定utf8_bin校对规则即可。\n还有另外一种方法，通过binary关键字，将串转为二进制进行比较，由于大小写字符的二进制肯定不同，因此可以认为是区分大小的一种方式。\n校对规则与索引存储的关系。因为校对规则会用于字符串之间比较，而索引是基于比较有序排列的，因此校对规则会影响记录的索引顺序。下面举一个小例子说明：\n建表： create table test3(name varchar(100), primary key(name)); create table test4(name varchar(100), primary key(name)) collate utf8_bin; 给表test3插入数据： insert into test3(name) values(\u0026#39;abc\u0026#39;); insert into test3(name) values(\u0026#39;ABD\u0026#39;); insert into test3(name) values(\u0026#39;ZBC\u0026#39;); 给表test4插入数据： insert into test4(name) values(\u0026#39;abc\u0026#39;); insert into test4(name) values(\u0026#39;ABD\u0026#39;); insert into test4(name) values(\u0026#39;ZBC\u0026#39;); 查表： select * from test3; select * from test4; 从结果可以看到test3和test4返回的结果集中，记录的相对顺序是不同的，因为是全表扫描，返回的记录体现了主键顺序。由于test3表校验规则采用默认的utf8_general_ci，大小写不敏感，因此abc\u0026lt;ABC\u0026lt;ZBC；同理，test4采用utf8_bin，大小写敏感，因此ABD\u0026lt;ZBC\u0026lt;abc。\n关于mysql相关海量教程可以关注文末公众号回复【1】加助手微信索取。\n","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/mysql%E5%A4%A7%E5%B0%8F%E5%86%99%E6%95%8F%E6%84%9F%E4%B8%8E%E6%A0%A1%E5%AF%B9%E8%A7%84%E5%88%99/","section":"Posts","summary":"\u003cp\u003e\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"\" src=\"https://img.hacpai.com/bing/20190521.jpg?imageView2/1/w/960/h/540/interlace/1/q/100\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e\n\n\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e大家在使用mysql过程中，可能会遇到类似以下的问题：\u003c/p\u003e","title":"mysql大小写敏感与校对规则","type":"posts"},{"content":"","date":"2019年10月17日","externalUrl":null,"permalink":"/tags/xyplorer/","section":"Tags","summary":"","title":"XYplorer","type":"tags"},{"content":" 正文 # 在日常生活或工作中，除了一些文本编辑工具以及网页浏览器以外，我们接触的最多的可能就是资源管理器了。资源管理器软件有很多。如：\nClover 、QTTabBar、FreeCommander、WindowsTabs、Q-Dir、Total Commander等\n之前一直用Clover，它 是 Windows Explorer 资源管理器的一个扩展，为其增加类似谷歌 Chrome 浏览器的多标签页功能。但这款软件久无更新，且存在的问题让人用着很不爽：在win10下打开窗口会经常崩溃或反映迟钝或卡机失去响应，而且在底部增加了广告条，美名其曰“状态栏”，更是在书签里都放上了淘宝京东的推广链接。本来做的挺好的一款软件被糟蹋成这样，果断寻找了替代品XYplorer 。\nXYplorer 是一款资源管理器增强工具，提供多面板操作、将程序固定至任务栏、快捷文件新建等不常见的高效功能。XYplorer 凭借其强大性能以及对中文的友好支持，在中国用户之间有着非常高的传播度，其主要功能：\n1、多标签支持\n2、强制只能运行一个实例\n3、支持快捷键操作（ctrl+T）\n如果你有大量文件管理需求，建议你可以对比官网进行深度探索；如果你只是找一款clover的替代者，它会让你用得很舒爽，流畅性没得说。\n下面介绍几个吸引我的点\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\n双屏多标签：\n一般的文件管理器要么是只有双面板，要么是只有多标签，而XYplorer做到了真正的双面板多标签，在整理大量文件时实在是利器，即使不慎关闭不必担心，XYplorer 将为您记忆上次打开的所有标签以及双面板状态。\n自动计算文件夹大小：\n以往要用专门的软件或插件才能做到，而XYplorer原生即可计算，相当方便，而且速度非常快！（最牛X的是还能自定义文件夹大小的单位！）\n文件筛选：\nXYplorer 还同时提供了强大的文件筛选工具并支持用户自行设定的文件类型 (单种或多种拓展名)，其将为您筛选并显示某一或数个类型的所有文件以方便您进行批量操作。\n自定义命令：\n在平日整理文件时可能经常需要将某些类型的文件移动至某个文件夹，通过定义 XYplorer 用户命令，您可以先使用筛选工具选择您所需要处理的文件然后按下所定义的快捷键即可将文件备份、移动至指定文件夹，亦可对其路径进行自定义，例如按时间、按长度、按数量等方式建立文件夹等等。您可以单击动作后的技巧找到所有的可代替值，例如时间、路径、长度等。\n文件查找：\n加速查找文件的速度，比windows自带的查找功能流畅速度快，好用不卡。\n批量重命名：\n以上便是吸引我的点，而且我现在只用了不到20%的功能（对比官方的feature list），可想而知这个软件可定制度相当高，在日后工作中慢慢体会它的强大之处。\n文章中 XYplorer 软件可以关注文末公众号后在后台回复【1】 获取。\n","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/%E4%B8%80%E6%AC%BE%E6%9C%80%E5%A5%BD%E7%94%A8%E7%9A%84windows%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E5%99%A8/","section":"Posts","summary":"\u003cp\u003e\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"\" src=\"https://img.hacpai.com/bing/20180704.jpg?imageView2/1/w/960/h/540/interlace/1/q/100\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e\n\n\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e在日常生活或工作中，除了一些文本编辑工具以及网页浏览器以外，我们接触的最多的可能就是资源管理器了。资源管理器软件有很多。如：\u003c/p\u003e","title":"一款最好用的windows文件管理器","type":"posts"},{"content":" 正文 # 日志的转储和压缩是非常关键的，它不仅可以减少硬盘空间占用，主要还可以在发生故障时根据日志定位出故障原因。下面来看看golang和java的文件转储实现。\ngo语言： # 用到了filepath包下的Walk方法，具体说明可以参看历史文章：\ngo语言path/filepath包之Walk源码解析\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;io\u0026#34; \u0026#34;archive/zip\u0026#34; \u0026#34;path/filepath\u0026#34; \u0026#34;time\u0026#34; \u0026#34;log\u0026#34; ) func main() { logFile := \u0026#34;D:/tmp/successLog/logs/root.log\u0026#34; backFile := \u0026#34;D:/tmp/successLog/logs/root_\u0026#34; + time.Now().Format(\u0026#34;20060102150405\u0026#34;) + \u0026#34;.zip\u0026#34; err := zipFile(logFile, backFile) if err != nil { log.Println(fmt.Sprintf(\u0026#34;zip file %s to %s error : %v\u0026#34;, logFile, backFile, err)) return } else { os.Remove(logFile) } //转储后创建新文件 //createFile() //修改文件权限 //os.Chmod(backfile, 0400) //删除备份文件 //deleteOldBackfiles(dir) } func zipFile(source, target string) error { zipFile, err := os.OpenFile(target, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0440) if err != nil { log.Println(err) return err } defer zipFile.Close() archive := zip.NewWriter(zipFile) defer archive.Close() return filepath.Walk(source, func(path string, info os.FileInfo, err error) error { if err != nil { return err } header, err := zip.FileInfoHeader(info) if err != nil { return err } if !info.IsDir() { header.Method = zip.Deflate } header.SetModTime(time.Now().UTC()) header.Name = path writer, err := archive.CreateHeader(header) if err != nil { return err } if info.IsDir() { return nil } file, err := os.Open(path) if err != nil { return err } defer file.Close() _, err = io.Copy(writer, file) return err }) } java版： # 说明见注释。\nimport org.slf4j.Logger; import org.slf4j.LoggerFactory; import java.io.*; import java.text.DateFormat; import java.text.SimpleDateFormat; import java.util.zip.CRC32; import java.util.zip.CheckedOutputStream; import java.util.zip.ZipEntry; import java.util.zip.ZipOutputStream; /** * @program: website * @description: 转储压缩文件 * @author: smallsoup * @create: 2018-08-12 17:58 **/ public class ZipFile { private static final Logger LOGGER = LoggerFactory.getLogger(ZipFile.class); /** * 格式化文件名格式 */ private static final String AUDIT_LOG_FORMAT = \u0026#34;yyyyMMddHHmmssSSS\u0026#34;; /** * 压缩后文件后缀 */ private static final String AUDIT_FILE_ZIP_SUFFIX = \u0026#34;.zip\u0026#34;; /** * 压缩前文件后缀 */ private static final String AUDIT_FILE_EXT = \u0026#34;.log\u0026#34;; private static final int ZIP_BUFFER = 4096; /** * 控制压缩后的文件解压后是否带base路径 */ private static final String rootPath = \u0026#34;\u0026#34;; public static void main(String[] args) throws IOException { System.out.println(); new ZipFile().zipAuditLogFile(\u0026#34;D:/tmp/successLog/logs/root.log\u0026#34;); } /** * 日志压缩 * * @param waitZipFile 要压缩文件名 * @throws IOException */ private void zipAuditLogFile(String waitZipFile) throws IOException { File oldFile = new File(waitZipFile); if (!oldFile.exists()) { LOGGER.error(\u0026#34;zipAuditLogFile name is {} not exist\u0026#34;, waitZipFile); return; } //生成zip文件名 DateFormat dataFormat = new SimpleDateFormat(AUDIT_LOG_FORMAT); String formatTime = dataFormat.format(oldFile.lastModified()); int end = waitZipFile.length() - AUDIT_FILE_EXT.length(); String zipFileName = waitZipFile.subSequence(0, end) + \u0026#34;_\u0026#34; + formatTime + AUDIT_FILE_ZIP_SUFFIX; File zipFile = new File(zipFileName); FileOutputStream zipfos = null; ZipOutputStream zipOs = null; CheckedOutputStream cos = null; try { zipfos = new FileOutputStream(zipFile); cos = new CheckedOutputStream(zipfos, new CRC32()); zipOs = new ZipOutputStream(cos); compress(oldFile, zipOs, rootPath); if (zipFile.exists()) { // 写完的日志文件权限改为400 try { //linux上才可以运行,windows上需要装cygwin并且把cygwin的bin目录加到环境变量的path中才可以 Runtime.getRuntime().exec(\u0026#34;chmod 400 -R \u0026#34; + zipFile); //压缩后删除旧文件 boolean isDelete = oldFile.delete(); //创建新文件 if (isDelete) { oldFile.createNewFile(); } // boolean isSuccess = PathUtil.setFilePermision(zipFile.toPath(), ARCHIVE_LOGFILE_PERMISION); // LOGGER.warn(\u0026#34;set archive file: {}, permision result is {}\u0026#34;, zipFile.getAbsolutePath(), isSuccess); } catch (IOException e) { LOGGER.error(\u0026#34;set archive file:{} permision catch an error: {}\u0026#34;, zipFile, e); } } } finally { if (null != zipOs) { zipOs.close(); } if (null != cos) { cos.close(); } if (null != zipfos) { zipfos.close(); } } } /** * 压缩文件或目录 * * @param oldFile 要压缩的文件 * @param zipOut 压缩文件流 * @param baseDir baseDir * @throws IOException */ private void compress(File oldFile, ZipOutputStream zipOut, String baseDir) throws IOException { if (oldFile.isDirectory()) { compressDirectory(oldFile, zipOut, baseDir); } else { compressFile(oldFile, zipOut, baseDir); } } /** * 压缩目录 * * @param dir 要压缩的目录 * @param zipOut 压缩文件流 * @param baseDir baseDir * @throws IOException */ private void compressDirectory(File dir, ZipOutputStream zipOut, String baseDir) throws IOException { File[] files = dir.listFiles(); for (File file : files) { compress(file, zipOut, baseDir + dir.getName() + File.separator); } } /** * 压缩文件 * * @param oldFile 要压缩的文件 * @param zipOut 压缩文件流 * @param baseDir baseDir * @throws IOException */ private void compressFile(File oldFile, ZipOutputStream zipOut, String baseDir) throws IOException { if (!oldFile.exists()) { LOGGER.error(\u0026#34;zipAuditLogFile name is {} not exist\u0026#34;, oldFile); return; } BufferedInputStream bis = null; try { bis = new BufferedInputStream(new FileInputStream(oldFile)); ZipEntry zipEntry = new ZipEntry(baseDir + oldFile.getName()); zipOut.putNextEntry(zipEntry); int count; byte data[] = new byte[ZIP_BUFFER]; while ((count = bis.read(data, 0, ZIP_BUFFER)) != -1) { zipOut.write(data, 0, count); } } finally { if (null != bis) { bis.close(); } } } } 修改权限也可以利用Java7中NIO.2对元数据文件操作的支持，具体可以查看NIO包的使用，其相关教程见文末说明。\n代码如下：\npackage com.website.common; import java.io.IOException; import java.nio.file.FileSystems; import java.nio.file.Files; import java.nio.file.Path; import java.nio.file.attribute.PosixFilePermission; import java.nio.file.attribute.PosixFilePermissions; import java.util.Set; /** * 提供文件路径公共函数 改变权限，判断是否正规文件，判断是否路径在安全路径下等 * * @program: website * @description: 路径工具, 修改权限 * @author: smallsoup * @create: 2018-08-14 07:56 **/ public class PathUtil { /** * POSIX表示可移植操作系统接口,并不局限于unix类系统 */ private static final boolean ISPOSIX = FileSystems.getDefault().supportedFileAttributeViews().contains(\u0026#34;posix\u0026#34;); /** * 数字权限格式,如600 */ private static final int PERM_LEN_THREE = 3; /** * 如765 rwxrw_r_x */ private static final int PERM_LEN_NINE = 9; /** * 设置文件的权限，尽在posix下有效 * * @param file 文件 * @param perm 权限 类似 “rw-r-----”, \u0026#34;640\u0026#34; * @return true 修改成功 false 修改失败 * @throws IOException */ public static boolean setFilePermision(Path file, String perm) throws IOException { if (!ISPOSIX) { return true; } // 750 -\u0026gt; \u0026#34;rwxr-x---\u0026#34; if (perm.length() == PERM_LEN_THREE) { perm = trans2StrPerm(perm); } if (perm.length() != PERM_LEN_NINE) { return false; } Set\u0026lt;PosixFilePermission\u0026gt; perms = PosixFilePermissions.fromString(perm); Files.setPosixFilePermissions(file, perms); return true; } /** * 转换 * * @param digitPerm 长度为3的数字字符串 * @return */ private static String trans2StrPerm(String digitPerm) { StringBuilder builder = new StringBuilder(9); // owner builder.append(toStringPerm(digitPerm.charAt(0))); // group builder.append(toStringPerm(digitPerm.charAt(1))); // other builder.append(toStringPerm(digitPerm.charAt(2))); return builder.toString(); } private static String toStringPerm(char ch) { switch (ch - \u0026#39;0\u0026#39;) { case 7: return \u0026#34;rwx\u0026#34;; case 6: return \u0026#34;rw-\u0026#34;; case 5: return \u0026#34;r-x\u0026#34;; case 4: return \u0026#34;r--\u0026#34;; case 3: return \u0026#34;-wx\u0026#34;; case 2: return \u0026#34;-w-\u0026#34;; case 1: return \u0026#34;--x\u0026#34;; case 0: return \u0026#34;---\u0026#34;; default: return \u0026#34;\u0026#34;; } } } go语言、NIO等学习资料 可以关注文末公众号后在后台回复【1】 获取。\n","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/javagolang%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%E8%BD%AC%E5%82%A8%E5%8E%8B%E7%BC%A9%E5%AE%9E%E7%8E%B0/","section":"Posts","summary":"\u003cp\u003e\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"\" src=\"https://img.hacpai.com/bing/20190324.jpg?imageView2/1/w/960/h/540/interlace/1/q/100\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e\n\n\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e日志的转储和压缩是非常关键的，它不仅可以减少硬盘空间占用，主要还可以在发生故障时根据日志定位出故障原因。下面来看看golang和java的文件转储实现。\u003c/p\u003e","title":"java、golang日志文件转储压缩实现","type":"posts"},{"content":"","date":"2019年10月17日","externalUrl":null,"permalink":"/tags/%E6%97%A5%E5%BF%97/","section":"Tags","summary":"","title":"日志","type":"tags"},{"content":"","date":"2019年10月17日","externalUrl":null,"permalink":"/tags/typora/","section":"Tags","summary":"","title":"Typora","type":"tags"},{"content":" 正文 # Markdown 其实向来是文字爱好者和码农们的小众需求，市面上也涌现出了形形色色的 Markdown 编辑器，Mou、Typed、Ulysess、Macdown、简书、有道云等，这些比较流行的 Markdown 编辑器，都基本采用了「写字」和「预览」相分离的策略。\nTypora的设计理念就是极致简洁，它将「写字」和「预览」这两件事情合并了，输入的地方，也是输出的地方，即所见即所得。\n编辑预览合一：\n所有的行内元素（如加粗、斜体）都会根据当前是否在编辑态而智能地在编辑态和预览态切换，而区块级元素（如标题、列表）则会在按下 Enter 后即时渲染，不能再次编辑。\n表格、代码、公式编辑：\n之所以把这三个放一块是因为他们都是区块元素，而且它们都可以使用快捷键插入。\n表格：\n插入表格的快捷键在windows上是ctrl + T,效果如下：\n代码：\n输入```按下回车，如图：\n右下角可以输入代码的语言，可以根据不同的语言自动高亮显示，连 Swift 也不在例外。\n数学表达式：\n要启用这个功能，首先到Preference -\u0026gt; Editor中启用。\n然后使用$符号包裹Tex命令，例如：\n$lim_{x \\to \\infty} \\ exp(-x)=0$\n将产生如下的数学表达式：\nlimx→∞ exp(−x)=0\nTypora支持Latex的公式编辑，公式编辑几乎和代码编辑的使用方法相同，同样分行内公式和行间公式，行内公式用两个$包裹起来，行间公式可以使用快捷键ctrl+shift+m插入：\n插入图片：\n在传统的 Markdown 编辑器中，如果想要插入一张图片，默认的语法是这样的：\n而在 Typora 中，只需要像把图片拖拽进去，就大功告成了。再也不用记住语法格式，再也不用输文件名，再也不用自己去找文件的路径地址，就是这么简单。\n自定义主题：\n下载完成后默认会带有几套主题：Github、newprint、Night、pixyll、whitey\n导出：\nTypora的导出选项提供了很多选项，PDF、html等等，\n如下为导出的PDF格式预览：\n该软件的 windows和mac版的 可以关注文末公众号后在后台回复【1】，加小助手微信索取。\n","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/%E4%B8%80%E6%AC%BE%E5%BE%88%E5%A5%BD%E7%94%A8%E7%9A%84markdown%E7%BC%96%E8%BE%91%E5%99%A8/","section":"Posts","summary":"\u003cp\u003e\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"\" src=\"https://img.hacpai.com/bing/20190115.jpg?imageView2/1/w/960/h/540/interlace/1/q/100\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e\n\n\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003eMarkdown 其实向来是文字爱好者和码农们的小众需求，市面上也涌现出了形形色色的 Markdown 编辑器，Mou、Typed、Ulysess、Macdown、简书、有道云等，这些比较流行的 Markdown 编辑器，都基本采用了「写字」和「预览」相分离的策略。\u003c/p\u003e","title":"一款很好用的markdown编辑器","type":"posts"},{"content":" 正文 # 今天来看三件事：\n1、beego的两个重要参数： # beego.BConfig.CopyRequestBody：\n是否允许在HTTP请求时，返回原始请求体数据字节，默认为false（GET or HEAD or 上传文件请求除外）。\nbeego.BConfig.CopyRequestBody = false\n在controller中this.Ctx.Input.RequestBody取body体时，需要注意必须把app.conf中的CopyRequestBody属性设置为true，并保证配置文件能被读取到。只有在非GET请求，this.Ctx.Input.RequestBody才能取到请求中的body体。\nbeego.BConfig.RecoverPanic：\n是否异常恢复，默认值为 true，即当应用出现异常的情况，通过 recover 恢复回来，而不会导致应用异常退出。\nbeego.BConfig.RecoverPanic = true\n在这里有一点需要说明，利用beego搭建的web工程最好用bee工具运行，因为在beego1.6.1版本，用go run运行，程序运行过程中出现了\n**slice bounds out of range：**切片下标越界；\n或者\n**invalid memory address or nil pointer dereference：**没有初始化的地址，即空指针。\n都不会打印日志，加大问题定位难度。\n当使用beego1.8.3版本时，可以正常读到app.conf配置：\nCopyRequestBody = true HTTPPort = 8081 同样的app.conf配置，用beego1.6.1启动后：\n但用bee工具启动时加载正常：\n经查阅资料，发现这是beego1.6.1版本的bug，issue见：\nhttps://github.com/astaxie/beego/issues/1831\n有兴趣可以看看各位大佬激烈的讨论。\n2、beego参数接收：\n第一种：路径参数 (Path Parameters)：\n就是用 URL 路径的一部分来作为我们获取参数值的一种方式。\n如：\nbeego.Router(\u0026#34;/:ak/:sk\u0026#34;, \u0026amp;SayHelloController, \u0026#34;POST:SayHello\u0026#34;) 或者 beego.Router(\u0026#34;/?:ak/?:sk\u0026#34;, \u0026amp;SayHelloController, \u0026#34;GET:SayHello\u0026#34;) 接收方法如下：\n方法一： fmt.Println(\u0026#34;---ak is --- \u0026#34;, this.GetString(\u0026#34;:ak\u0026#34;)) fmt.Println(\u0026#34;---sk is --- \u0026#34;, this.GetString(\u0026#34;:sk\u0026#34;)) 方法二： sk1 := this.Ctx.Input.Param(\u0026#34;:sk\u0026#34;) ak1 := this.Ctx.Input.Param(\u0026#34;:ak\u0026#34;) 第二种：查询参数 (Query string)\n在 beego 中获取查询参数是十分方便的, 使用 beego.Controller.GetString() 便可以方便的获取查询参数（这个方法同样可以获取 request body 中的以 POST 方式发送的表单参数）。\n在url中?之后，以\u0026amp;分隔的键值对。从某种意义上将这些键值对与表单是起到相同作用的，只是一个放在URL中，一个放在body中（当然表单get方式提交也是放到url中）它们都可以用不带 : 的方式获取。\n方法一： //获取?后面\u0026amp;分隔的参数 name2 := this.Input()[\u0026#34;name\u0026#34;] age2 := this.Input()[\u0026#34;age\u0026#34;] fmt.Printf(\u0026#34;Name2:%s Age2:%s\\n\u0026#34;, name2, age2) 方法二： //获取?后面的参数 key不能加: name3 := this.GetString(\u0026#34;name\u0026#34;) age3 := this.GetString(\u0026#34;age\u0026#34;) fmt.Printf(\u0026#34;Name3:%s Age3:%s\\n\u0026#34;, name3, age3) 第三种：Web 表单 (Web form)：\n可以利用 beego.Controller.GetString() 获取；如果是post的请求方式，也可以定义和表单对应的struct，然后将this.Ctx.Input.RequestBody转换为结构体对象：\ntype MyStruct struct { Name string `json:\u0026#34;name\u0026#34;` Age int `json:\u0026#34;age\u0026#34;` } myStruct := MyStruct{} json.Unmarshal(this.Ctx.Input.RequestBody, \u0026amp;myStruct) 3、执行curl命令：\n执行curl命令调接口时，参数传递需要注意：\n如：\ncurl -X GET http://10.119.155.114:8081/jgjgjg/sqasdasda?name=jingge\u0026amp;age=21 -v 如果直接发送，\u0026amp; 会被系统解析（空格等字符也会被系统解析）\n需对特殊字符进行转义。上面的命令可以修改为：\ncurl -X GET http://10.119.155.114:8081/jgjgjg/sqasdasda?name=jingge\u0026amp;age=21 -v 在 \u0026amp; 前加转义符 \\ （ 空格可用+或者%20取代 ）\n或者给 url 加双引号，如：\ncurl -X GET \u0026#34;http://10.119.155.114:8081/jgjgjg/sqasdasda?name=jingge\u0026amp;age=21\u0026#34; -v 注意：\n我测试过，在windows上用%26代替\u0026amp;，都会导致name取到jingge\u0026amp;age=21整体，而age取不到值，用 \\ 转义会导致name取到jingge\\，而age取不到值，如下图：\n%26代替\u0026amp;：\n\\ 转义\u0026amp;：\n唯一可行的是在url上加双引号；\n在linux上用%26也会导致name取到jingge\u0026amp;age=21整体，而age取不到值，但是用 \\ 转义和加双引号都可以。\n","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/beego%E4%B8%8Ecurl%E4%B8%89%E4%BB%B6%E4%BA%8B/","section":"Posts","summary":"\u003cp\u003e\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"\" src=\"https://img.hacpai.com/bing/20190706.jpg?imageView2/1/w/960/h/540/interlace/1/q/100\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e\n\n\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e今天来看三件事：\u003c/p\u003e","title":"beego与curl三件事","type":"posts"},{"content":"","date":"2019年10月17日","externalUrl":null,"permalink":"/tags/curl/","section":"Tags","summary":"","title":"Curl","type":"tags"},{"content":"","date":"2019年10月17日","externalUrl":null,"permalink":"/tags/slf4j/","section":"Tags","summary":"","title":"Slf4j","type":"tags"},{"content":" 正文 # 日志相关包 slf4j打印日志必须的三个依赖包\nslf4j假设使用log4j做为底层日志工具，运行以上程序需要三个包：\nlog4j-1.2.xx.jar、 slf4j-api-x.x.x.jar、 slf4j-log4j12-x.x.x.jar \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;log4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;log4j\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.17\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.slf4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;slf4j-log4j12\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7.21\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.slf4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;slf4j-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7.21\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; log4j.properties文件配置：\n### set log levels ### log4j.rootLogger = INFO,root,stdout log4j.appender.stdout=org.apache.log4j.ConsoleAppender log4j.appender.stdout.layout=org.apache.log4j.PatternLayout log4j.appender.stdout.layout.conversionPattern=%d{yyyy-MM-dd HH:mm:ss.SSSXXX} %-5p [%t] [%C %L] %m%n log4j.appender.root.Append=true log4j.appender.root.File=${scheduleProject}logs/root.log log4j.appender.root.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss.SSSXXX} %-5p [%t] [%C %L] %m%n log4j.appender.root.layout=org.apache.log4j.PatternLayout log4j.appender.root.MaxBackupIndex=50 log4j.appender.root.MaxFileSize=20MB log4j.appender.root=org.apache.log4j.RollingFileAppender log4j.appender.root.zipPermission=400 log4j.appender.root.logPermission=600 web.xml配置：\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;web-app xmlns=\u0026#34;http://xmlns.jcp.org/xml/ns/javaee\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd\u0026#34; version=\u0026#34;3.1\u0026#34; metadata-complete=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;display-name\u0026gt;Archetype Created Web Application\u0026lt;/display-name\u0026gt; \u0026lt;!-- 加载log4j的配置文件log4j.properties --\u0026gt; \u0026lt;context-param\u0026gt; \u0026lt;param-name\u0026gt;log4jConfigLocation\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;classpath:config/log4j.properties\u0026lt;/param-value\u0026gt; \u0026lt;/context-param\u0026gt; \u0026lt;!-- 设定刷新日志配置文件的时间间隔，这里设置为10s --\u0026gt; \u0026lt;context-param\u0026gt; \u0026lt;param-name\u0026gt;log4jRefreshInterval\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;10000\u0026lt;/param-value\u0026gt; \u0026lt;/context-param\u0026gt; \u0026lt;!--加载Spring框架中的log4j监听器Log4jConfigListener--\u0026gt; \u0026lt;listener\u0026gt; \u0026lt;listener-class\u0026gt;org.springframework.web.util.Log4jConfigListener\u0026lt;/listener-class\u0026gt; \u0026lt;/listener\u0026gt; \u0026lt;!-- 为避免项目间冲突，定义唯一的 webAppRootKey --\u0026gt; \u0026lt;context-param\u0026gt; \u0026lt;param-name\u0026gt;webAppRootKey\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;scheduleProject\u0026lt;/param-value\u0026gt; \u0026lt;/context-param\u0026gt; \u0026lt;!-- 注册字符集过滤器 --\u0026gt; \u0026lt;filter\u0026gt; \u0026lt;filter-name\u0026gt;characterEncodingFilter\u0026lt;/filter-name\u0026gt; \u0026lt;filter-class\u0026gt;org.springframework.web.filter.CharacterEncodingFilter\u0026lt;/filter-class\u0026gt; \u0026lt;!-- 指定字符集编码 --\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;encoding\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;utf-8\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;filter-mapping\u0026gt; \u0026lt;filter-name\u0026gt;characterEncodingFilter\u0026lt;/filter-name\u0026gt; \u0026lt;url-pattern\u0026gt;/*\u0026lt;/url-pattern\u0026gt; \u0026lt;/filter-mapping\u0026gt; \u0026lt;!-- 注册前端控制器 --\u0026gt; \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;springmvc\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;org.springframework.web.servlet.DispatcherServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;contextConfigLocation\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;classpath*:config/spring-*.xml\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;springmvc\u0026lt;/servlet-name\u0026gt; \u0026lt;!--默认匹配所有的请求--\u0026gt; \u0026lt;url-pattern\u0026gt;/\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; \u0026lt;/web-app\u0026gt; ","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/slf4j%E6%89%93%E5%8D%B0%E6%97%A5%E5%BF%97%E5%BF%85%E9%A1%BB%E7%9A%84%E4%B8%89%E4%B8%AA%E4%BE%9D%E8%B5%96%E5%8C%85/","section":"Posts","summary":"\u003cp\u003e\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"\" src=\"https://img.hacpai.com/bing/20180329.jpg?imageView2/1/w/960/h/540/interlace/1/q/100\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e\n\n\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e日志相关包 slf4j打印日志必须的三个依赖包\u003cbr /\u003e\nslf4j假设使用log4j做为底层日志工具，运行以上程序需要三个包：\u003c/p\u003e","title":"slf4j打印日志必须的三个依赖包","type":"posts"},{"content":" 正文 # 安装MySql镜像 # \u0026gt; docker search mysql #查找MySql镜像版本 \u0026gt; docker pull mysql:tag #安装指定版本的mysql镜像，tag为版本号 例如：\n\u0026gt; docker pull mysql:5.6 #安装MySql 5.6版本镜像 启动MySql容器 # \u0026gt; docker run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag 例如：\n\u0026gt; docker run --name test-mysql -e MYSQL_ROOT_PASSWORD=123456 -d -p 3306:3306 mysql:5.6 #启动mysql 5.6版本镜像容器，通过--name取名test-mysql，设置root用户密码为123456，映射host的3306端口访问mysql 从host连接上述启动的container # \u0026gt; ifconfig #查看下docker虚拟出的ip地址 \u0026gt; docker ps -a #查看下容器的运行状态 \u0026gt; mysql -h {ip} -P {port} -u root -p #从host连接docker中的MySql 例如：\n\u0026gt; mysql -h 192.168.0.1 -P 3306 -u root -p 如果可以进入mysql命令终端，则表示一切安装配置成功。\n如果要用远程用Navicat连接mysql：\n创建honey用户，密码也为honey\ncreate user\u0026#39;honey\u0026#39;@\u0026#39;%\u0026#39;identified by\u0026#39;honey\u0026#39;; 查看用户honey的权限\nshow grants for \u0026#39;honey\u0026#39;@\u0026#39;%\u0026#39;; 创建数据库，honey用户只有操作museum_of_art数据库的权限。\ncreate database museum_of_art; 允许用户honey操作museum_of_art表\ngrant all on museum_of_art.* to\u0026#39;honey\u0026#39;@\u0026#39;%\u0026#39;; 开最大权限：\nGRANT ALL PRIVILEGES ON *.* TO \u0026#39;honey\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;honey\u0026#39;; GRANT ALL PRIVILEGES ON *.* TO \u0026#39;honey\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;honey\u0026#39;; 但这里有个问题如果要公网访问的话要注意几个点。首先是docker版本问题，我这里安装的是1.13.1 docker ，那么不需要再去开启http远程访问，默认是可以访问的。\n现在如果用在公网上用Navicat 是链接不上的。\n原因如下：\n首先需要登陆阿里云后台，添加阿里云安全组策略 具体位置\u0026ndash;网络和安全\u0026ndash;安全组\u0026ndash;配置规则\n可以选择多配置你需要的端口。\n下面我们需要配置阿里云防火墙\n查看下防火墙的状态： systemctl status firewalld 关闭防火墙： systemctl stop firewalld 其实这样就可以使用了，但是这样是很不安全，我们可以将firewall服务禁用，应用iptables服务（网上大部分启用端口的资料都是基于iptables服务）。\n安装iptables # 由于没有防火墙会造成不安全，所以给服务器安装一应用更广的防火墙iptables，首先要禁用firewall，通过yum安装iptables：\nsystemctil disable firewalld yum install -y iptables-services 启动iptables # systemctl start iptables 启动后可以通过systemctl status iptables查看状态。\n更改iptables规则 # 将iptables文件备份下： cp -a /etc/sysconfig/iptables /etc/sysconfig/iptables.bak 设置 INPUT 方向所有的请求都拒绝 iptables -P INPUT DROP 放开所需端口 iptables -I INPUT -p tcp --dport 3306 -m state --state NEW -j ACCEPT 保存规则 iptables-save \u0026gt; /etc/sysconfig/iptables 设置为开机启动并且重启 systemctl enable iptables.service systemctl reboot 好了，系统到这里我们需要重新去启动docker\nsystemctl start docker #运行Docker守护进程 这里如果直接启动镜像的话会报这个错误\n那么我们只需要重启下docker ,再去开启你的容器就OK了\nsystemctl restart docker 那么到这里我们外网就可以正常的去使用阿里云这里的mysql服务\n","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/mysql%E9%95%9C%E5%83%8F%E5%AE%89%E8%A3%85/","section":"Posts","summary":"\u003cp\u003e\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"\" src=\"https://img.hacpai.com/bing/20181021.jpg?imageView2/1/w/960/h/540/interlace/1/q/100\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e\n\n\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003chr /\u003e\n\n\u003ch2 class=\"relative group\"\u003e安装MySql镜像 \n    \u003cdiv id=\"安装mysql镜像\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e5%ae%89%e8%a3%85mysql%e9%95%9c%e5%83%8f\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e\u0026gt; docker search mysql #查找MySql镜像版本\n\u0026gt; docker pull mysql:tag #安装指定版本的mysql镜像，tag为版本号\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e例如：\u003c/p\u003e","title":"MySql镜像安装","type":"posts"},{"content":" 正文 # class FatherClass{ public FatherClass(){ System.out.println(\u0026#34;父类 无参 构造函数\u0026#34;); } public FatherClass(int i){ System.out.println(\u0026#34;父类 一个参数构造函数super = \u0026#34;+i); } public FatherClass(int i,String j){ System.out.println(\u0026#34;父类 一个参数构造函数superi = \u0026#34;+i+\u0026#34;,superj = \u0026#34;+j); } } class SonClass extends FatherClass{ public SonClass(){ // super(22);//line 1 System.out.println(\u0026#34;子类 无参 构造函数\u0026#34;); } public SonClass(int a){ super(33,\u0026#34;Hello\u0026#34;);//line 2 System.out.println(\u0026#34;子类一个参数构造函数sub = \u0026#34;+a); } public void fun(int a){//子类中定义一个实例函数 //super(33,\u0026#34;Hello\u0026#34;);//构造函数调用必须声明在构造函数中,这行代码不注释的话会报错 System.out.println(\u0026#34;子类一个参数构造函数sub = \u0026#34;+a); } } public class ConstructorExtend {//测试子类继承父类的构造函数 public static void main(String args[]){ // FatherClass fa = new FatherClass(); // FatherClass fa1 = new FatherClass(100); // SonClass son = new SonClass(); SonClass son1 = new SonClass(200); son1.fun(2); } } 子类 调用 父类的构造函数：（构造函数不会被继承，只是被子类调用而已）\n1、子类所有的 构造函数 默认调用父类的无参构造函数（其实是默认省略掉了一行代码：super();）;省略掉的这行super()代码可以自行添加到构造函数的第一行（必须是第一行，否则报错）\n2、如果父类没有定义构造函数，系统会默认定义一个无参无返回值的构造函数，子类继承时无需（无需的意思是：可以写可以不写）在子类构造函数中显式调用super( )；如果父类定义了有参构造函数，此时子类的构造函数中第一行必须显式调用父类定义的某个有参数构造函数。即，显式调用对应的参数个数、对应参数类型与此super( [arg0][,arg1]…. )的父类构造函数。\n3、如果子类的某个构造函数 想 调用父类的其他的带参数的构造函数，在构造函数的第一行人为添加 super(val1,val2[,val3…]),super()括号中的变量数量由想调用的父类的构造函数中的变量数量决定。如代码中的line 2，调用的是父类构造函数中两个参数的构造函数，那么Super(20,”Hello”)就两个变量。\n4、自行添加super(val1,val2,…),就可以指定调用父类的那个参数类型和数量一致的构造函数。之后在此子类构造函数中，系统不会再默认调用父类无参构造函数；\n5、如果子类的每个构造函数都自行添加super([val1,]….),除非人为调用父类无参构造函数，否则的话父类的无参构造函数可以不写。有super指定调用的父类构造函数存在即可\n6、super指代父类对象，可以在子类中使用 super.父类方法名(); 调用父类中的方法（无论是类方法还是实例方法都可以)，此外调用实例方法还可以在方法内部实例化再调用\n","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/java%E5%AD%90%E7%B1%BB%E8%B0%83%E7%94%A8%E7%88%B6%E7%B1%BB%E6%9E%84%E9%80%A0%E5%99%A8%E5%87%BD%E6%95%B0/","section":"Posts","summary":"\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-java\" data-lang=\"java\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"kd\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eFatherClass\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"kd\"\u003epublic\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nf\"\u003eFatherClass\u003c/span\u003e\u003cspan class=\"p\"\u003e(){\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e\u003cspan class=\"n\"\u003eSystem\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eout\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eprintln\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;父类 无参 构造函数\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"kd\"\u003epublic\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nf\"\u003eFatherClass\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ei\u003c/span\u003e\u003cspan class=\"p\"\u003e){\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e\u003cspan class=\"n\"\u003eSystem\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eout\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eprintln\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;父类 一个参数构造函数super = \u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e+\u003c/span\u003e\u003cspan class=\"n\"\u003ei\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"kd\"\u003epublic\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nf\"\u003eFatherClass\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ei\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"n\"\u003eString\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ej\u003c/span\u003e\u003cspan class=\"p\"\u003e){\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e\u003cspan class=\"n\"\u003eSystem\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eout\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eprintln\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;父类 一个参数构造函数superi = \u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e+\u003c/span\u003e\u003cspan class=\"n\"\u003ei\u003c/span\u003e\u003cspan class=\"o\"\u003e+\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;,superj = \u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e+\u003c/span\u003e\u003cspan class=\"n\"\u003ej\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"kd\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eSonClass\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kd\"\u003eextends\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eFatherClass\u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"kd\"\u003epublic\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nf\"\u003eSonClass\u003c/span\u003e\u003cspan class=\"p\"\u003e(){\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"c1\"\u003e//      super(22);//line 1\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e\u003cspan class=\"n\"\u003eSystem\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eout\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eprintln\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;子类 无参 构造函数\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"kd\"\u003epublic\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nf\"\u003eSonClass\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ea\u003c/span\u003e\u003cspan class=\"p\"\u003e){\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e\u003cspan class=\"kd\"\u003esuper\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e33\u003c/span\u003e\u003cspan class=\"p\"\u003e,\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;Hello\u0026#34;\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\u003cspan class=\"c1\"\u003e//line 2\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e\u003cspan class=\"n\"\u003eSystem\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eout\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eprintln\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;子类一个参数构造函数sub = \u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e+\u003c/span\u003e\u003cspan class=\"n\"\u003ea\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"kd\"\u003epublic\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nf\"\u003efun\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"kt\"\u003eint\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003ea\u003c/span\u003e\u003cspan class=\"p\"\u003e){\u003c/span\u003e\u003cspan class=\"c1\"\u003e//子类中定义一个实例函数\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e\u003cspan class=\"c1\"\u003e//super(33,\u0026#34;Hello\u0026#34;);//构造函数调用必须声明在构造函数中,这行代码不注释的话会报错\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e        \u003c/span\u003e\u003cspan class=\"n\"\u003eSystem\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eout\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003eprintln\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;子类一个参数构造函数sub = \u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e+\u003c/span\u003e\u003cspan class=\"n\"\u003ea\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"kd\"\u003epublic\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kd\"\u003eclass\u003c/span\u003e \u003cspan class=\"nc\"\u003eConstructorExtend\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"p\"\u003e{\u003c/span\u003e\u003cspan class=\"c1\"\u003e//测试子类继承父类的构造函数\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"kd\"\u003epublic\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kd\"\u003estatic\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"kt\"\u003evoid\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"nf\"\u003emain\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eString\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eargs\u003c/span\u003e\u003cspan class=\"o\"\u003e[]\u003c/span\u003e\u003cspan class=\"p\"\u003e){\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"c1\"\u003e//  FatherClass fa = new FatherClass();\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"c1\"\u003e//  FatherClass fa1 = new FatherClass(100);\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"c1\"\u003e//  SonClass son = new SonClass();\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"n\"\u003eSonClass\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eson1\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"k\"\u003enew\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"n\"\u003eSonClass\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e200\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"n\"\u003eson1\u003c/span\u003e\u003cspan class=\"p\"\u003e.\u003c/span\u003e\u003cspan class=\"na\"\u003efun\u003c/span\u003e\u003cspan class=\"p\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e2\u003c/span\u003e\u003cspan class=\"p\"\u003e);\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e\u003c/span\u003e\u003cspan class=\"p\"\u003e}\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e子类 调用 父类的构造函数：（构造函数不会被继承，只是被子类调用而已）\u003c/p\u003e","title":"java子类调用父类构造器函数","type":"posts"},{"content":" 正文 # 要求在页面查询到5000条数据，为了方便插入，用shell脚本写curl命令调用自己写的代码接口；\n脚本如下：\n#!/bin/bash a=0 while [ $a -le 10 ]; do # length of ts is 13 required,Through the following way like this ts=`date +%s%N` ts=${ts:0:13} json=\u0026#39;{\u0026#34;name\u0026#34; : \u0026#34;\u0026#39;$1$a\u0026#39;\u0026#34;, \u0026#34;age\u0026#34; : \u0026#39;$2\u0026#39;, \u0026#34;ts\u0026#34; : \u0026#39;$ts\u0026#39;}\u0026#39; a=$((a+1)) curl -k -H \u0026#39;Content-Type:application/json;charset=utf-8\u0026#39; http://192.168.2.5:8080 -X POST -d \u0026#34;\u0026#39;$json\u0026#39;\u0026#34; done 执行脚本\nsh batch_curl.sh gege 21\n执行结果\n该接口是用go语言提供的demo接口：如下：\n目录结构：\napp.conf copyrequestbody = true controller.go package controller import ( \u0026#34;github.com/astaxie/beego\u0026#34; \u0026#34;fmt\u0026#34; ) type SayHelloController struct { beego.Controller } func (this *SayHelloController) SayHello(){ fmt.Println(\u0026#34;RequestBody is \u0026#34;, string(this.Ctx.Input.RequestBody)) this.Ctx.Output.Header(\u0026#34;Content-type\u0026#34;, \u0026#34;application/json;charset=utf-8\u0026#34;) this.Ctx.Output.SetStatus(200) this.Ctx.Output.Body(this.Ctx.Input.RequestBody) } router.go package router import ( \u0026#34;github.com/astaxie/beego\u0026#34; \u0026#34;sayHello/controller\u0026#34; ) var hello = controller.SayHelloController{} func init() { beego.Router(\u0026#34;/\u0026#34;, \u0026amp;hello, \u0026#34;POST:SayHello\u0026#34;) } main.go package main import ( \u0026#34;github.com/astaxie/beego\u0026#34; _ \u0026#34;sayHello/router\u0026#34; \u0026#34;fmt\u0026#34; ) func main() { fmt.Println(beego.BConfig.CopyRequestBody) beego.Run() } ","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/shell%E8%84%9A%E6%9C%AC%E6%89%B9%E9%87%8F%E8%B0%83%E7%94%A8%E6%8E%A5%E5%8F%A3/","section":"Posts","summary":"\u003cp\u003e\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"\" src=\"https://img.hacpai.com/bing/20190405.jpg?imageView2/1/w/960/h/540/interlace/1/q/100\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e\n\n\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e  要求在页面查询到5000条数据，为了方便插入，用shell脚本写curl命令调用自己写的代码接口；\u003c/strong\u003e\u003c/p\u003e","title":"shell脚本批量调用接口","type":"posts"},{"content":" 正文 # 安装go后，我们一般会设置好GOROOT和GOPATH环境变量，但是有时候因为实际工作中项目结构复杂，设置的GOPATH不能满足需要时，可以在cmd设置临时的GOPATH；很多IDE，比如IDEA也可以设置全局的GOPATH和临时的GOPATH，但是编译可执行文件可能有些复杂或者通过IDE编译或者运行会出现app.conf配置文件加载不到的情况，这个坑我遇到过。请看https://github.com/astaxie/beego/issues/1831\n故通过命令的方式生成go的可执行文件。\n比如项目结构是这样：\n由于依赖了github.com里的beego，所以要加github.com的上级目录到GOPATH。\n1. 打开cmd命令窗口，用命令设置要编译包以及依赖包所在路径的环境变量，即GOPATH(该设置只对该窗口生效): # set GOPATH=E:\\ProgrammerRoute\\Go\\Development\\\n2.然后设置操作系统： # 生成windows的可执行文件: set GOOS=windows\n生成linux的可执行文件: set GOOS=linux\n3.然后在src目录下执行go install # go install sayHello\n没有报错的话，会在GOPATH下生成bin和pkg目录，可执行文件在bin目录下，如图：\n注：\nbeego1.7.0前的版本app.conf里的配置加载不到，以下的github有issue可寻：\nhttps://github.com/astaxie/beego/issues/1831\n利用beego1.7.0之后的版本，用IDE运行go工程也加载不到app.conf的配置，利用go install也加载不到；\n用go run main.go可以加载app.conf，用bee工具也可以加载到。\n","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/go%E8%AF%AD%E8%A8%80%E7%94%9F%E6%88%90%E5%8F%AF%E6%89%A7%E8%A1%8C%E6%96%87%E4%BB%B6/","section":"Posts","summary":"\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e安装go后，我们一般会设置好GOROOT和GOPATH环境变量，但是有时候因为实际工作中项目结构复杂，设置的GOPATH不能满足需要时，可以在cmd设置临时的GOPATH；很多IDE，比如IDEA也可以设置全局的GOPATH和临时的GOPATH，但是编译可执行文件可能有些复杂或者通过IDE编译或者运行会出现app.conf配置文件加载不到的情况，这个坑我遇到过。请看https://github.com/astaxie/beego/issues/1831\u003cbr /\u003e\n故通过命令的方式生成go的可执行文件。\u003c/p\u003e","title":"go语言生成可执行文件","type":"posts"},{"content":" 正文 # 1. VM8 使用固定IP：\n2. 这里使用NAT模式：\n3. VM中依次：编辑——\u0026gt;虚拟网络编辑器，点VMnet8 把使用本\n地DHCP的勾去掉，子网IP和主机VM8的IP同网段，然后点NAT设置。\n网关IP和刚才的IP也是同一个网段。 # 4. vim /etc/sysconfig/network-scripts/ifcfg-eno16777736\n增加这些： TYPE=Ethernet BOOTPROTO=static DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no NAME=eno16777736 UUID=0e2e0e3d-eaaf-4810-9c6a-dda5ebe0ac9c ONBOOT=yes IPADDR0=192.168.2.5 GATEWAY0=192.168.2.2 PREFIX0=24 DNS1=192.168.2.2 HWADDR=00:0C:29:1D:3A:DF PEERDNS=yes PEERROUTES=yes IPV6_PEERDNS=yes IPV6_PEERROUTES=yes 5. 修改完以后重启network\nsystemctl restart network\n或者用:\nservice network restart\n###注意：\n想要上网，即ping www.baidu.com不通时，\n要将/etc/sysconfig/network-scripts/ifcfg-eno16777736中的DNS1和GATEWAY1设置为一样的。\n","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/linux%E9%80%9A%E8%BF%87vmware%E5%92%8C%E4%B8%BB%E6%9C%BA%E7%9B%B8%E8%BF%9E%E8%BF%9E%E6%8E%A5%E4%BA%92%E8%81%94%E7%BD%91/","section":"Posts","summary":"\u003cp\u003e\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"\" src=\"https://img.hacpai.com/bing/20181014.jpg?imageView2/1/w/960/h/540/interlace/1/q/100\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e\n\n\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e1. VM8 使用固定IP：\u003c/strong\u003e\u003cbr /\u003e\n\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"VMnet8 IP设置\" src=\"https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy85MTM0NzYzLWUzMzA0OGM5ZWU3Njg2ODEucG5n?x-oss-process=image/format,png\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e","title":"linux通过VMware和主机相连连接互联网","type":"posts"},{"content":" 正文 # 要求在页面查询到5000条数据，为了方便插入，准备用shell脚本写curl命令调用自己写的代码接口，但是速度慢，而且写的时候遇到点儿小问题，故用sql语句写了这个功能\n由于operationlog表中的ts字段为13位的时间戳，所以采用了截取的方式。\nDROP TABLE IF EXISTS `operationlog`; CREATE TABLE `operationlog` ( `sn` int(11) NOT NULL AUTO_INCREMENT, `opl` varchar(8) NOT NULL, `src` varchar(32) NOT NULL, `pid` varchar(32) DEFAULT NULL, `ts` varchar(13) NOT NULL, PRIMARY KEY (`sn`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; drop procedure if exists batchAdd; /*count1 循环次数 opl和src为operationlog的列*/ create procedure batchAdd(in count1 int,in opl varchar(32),in src varchar(32)) begin declare a int; set a=0; while a\u0026lt;count1 do begin /*延时1s*/ select sleep(1); /*获取时间戳1523285555.207000,后面3位是0,现在的需求是ts为13位,即带ms的*/ select @time1:=unix_timestamp(now(3)); /*将1523285555.207000的.去掉*/ select @time1:=replace(@time1, \u0026#39;.\u0026#39;, \u0026#39;\u0026#39;); /*取1523285555207000左边13位*/ select @time1:=left(@time1, 13); /*生成sql,进行insert*/ insert into operationlog(opl, src, pid, ts) values(opl, src, \u0026#39;1111\u0026#39;, @time1); /*a加1*/ set a = a + 1; end; end while; end; --查看procedure show procedure status; --调用该procedure call batchAdd(10, \u0026#39;INFO\u0026#39;, \u0026#39;AJG\u0026#39;); --删除procedure drop procedure batchAdd; create procedure batchAdd如图所示： # 创建好procedure后,可以通过call batchAdd(10, \u0026lsquo;INFO\u0026rsquo;, \u0026lsquo;AJG\u0026rsquo;);来调用,如下图所示： # ","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/%E5%88%A9%E7%94%A8procedure%E6%89%B9%E9%87%8F%E6%8F%92%E5%85%A5%E6%95%B0%E6%8D%AE/","section":"Posts","summary":"\u003cp\u003e\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"\" src=\"https://img.hacpai.com/bing/20180204.jpg?imageView2/1/w/960/h/540/interlace/1/q/100\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e\n\n\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003e  要求在页面查询到5000条数据，为了方便插入，准备用shell脚本写curl命令调用自己写的代码接口，但是速度慢，而且写的时候遇到点儿小问题，故用sql语句写了这个功能\u003c/strong\u003e\u003cbr /\u003e\n\u003cstrong\u003e  由于operationlog表中的ts字段为13位的时间戳，所以采用了截取的方式。\u003c/strong\u003e\u003c/p\u003e","title":"利用procedure批量插入数据","type":"posts"},{"content":"","date":"2019年10月17日","externalUrl":null,"permalink":"/tags/ingress-nginx/","section":"Tags","summary":"","title":"Ingress-Nginx","type":"tags"},{"content":" 在Kubernetes中，服务和Pod的IP地址仅可以在集群网络内部使用，对于集群外的应用是不可见的。为了使外部的应用能够访问集群内的服务，在Kubernetes 目前 提供了以下几种方案：\nNodePort\nLoadBalancer\nIngress\n本节主要就ingress和ingress控制器ingress-nginx-controller的部署作简单介绍和记录。\n以下系统组件版本：\n云服务器：centos版本7.6.1810、k8s版本1.15.0、docker版本18.06.1-ce、ingress-nginx-controller版本0.25.0\nIngress\nIngress 组成？ # 将Nginx的配置抽象成一个Ingress对象，每添加一个新的服务只需写一个新的Ingress的yaml文件即可\n将新加入的Ingress转化成Nginx的配置文件并使之生效\ningress controller\ningress服务\nIngress 工作原理? # ingress controller通过和kubernetes api交互，动态的去感知集群中ingress规则变化， 然后读取它，按照自定义的规则，规则就是写明了哪个域名对应哪个service，生成一段nginx配置， 再写到nginx-ingress-controller的pod里，这个Ingress\ncontroller的pod里运行着一个Nginx服务，控制器会把生成的nginx配置写入/etc/nginx.conf文件中， 然后reload一下使配置生效。以此达到域名分配置和动态更新的问题。 Ingress 可以解决什么问题？ # 动态配置服务 # 如果按照传统方式, 当新增加一个服务时, 我们可能需要在流量入口加一个反向代理指向我们新的服务. 而如果用了Ingress, 只需要配置好这个服务, 当服务启动时, 会自动注册到Ingress的中, 不需要而外的操作.\n减少不必要的端口暴露 # 配置过k8s的都清楚, 第一步是要关闭防火墙的, 主要原因是k8s的很多服务会以NodePort方式映射出去, 这样就相当于给宿主机打了很多孔, 既不安全也不优雅. 而Ingress可以避免这个问题, 除了Ingress自身服务可能需要映射出去, 其他服务都不要用NodePort方式\nIngress当前的实现方式？ # ingress-nginx-controller # 目前最新版本的ingress-nginx-controller，用lua实现了当upstream变化时不用reload，大大减少了生产环境中由于服务的重启、升级引起的IP变化导致的nginx reload。\n以下就ingress-nginx-controller的部署做简单记录：\nyaml如下：\nkubectl apply -f {如下文件} apiVersion: v1 kind: Namespace metadata: name: ingress-nginx labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx --- kind: ConfigMap apiVersion: v1 metadata: name: nginx-configuration namespace: ingress-nginx labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx --- kind: ConfigMap apiVersion: v1 metadata: name: tcp-services namespace: ingress-nginx labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx --- kind: ConfigMap apiVersion: v1 metadata: name: udp-services namespace: ingress-nginx labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx --- apiVersion: v1 kind: ServiceAccount metadata: name: nginx-ingress-serviceaccount namespace: ingress-nginx labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx --- apiVersion: rbac.authorization.k8s.io/v1beta1 kind: ClusterRole metadata: name: nginx-ingress-clusterrole labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx rules: - apiGroups: - \u0026#34;\u0026#34; resources: - configmaps - endpoints - nodes - pods - secrets verbs: - list - watch - apiGroups: - \u0026#34;\u0026#34; resources: - nodes verbs: - get - apiGroups: - \u0026#34;\u0026#34; resources: - services verbs: - get - list - watch - apiGroups: - \u0026#34;\u0026#34; resources: - events verbs: - create - patch - apiGroups: - \u0026#34;extensions\u0026#34; - \u0026#34;networking.k8s.io\u0026#34; resources: - ingresses verbs: - get - list - watch - apiGroups: - \u0026#34;extensions\u0026#34; - \u0026#34;networking.k8s.io\u0026#34; resources: - ingresses/status verbs: - update --- apiVersion: rbac.authorization.k8s.io/v1beta1 kind: Role metadata: name: nginx-ingress-role namespace: ingress-nginx labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx rules: - apiGroups: - \u0026#34;\u0026#34; resources: - configmaps - pods - secrets - namespaces verbs: - get - apiGroups: - \u0026#34;\u0026#34; resources: - configmaps resourceNames: # Defaults to \u0026#34;\u0026lt;election-id\u0026gt;-\u0026lt;ingress-class\u0026gt;\u0026#34; # Here: \u0026#34;\u0026lt;ingress-controller-leader\u0026gt;-\u0026lt;nginx\u0026gt;\u0026#34; # This has to be adapted if you change either parameter # when launching the nginx-ingress-controller. - \u0026#34;ingress-controller-leader-nginx\u0026#34; verbs: - get - update - apiGroups: - \u0026#34;\u0026#34; resources: - configmaps verbs: - create - apiGroups: - \u0026#34;\u0026#34; resources: - endpoints verbs: - get --- apiVersion: rbac.authorization.k8s.io/v1beta1 kind: RoleBinding metadata: name: nginx-ingress-role-nisa-binding namespace: ingress-nginx labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx roleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: nginx-ingress-role subjects: - kind: ServiceAccount name: nginx-ingress-serviceaccount namespace: ingress-nginx --- apiVersion: rbac.authorization.k8s.io/v1beta1 kind: ClusterRoleBinding metadata: name: nginx-ingress-clusterrole-nisa-binding labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: nginx-ingress-clusterrole subjects: - kind: ServiceAccount name: nginx-ingress-serviceaccount namespace: ingress-nginx --- apiVersion: apps/v1 kind: Deployment metadata: name: nginx-ingress-controller namespace: ingress-nginx labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx spec: replicas: 1 selector: matchLabels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx template: metadata: labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx annotations: prometheus.io/port: \u0026#34;10254\u0026#34; prometheus.io/scrape: \u0026#34;true\u0026#34; spec: serviceAccountName: nginx-ingress-serviceaccount containers: - name: nginx-ingress-controller image: quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.25.0 args: - /nginx-ingress-controller - --configmap=$(POD_NAMESPACE)/nginx-configuration - --tcp-services-configmap=$(POD_NAMESPACE)/tcp-services - --udp-services-configmap=$(POD_NAMESPACE)/udp-services - --publish-service=$(POD_NAMESPACE)/ingress-nginx - --annotations-prefix=nginx.ingress.kubernetes.io securityContext: allowPrivilegeEscalation: true capabilities: drop: - ALL add: - NET_BIND_SERVICE # www-data -\u0026gt; 33 runAsUser: 33 env: - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace ports: - name: http containerPort: 80 - name: https containerPort: 443 livenessProbe: failureThreshold: 3 httpGet: path: /healthz port: 10254 scheme: HTTP initialDelaySeconds: 10 periodSeconds: 10 successThreshold: 1 timeoutSeconds: 10 readinessProbe: failureThreshold: 3 httpGet: path: /healthz port: 10254 scheme: HTTP periodSeconds: 10 successThreshold: 1 timeoutSeconds: 10 --- 在墙内会拉取不到以下镜像：\nquay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.25.0 可以使用国内阿里云镜像：\ndocker pull registry.cn-hangzhou.aliyuncs.com/google_containers/nginx-ingress-controller:0.25.0 安装后，在ingress-nginx命名空间下可以看到pod一直pending，describe pod报如下警告：\n查看master节点默认加了污点，一般不允许pod调度到master节点：\n如果k8s集群只有一个节点，可以在pod的spec下设置容忍该污点：\n即：\nspec: tolerations: - effect: NoSchedule key: node-role.kubernetes.io/master 可以看到ingress-nginx pod被调度到master节点，且变为Running\n看日志报以下警告：\nW0714 13:31:04.883127 6 queue.go:130] requeuing \u0026amp;ObjectMeta{Name:sync status,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:\u0026lt;nil\u0026gt;,DeletionGracePeriodSeconds:nil,Labels:map[string]string{},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],}, err services \u0026#34;ingress-nginx\u0026#34; not found 需要创一个名为ingress-nginx的service：\nkubectl apply -f {如下文件} kind: Service apiVersion: v1 metadata: name: ingress-nginx namespace: ingress-nginx labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx spec: externalTrafficPolicy: Local type: LoadBalancer selector: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/part-of: ingress-nginx ports: - name: http port: 80 targetPort: http - name: https port: 443 targetPort: https 参考： # ingress deploy\nhttps://github.com/kubernetes/ingress-nginx/blob/master/docs/deploy/index.md\nTaint和Toleration（污点和容忍）\nhttps://jimmysong.io/kubernetes-handbook/concepts/taint-and-toleration.html\nk8s 1.12部署ingress-nginx\nhttps://www.jianshu.com/p/e30b06906b77\n","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/k8s%E4%B8%AD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%99%A8ingressnginx%E9%83%A8%E7%BD%B2/","section":"Posts","summary":"\u003cp\u003e\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"\" src=\"https://img.hacpai.com/bing/20190422.jpg?imageView2/1/w/960/h/540/interlace/1/q/100\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e在Kubernetes中，服务和Pod的IP地址仅可以在集群网络内部使用，对于集群外的应用是不可见的。为了使外部的应用能够访问集群内的服务，在Kubernetes 目前 提供了以下几种方案：\u003c/p\u003e","title":"k8s中负载均衡器【ingress-nginx】部署","type":"posts"},{"content":"前提：亚马逊云已经配置好启动。\n安全组入站策略如下：\n出站策略如下：\n登陆EC2后，默认只能用ec2-user用户登陆，然后切换到root：\nsudo su 用yum执行安装docker提示No package docker avaible\nyum install docker -y 解决方法：\n在/etc/yum.repos.d/下加CentOS7-Base-163.repo文件：\nvi CentOS7-Base-163.repo # CentOS-Base.repo # # The mirror system uses the connecting IP address of the client and the # update status of each mirror to pick mirrors that are updated to and # geographically close to the client. You should use this for CentOS updates # unless you are manually picking other mirrors. # # If the mirrorlist= does not work for you, as a fall back you can try the # remarked out baseurl= line instead. # # [base] name=CentOS-$releasever - Base - 163.com baseurl=http://mirrors.163.com/centos/7/os/x86_64 gpgcheck=1 gpgkey=http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-7 #released updates [updates] name=CentOS-$releasever - Updates - 163.com baseurl=http://mirrors.163.com/centos/7/updates/x86_64 gpgcheck=1 gpgkey=http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-7 #additional packages that may be useful [extras] name=CentOS-$releasever - Extras - 163.com baseurl=http://mirrors.163.com/centos/7/extras/x86_64 gpgcheck=1 gpgkey=http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-7 #additional packages that extend functionality of existing packages [centosplus] name=CentOS-$releasever - Plus - 163.com baseurl=http://mirrors.163.com/centos/7/centosplus/x86_64 gpgcheck=1 enabled=0 gpgkey=http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-7 保存退出后，执行命令：\nyum makecache 然后执行yum安装docker命令：\nyum install docker -y 安装完后如下图：\n启动docker：\n## 启动 docker 服务 systemctl start docker chkconfig docker on 查看docker版本：\ndocker version 拉取 docker 镜像：\n好了，现在让我们直接拉取别人做好的 docker 镜像。这里选择的是 github上的 shadowsock vpn docker 镜像，直接执行以下命令：\ndocker pull oddrationale/docker-shadowsocks 运行 docker 镜像：\n运行如下命令启动该 docker 镜像。\ndocker run -d -p 8001:8001 oddrationale/docker-shadowsocks -s 0.0.0.0 -p 8001 -k yourpassword-m aes-256-cfb 运行docker ps -a查看容器是否已成功运行起来了。\ndocker ps -a linux上curl命令调：\ncurl -k localhost:8001 windows上curl命令调：\n回显如上说明已经部署好了，接下来你要干什么就是你的事了\u0026hellip;\n","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%BF%E7%94%A8docker%E6%90%AD%E5%BB%BA%E6%9C%8D%E5%8A%A1/","section":"Posts","summary":"\u003cp\u003e\u003cstrong\u003e前提：亚马逊云已经配置好启动。\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e安全组入站策略如下：\u003c/p\u003e\n\u003cp\u003e\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"在这里插入图片描述\" src=\"https://img-blog.csdnimg.cn/20190715082029462.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9saWFiaW8uYmxvZy5jc2RuLm5ldA==,size_16,color_FFFFFF,t_70\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003cbr /\u003e\n出站策略如下：\u003cbr /\u003e\n\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"在这里插入图片描述\" src=\"https://img-blog.csdnimg.cn/20190715082044270.png\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e","title":"云服务器使用docker搭建服务","type":"posts"},{"content":" Kubernetes 中使用 Job 和 CronJob 两个资源分别提供了一次性任务和定时任务的特性，这两种对象也使用控制器模型来实现资源的管理，我们在这篇文章来介绍Job执行如果失败了会怎么样呢？\n修改job-fail.yaml，故意引入一个错误：\nNever # 如果将 restartPolicy 设置为 Never 会怎么样？下面我们实践一下，修改job-fail.yaml后重新启动。\n运行 Job 并查看状态，可以看到Never策略的job，pod失败后，重新创建：\n直到重新创建7个（spec.backoffLimit默认为6，即重试6次，共7个pod）pod都失败后，认为失败，job的status里会更新为Failed\n当前 Completion 的数量为 0\n查看 Pod 的状态：\n可以看到有多个 Pod，状态均不正常。kubectl describe pod 查看某个 Pod 的启动日志：\n日志显示没有可执行程序，符合我们的预期。\n为什么 kubectl get pod 会看到这么多个失败的 Pod？\n原因是：当第一个 Pod 启动时，容器失败退出，根据 restartPolicy: Never，此失败容器不会被重启，但 Job DESIRED 的 Pod 是 1，目前 SUCCESSFUL 为 0，不满足，所以 Job controller 会启动新的 Pod，直到 SUCCESSFUL 为 1。对于我们这个例子，SUCCESSFUL 永远也到不了 1，所以 Job controller 会一直创建新的 Pod，直到设置的数量，失败后pod不会自动被删除，为了终止这个行为，只能删除 Job，pod也会被同时删掉。\nOnFailure # 如果将 restartPolicy 设置为 OnFailure 会怎么样？下面我们实践一下，修改job-fail.yaml后重新启动。 Job 的 Completions Pod 数量还是为 0，看看 Pod 的情况：\n这里只有一个 Pod，不过 RESTARTS 在不断增加，说明 OnFailure 生效，容器失败后会自动重启。\n6次失败后，pod被删除：\n同时更新job的status为失败，方便查看最终执行结果：\n","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/k8s%E4%BD%BF%E7%94%A8job%E6%89%A7%E8%A1%8C%E4%BB%BB%E5%8A%A1%E5%A4%B1%E8%B4%A5%E4%BA%86%E6%80%8E%E4%B9%88%E5%8A%9E/","section":"Posts","summary":"\u003cp\u003e\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"\" src=\"https://img.hacpai.com/bing/20180724.jpg?imageView2/1/w/960/h/540/interlace/1/q/100\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003eKubernetes 中使用 Job 和 CronJob 两个资源分别提供了一次性任务和定时任务的特性，这两种对象也使用控制器模型来实现资源的管理，我们在这篇文章来介绍Job执行如果失败了会怎么样呢？\u003c/p\u003e","title":"k8s使用Job执行任务失败了怎么办","type":"posts"},{"content":" 正文 # 前几天，在ucloud上搭建的k8s集群（搭建教程后续会发出）。今天发现域名解析不了。\n组件版本：k8s 1.15.0，coredns：1.3.1\n过程是这样的： # 首先用以下yaml文件创建了一个nginx服务\napiVersion: v1 kind: Service metadata: name: nginx-svc-old labels: app: nginx-svc spec: selector: app: nginx ports: - protocol: TCP port: 80 targetPort: 80 --- apiVersion: apps/v1beta1 kind: Deployment metadata: name: nginx-old spec: replicas: 1 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80 创建好之后：\n因只部署了一个master节点。在master宿主机上直接执行以下命令：\nnslookup nginx-svc-old.default.svc 发现不能解析域名。事先也在宿主机上/etc/resolv.conf里配置了nameserver {coredns的podIP}\n这样一来，就以为可能是coredns有问题。。\n然后用以下yaml创建了一个busybox作为调试工具：\napiVersion: extensions/v1beta1 kind: Deployment metadata: name: busybox-deployment spec: replicas: 1 template: metadata: labels: app: busybox spec: restartPolicy: Always containers: - name: busybox command: - sleep - \u0026#34;3600\u0026#34; image: busybox 这里用的是截止2019/07/20，busybox的最新镜像。创建好之后，exec进入容器，执行测试命令\n发现解析不了:\n/ # nslookup nginx-svc-old.default.svc Server: 10.96.0.10 Address: 10.96.0.10:53 ** server can\u0026#39;t find nginx-svc-old.default.svc: NXDOMAIN *** Can\u0026#39;t find nginx-svc-old.default.svc: No answer 根据coredns解析集群内域名原理可知：\n服务 a 访问服务 b，对于同一个 Namespace下，可以直接在 pod 中，通过 curl b 来访问。对于跨 Namespace 的情况，服务名后边对应 Namespace即可，比如 curl b.default。DNS 如何解析，依赖容器内 resolv 文件的配置。\n查看busybox容器内的resolve.conf文件：\n[root@liabio nginx]# kubectl exec -ti busybox-deployment-59755c8c6d-rmrfq sh / # nslookup nginx-svc-old.default.svc Server: 10.96.0.10 Address: 10.96.0.10:53 ** server can\u0026#39;t find nginx-svc-old.default.svc: NXDOMAIN *** Can\u0026#39;t find nginx-svc-old.default.svc: No answer / # cat /etc/resolv.conf nameserver 10.96.0.10 search default.svc.cluster.local svc.cluster.local cluster.local options ndots:5 / # 这个文件中，配置的 DNS Server，一般就是 K8S 中，kubedns 的 Service 的 ClusterIP，这个IP是虚拟IP，无法ping，但可以访问。\n在容器内发请求时，会根据 /etc/resolv.conf 进行解析流程。选择 nameserver 10.96.0.10 进行解析，然后用nginx-svc-old ，依次带入 /etc/resolve.conf 中的 search 域，进行DNS查找，分别是：\nsearch 内容类似如下（不同的pod，第一个域会有所不同）\nsearch default.svc.cluster.local svc.cluster.local cluster.local nginx-svc-old.default.svc.cluster.local -\u0026gt; nginx-svc-old.svc.cluster.local -\u0026gt; nginx-svc-old.cluster.local 直到找到为止。所以，我们执行 ping nginx-svc-old，或者执行 ping nginx-svc-old.default，都可以完成DNS请求，这2个不同的操作，会分别进行不同的DNS查找步骤。\n根据以上原理，查看到busybox内的域名/etc/resolv.conf没有问题，nameserver指向正确的kube-dns的service clusterIP。\n这下更加怀疑core-dns有问题了。\n但查看coredns日志，可以看到并没有报错：\n那就说明不是coredns问题了。。\n把busybox里报的错误，进行搜索google\n*** Can\u0026#39;t find nginx-svc-old.default.svc: No answer 查到了以下两个issue：\nissues1： # https://github.com/kubernetes/kubernetes/issues/66924\nissues2： # https://github.com/easzlab/kubeasz/issues/260\n发现都说是busybox镜像的问题，从1.28.4以后的镜像都存在这问题。把镜像换成1.28.4试试？修改yaml版本号：\napiVersion: extensions/v1beta1 kind: Deployment metadata: name: busybox-deployment spec: replicas: 1 template: metadata: labels: app: busybox spec: restartPolicy: Always containers: - name: busybox command: - sleep - \u0026#34;3600\u0026#34; image: busybox:1.28.4 重新apply后，进入容器：\n确实可以成功解析域名了。\n那为什么宿主机上直接执行测试命令，域名不能解析呢？\n继续google，知道resolver域名解析器：\nnameserver关键字，如果没指定nameserver就找不到DNS服务器，其它关键字是可选的。nameserver表示解析域名时使用该地址指定的主机为域名服务器。其中域名服务器是按照文件中出现的顺序来查询的，且只有当第一个nameserver没有反应时才查询下面的nameserver，一般不要指定超过3个服务器。\n而我在宿主上/etc/resolv.conf中nameserver如下：\n且前三个域名解析服务器后可以通。\n现在试着把coredns的其中一个podIP：192.168.155.73放到第一个nameserver：\n可以看到现在可以解析了。\n其实最好把kube-dns service的clusterIP放到/etc/resolv.conf中，这样pod重启后也可以解析。\n参考 # Linux中/etc/resolv.conf文件简析\nhttps://blog.csdn.net/lcr_happy/article/details/54867510\nCoreDNS系列1：Kubernetes内部域名解析原理、弊端及优化方式\nhttps://hansedong.github.io/2018/11/20/9/\n","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/%E9%87%87%E5%9D%91%E6%8C%87%E5%8D%97k8s%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90coredns%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%E8%BF%87%E7%A8%8B/","section":"Posts","summary":"\u003cp\u003e\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"\" src=\"https://img.hacpai.com/bing/20180826.jpg?imageView2/1/w/960/h/540/interlace/1/q/100\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e\n\n\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e前几天，在ucloud上搭建的k8s集群（搭建教程后续会发出）。今天发现域名解析不了。\u003c/p\u003e","title":"采坑指南——k8s域名解析coredns问题排查过程","type":"posts"},{"content":" 本文首发于公众号【我的小碗汤】扫描文末二维码关注，一起交流学习\n在云平台开发、中间件容器化时，经常会遇到批量删除k8s资源对象的需求，下面记录一下kubectl和golang发送删除pvc、pv、pod请求的例子，便于后续学习查阅\nkubectl发送删除请求 # 根据label批量删除pod：\nkubectl delete pod -n kube-system -l \u0026#34;harmonycloud.cn/statefulset=redis-ll-1010-a\u0026#34; 根据label批量删除pvc：\nkubectl delete pvc -n kube-system -l \u0026#34;harmonycloud.cn/statefulset=redis-ll-1010-a\u0026#34; 根据label批量删除pv：\nkubectl delete pv -l \u0026#34;harmonycloud.cn/statefulset=redis-ll-1010-a\u0026#34; golang发送删除请求 # 根据label批量删除pvc、pod、pv\n注意：启动参数中加入以下参数：\n--kubeconfig=/root/.kube/config --v=5 package operator import ( \u0026#34;flag\u0026#34; extensionsclient \u0026#34;k8s.io/apiextensions-apiserver/pkg/client/clientset/clientset\u0026#34; \u0026#34;k8s.io/apimachinery/pkg/api/errors\u0026#34; metav1 \u0026#34;k8s.io/apimachinery/pkg/apis/meta/v1\u0026#34; \u0026#34;k8s.io/apimachinery/pkg/labels\u0026#34; \u0026#34;k8s.io/apiserver/pkg/util/logs\u0026#34; clientset \u0026#34;k8s.io/client-go/kubernetes\u0026#34; restclient \u0026#34;k8s.io/client-go/rest\u0026#34; \u0026#34;k8s.io/client-go/tools/clientcmd\u0026#34; \u0026#34;k8s.io/klog\u0026#34; \u0026#34;os\u0026#34; \u0026#34;testing\u0026#34; ) type OperatorManagerServer struct { Master string Kubeconfig string } func NewOMServer() *OperatorManagerServer { s := OperatorManagerServer{} return \u0026amp;s } var s *OperatorManagerServer func init() { s = NewOMServer() flag.StringVar(\u0026amp;s.Master, \u0026#34;master\u0026#34;, s.Master, \u0026#34;The address of the Kubernetes API server (overrides any value in kubeconfig)\u0026#34;) flag.StringVar(\u0026amp;s.Kubeconfig, \u0026#34;kubeconfig\u0026#34;, s.Kubeconfig, \u0026#34;Path to kubeconfig file with authorization and master location information.\u0026#34;) //初始化klog等flag logs.InitLogs() flag.Parse() } func Test_DeleteCollection(t *testing.T) { if err := Run(s); err != nil { t.Fatalf(\u0026#34;%v\\n\u0026#34;, err) os.Exit(1) } } func Run(s *OperatorManagerServer) error { var ( generalLabelKey = \u0026#34;harmonycloud.cn/statefulset\u0026#34; redisClusterName = \u0026#34;redis-ll-1010\u0026#34; redisClusterNamespace = \u0026#34;kube-system\u0026#34; ) kubeClient, _, _, err := createClients(s) if err != nil { return err } //根据label批量删除pod labelPod := labels.SelectorFromSet(labels.Set(map[string]string{generalLabelKey: redisClusterName})) listPodOptions := metav1.ListOptions{ LabelSelector: labelPod.String(), } err = kubeClient.CoreV1().Pods(redisClusterNamespace).DeleteCollection(\u0026amp;metav1.DeleteOptions{}, listPodOptions) if err != nil { if !errors.IsNotFound(err) { klog.Errorf(\u0026#34;Drop RedisCluster: %v/%v pod error: %v\u0026#34;, redisClusterNamespace, redisClusterName, err) return err } } //根据label批量删除pvc labelPvc := labels.SelectorFromSet(labels.Set(map[string]string{\u0026#34;app\u0026#34;: redisClusterName})) listPvcOptions := metav1.ListOptions{ LabelSelector: labelPvc.String(), } err = kubeClient.CoreV1().PersistentVolumeClaims(redisClusterNamespace).DeleteCollection(\u0026amp;metav1.DeleteOptions{}, listPvcOptions) if err != nil { if !errors.IsNotFound(err) { klog.Errorf(\u0026#34;Drop RedisCluster: %v/%v pvc error: %v\u0026#34;, redisClusterNamespace, redisClusterName, err) return err } } //如果pv没有删除掉,则删除 labelPv := labels.SelectorFromSet(labels.Set(map[string]string{generalLabelKey: redisClusterName})) listPvOptions := metav1.ListOptions{ LabelSelector: labelPv.String(), } err = kubeClient.CoreV1().PersistentVolumes().DeleteCollection(\u0026amp;metav1.DeleteOptions{}, listPvOptions) if err != nil { if !errors.IsNotFound(err) { klog.Errorf(\u0026#34;Drop RedisCluster: %v/%v pv error: %v\u0026#34;, redisClusterNamespace, redisClusterName, err) return err } } return nil } //根据kubeconfig文件创建客户端 func createClients(s *OperatorManagerServer) (*clientset.Clientset, *extensionsclient.Clientset, *restclient.Config, error) { kubeconfig, err := clientcmd.BuildConfigFromFlags(s.Master, s.Kubeconfig) if err != nil { return nil, nil, nil, err } kubeconfig.QPS = 100 kubeconfig.Burst = 100 kubeClient, err := clientset.NewForConfig(restclient.AddUserAgent(kubeconfig, \u0026#34;operator-manager\u0026#34;)) if err != nil { klog.Fatalf(\u0026#34;Invalid API configuration: %v\u0026#34;, err) } extensionClient, err := extensionsclient.NewForConfig(restclient.AddUserAgent(kubeconfig, \u0026#34;operator-manager\u0026#34;)) if err != nil { klog.Fatalf(\u0026#34;Invalid API configuration: %v\u0026#34;, err) } return kubeClient, extensionClient, kubeconfig, nil } client-go中提供的\nDelete方法,只能删除单个资源对象,第一个参数往往是资源对象名称,第二个参数是删除选项，如：优雅终止时间GracePeriodSeconds、删除传播策略：Foreground前台删除、后台删除：Background、孤儿删除：Orphan\nDeleteCollection方法第一个参数是删除选项，第二个参数是删除条件，包括label Selector、field Selector等\nDelete(name string, options *metav1.DeleteOptions) error DeleteCollection(options *metav1.DeleteOptions, listOptions metav1.ListOptions) error 参考 # k8s官方API文档：\nhttps://kubernetes.io/docs/reference/generated/kubernetes-api/v1.10/#delete-collection-524\n","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/%E5%A6%82%E4%BD%95%E6%89%B9%E9%87%8F%E5%88%A0%E9%99%A4k8s%E8%B5%84%E6%BA%90%E5%AF%B9%E8%B1%A1/","section":"Posts","summary":"\u003cp\u003e\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"\" src=\"https://img.hacpai.com/bing/20180630.jpg?imageView2/1/w/960/h/540/interlace/1/q/100\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e本文首发于公众号【我的小碗汤】扫描文末二维码关注，一起交流学习\u003c/p\u003e","title":"如何批量删除k8s资源对象","type":"posts"},{"content":" 有些小伙伴可能不知道，亚马逊AWS对新用户有个免费体验一年的活动。如果希望体验免费亚马逊AWS云服务器产品，或者看看他们后台面板长什么样，体验产品的速度和性能，又或者准备搭建一个免费t z，可以\n注册玩玩。\n很简单，全程基本都是中文，不用担心看不懂英文。\n我是2018年6月30号注册的账号，在EC2面板创建了一个实例，平时就上上谷歌；国内网速慢，在上面下载一些kubernetes镜像，编译一些golang项目。\n悲剧的是我把时间记错了，以为是2016年8月10号开始使用的，能用到今年8月。直到8月份信用卡收到扣费提示，才发现时间记错了\u0026hellip;\n于是乎，赶紧到EC2 DashBoard面板把实例停止，删除掉，以为这样就不会再扣费了。\n结果到9月份又收到信用卡扣费提醒：\n这次我以为是扣除8月份的，也就20多元，没当回事。\n到10月份又收到信用卡扣费提醒：\n这次我就解释不了了。\n登陆亚马逊控制台，点击到【用户名】\u0026raquo; 我的账户 \u0026raquo; 账单，选择7月份，看到扣费详情：\n每个云服务器实例每小时0.0716美元，共使用160小时，扣费11.46美元；\n每月每GB通用固态SSD（gp2）预置存储0.10美元，使用6.422 GB，扣费0.64美元；\n每小时未附加到正在运行的实例的每个弹性IP地址0.005美元，扣费2.92美元；\n同样的查看了8，9，10月的扣费详情后。我把EC2 DashBoard里所有资源都删除掉。\n有一个默认安全组，是直接删不掉的，需要去删除vpc，安全组就会被删除。 如果不是因为免费，1核2M，40G硬盘这价格，其实还是很贵的。\n能不能把这些费用让退回来呢？于是我点击 支持中心 \u0026raquo; create case：\nI have released the cloud server since in August. Although the elastic IP service has not been released, but there is no traffic, Why does the elastic IP cost the billing in August, September and October? I think this is unreasonable, I need you to return the elastic IP fee deducted from August to October months. Pleas help and check and confim, contact me by my email 8374108792@qq.com or my phone +8615211111104. 提交后，过了几小时，客服回复我了\nHello, Thank you for your reply. I\u0026#39;ve immediately refund the charges back it will take 5 days to complete. Now for any Elastic Ip left idle or not associated with an instance a small charge gets generated I know you\u0026#39;ve not been aware. So to avoid unexpected charges in the future, please make sure to monitor your usage periodically and let us know if you have any questions regarding the billing aspects of our services. 大概意思是，会立即退还费用，但到账还需要5天才能完成。\n现在对于任何弹性Ip闲置或与一个小实例负责生成我知道你没有意识到。\n所以在未来避免意想不到的费用,请确认定期监控您的使用,让我们知道如果你有任何关于我们的计费方面的问题。\n在账单里查看到已经处理了退款： 提case时也不用担心英语不好，怕客服看不懂，直接在谷歌翻译上翻译一下就可以，基本都可以理解！\n其实AWS的服务真的挺好、只要不是恶意使用还去退款的、基本上都可以申请退款成功。\n如果你也在使用亚马逊，以下这些点还是得注意一下，避免带来困扰：\n需要用到手机号码PIN验证，以及信用卡会扣1美金作为验证卡是否能用的费用；\n免费12个月AWS云服务器，有流量限制的，如果超过流量会额外计费，如果不好过反正就免费使用。其规定的是一个周期30天内免费流量是15G，包括出和入的流量，如果超了就要从信用卡扣款。这一项一定要注意，而且注意是30天一个月如果有31天的话就需要停一天服务，流量监控可以在控制面板里面去查看；\n一年到期后，一定要记得释放所有资源，否则会出现直接在信用卡里扣费的情况，费用还是很高的。\n现在我用的是ucloud香港服务器，速度挺快，如果你也需要，可以点击以下链接去注册:\nhttps://passport.ucloud.cn/?invitation_code=C1xAF50DBB253EC\u0026ytag=re677q\n然后联系我的微信837448792,获取优惠方式！\n","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/%E4%BA%9A%E9%A9%AC%E9%80%8Aaws%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8D%E5%90%88%E7%90%86%E6%89%A3%E8%B4%B9%E6%80%8E%E4%B9%88%E5%A4%84%E7%90%86/","section":"Posts","summary":"\u003cp\u003e\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"\" src=\"https://img.hacpai.com/bing/20180512.jpg?imageView2/1/w/960/h/540/interlace/1/q/100\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e有些小伙伴可能不知道，亚马逊AWS对新用户有个免费体验一年的活动。如果希望体验免费亚马逊AWS云服务器产品，或者看看他们后台面板长什么样，体验产品的速度和性能，又或者准备搭建一个免费t z，可以\u003cbr /\u003e\n注册玩玩。\u003c/p\u003e","title":"亚马逊AWS云服务器不合理扣费怎么处理","type":"posts"},{"content":"","date":"2019年10月17日","externalUrl":null,"permalink":"/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/","section":"Tags","summary":"","title":"服务器","type":"tags"},{"content":" 几个月前我也开始在csdn上开了博客，一来给自己加几个少的可怜的流量，再者，让公众号的原创文章获得更多的曝光，让有需要的同学看到。\n写过csdn博客的同学都知道，默认只有打赏c币功能；也没有专门广告位；引导栏目，只有侧栏csdn自己的引导二维码。\n如何在csdn自定义栏目，加赞赏功能，或者其他等引导，让读者能很直观的看到，而不是在每篇文章加，增加自己工作量。这个功能以前对所有用户开放，但是很不幸，这功能被CSDN下架了，看下图：\n我也是之前为了给读者下载CSDN资料开了VIP，目前还有400次下载，为了限制，每天有8个免费下载名额，需要的可以扫码关注公众号，在后台回复【2】加我代下载。\n鼠标放到头像处，点击下拉框中的【管理博客】\u0026raquo; 点击侧栏的【博客模块管理】\n只能添加一条自定义栏目，栏目内容支持html，可以自由发挥：\n添加公众号引导 # \u0026lt;div\u0026gt; \u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;公众号\u0026lt;/strong\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;img src=\u0026#34;http://www.liabio.cn/img/me/gongzhonghao-ercode.jpg\u0026#34; alt=\u0026#34;长按识别二维码关注,精彩第一时间送达\u0026#34; --- title=\u0026#34;长按识别二维码关注,精彩第一时间送达\u0026#34; height=\u0026#34;100%\u0026#34; width=\u0026#34;100%\u0026#34;\u0026gt; \u0026lt;marquee\u0026gt;\u0026lt;font color=\u0026#34; red\u0026#34;\u0026gt;欢迎扫码关注！ \u0026lt;/font\u0026gt;\u0026lt;/marquee\u0026gt; \u0026lt;/div\u0026gt; 效果图 # 添加QQ、QQ群、邮箱、友情链接等： # \u0026lt;div id=\u0026#34;custom_column_27694137\u0026#34; class=\u0026#34;panel\u0026#34;\u0026gt; \u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;联系方式\u0026lt;/strong\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;br\u0026gt;\u0026lt;br\u0026gt; \u0026lt;ul class=\u0026#34;panel_head\u0026#34;\u0026gt; \u0026lt;span\u0026gt;\u0026lt;a target=\u0026#34;_blank\u0026#34; href=\u0026#34;http://sighttp.qq.com/msgrd?v=3\u0026amp;uin=1939137617\u0026amp;site=\u0026amp;menu=yes\u0026#34;\u0026gt;☞ 本人QQ: 1939137617\u0026lt;/a\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;ul class=\u0026#34;panel_head\u0026#34;\u0026gt; \u0026lt;span\u0026gt;\u0026lt;a target=\u0026#34;_blank\u0026#34; href=\u0026#34;//shang.qq.com/wpa/qunwpa?idkey=1a08adf5d7f9d49a2a83bb0d3b4acf0e94554895e12dc657ecfb88d706d82673\u0026#34;\u0026gt;\u0026lt;img border=\u0026#34;0\u0026#34; src=\u0026#34;//pub.idqqimg.com/wpa/images/group.png\u0026#34; alt=\u0026#34;程序员实战\u0026#34; --- title=\u0026#34;程序员实战\u0026#34;\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;ul class=\u0026#34;panel_head\u0026#34;\u0026gt; \u0026lt;span\u0026gt;\u0026lt;a target=\u0026#34;_blank\u0026#34; href=\u0026#34;https://github.com/liabio\u0026#34;\u0026gt;☞ github.com/liabio\u0026lt;/a\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;ul class=\u0026#34;panel_head\u0026#34;\u0026gt; \u0026lt;span\u0026gt;\u0026lt;a href=\u0026#34;mailto:coderaction@foxmail.com\u0026#34;\u0026gt;☞ coderaction@foxmail.com\u0026lt;/a\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;span\u0026gt;\u0026lt;a href=\u0026#34;https://liabio.blog.csdn.net/\u0026#34;\u0026gt;☞ https://liabio.blog.csdn.net/\u0026lt;/a\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;marquee\u0026gt;\u0026lt;font color=\u0026#34; red\u0026#34;\u0026gt;欢迎光临！ \u0026lt;/font\u0026gt;\u0026lt;/marquee\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;友情链接\u0026lt;/strong\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;br\u0026gt;\u0026lt;br\u0026gt; \u0026lt;a target=\u0026#34;_blank\u0026#34; href=\u0026#34;http://www.liabio.cn/\u0026#34;\u0026gt;【小碗汤】的博客\u0026lt;/a\u0026gt;\u0026lt;br\u0026gt;\u0026lt;br\u0026gt; \u0026lt;marquee\u0026gt;\u0026lt;font color=\u0026#34; red\u0026#34;\u0026gt;欢迎来踩！ \u0026lt;/font\u0026gt;\u0026lt;/marquee\u0026gt; \u0026lt;/div\u0026gt; 效果图 # 其中点击QQ会打开登陆QQ的对话框，只需要把href里链接中QQ号换为自己的；\n点击加入QQ群后会跳转到加群窗口，需要在https://qun.qq.com/join.html 网站中登陆需要绑定的QQ号 \u0026raquo; 选择群 \u0026raquo; 复制网页代码\n点击邮箱会打开邮箱登陆窗口，只需修改href中的邮箱即可\n添加打赏提问 # \u0026lt;div\u0026gt; \u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;欢迎打赏和提问\u0026lt;/strong\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;img src=\u0026#34;http://www.liabio.cn/img/fee-say2.png\u0026#34; alt=\u0026#34;长按识别提问码 向我提问\u0026#34; --- title=\u0026#34;长按识别提问码 向我提问\u0026#34; height=\u0026#34;100%\u0026#34; width=\u0026#34;100%\u0026#34;\u0026gt; \u0026lt;/div\u0026gt; 效果图 # 打赏问答图片由【Chat快问】小程序生成。\n微信、支付宝打赏 # \u0026lt;div\u0026gt; \u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;扫码打赏\u0026lt;/strong\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;br\u0026gt; \u0026lt;img src=\u0026#34;http://www.liabio.cn/img/wechat-zhifubao-QR.png\u0026#34; alt=\u0026#34;长按识别 微信|支付宝打赏通用\u0026#34; --- title=\u0026#34;长按识别 微信|支付宝打赏通用\u0026#34; height=\u0026#34;100%\u0026#34; width=\u0026#34;100%\u0026#34;\u0026gt; \u0026lt;/div\u0026gt; 只用一个二维码实现微信、支付宝打赏，由小程序【二维码合并】支持。\n整体代码 # \u0026lt;div id=\u0026#34;asideCustom41021941\u0026#34; class=\u0026#34;aside-box custom-box\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;aside-content clearfix\u0026#34;\u0026gt; \u0026lt;div\u0026gt; \u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;公众号\u0026lt;/strong\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;img src=\u0026#34;http://www.liabio.cn/img/me/gongzhonghao-ercode.jpg\u0026#34; alt=\u0026#34;长按识别二维码关注,精彩第一时间送达\u0026#34; --- title=\u0026#34;长按识别二维码关注,精彩第一时间送达\u0026#34; height=\u0026#34;100%\u0026#34; width=\u0026#34;100%\u0026#34;\u0026gt; \u0026lt;marquee\u0026gt;\u0026lt;font color=\u0026#34; red\u0026#34;\u0026gt;欢迎扫码关注！ \u0026lt;/font\u0026gt;\u0026lt;/marquee\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;br\u0026gt; \u0026lt;div id=\u0026#34;custom_column_27694137\u0026#34; class=\u0026#34;panel\u0026#34;\u0026gt; \u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;联系方式\u0026lt;/strong\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;ul class=\u0026#34;panel_head\u0026#34;\u0026gt; \u0026lt;span\u0026gt;\u0026lt;a target=\u0026#34;_blank\u0026#34; href=\u0026#34;http://sighttp.qq.com/msgrd?v=3\u0026amp;uin=1939137617\u0026amp;site=\u0026amp;menu=yes\u0026#34;\u0026gt;☞ 本人QQ: 1939137617\u0026lt;/a\u0026gt; \u0026lt;/span\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;ul class=\u0026#34;panel_head\u0026#34;\u0026gt; \u0026lt;span\u0026gt;\u0026lt;a target=\u0026#34;_blank\u0026#34; href=\u0026#34;//shang.qq.com/wpa/qunwpa?idkey=1a08adf5d7f9d49a2a83bb0d3b4acf0e94554895e12dc657ecfb88d706d82673\u0026#34;\u0026gt;\u0026lt;img border=\u0026#34;0\u0026#34; src=\u0026#34;//pub.idqqimg.com/wpa/images/group.png\u0026#34; alt=\u0026#34;程序员实战\u0026#34; --- title=\u0026#34;程序员实战\u0026#34;\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;ul class=\u0026#34;panel_head\u0026#34;\u0026gt; \u0026lt;span\u0026gt;\u0026lt;a target=\u0026#34;_blank\u0026#34; href=\u0026#34;https://github.com/liabio\u0026#34;\u0026gt;☞ github.com/liabio\u0026lt;/a\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;ul class=\u0026#34;panel_head\u0026#34;\u0026gt; \u0026lt;span\u0026gt;\u0026lt;a href=\u0026#34;mailto:coderaction@foxmail.com\u0026#34;\u0026gt;☞ coderaction@foxmail.com\u0026lt;/a\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;span\u0026gt;\u0026lt;a href=\u0026#34;https://liabio.blog.csdn.net/\u0026#34;\u0026gt;☞ https://liabio.blog.csdn.net/\u0026lt;/a\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;marquee\u0026gt;\u0026lt;font color=\u0026#34; red\u0026#34;\u0026gt;欢迎光临！ \u0026lt;/font\u0026gt;\u0026lt;/marquee\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;br\u0026gt; \u0026lt;div\u0026gt; \u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;友情链接\u0026lt;/strong\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;a target=\u0026#34;_blank\u0026#34; href=\u0026#34;http://www.liabio.cn/\u0026#34;\u0026gt;【小碗汤】的博客\u0026lt;/a\u0026gt;\u0026lt;br\u0026gt;\u0026lt;br\u0026gt; \u0026lt;marquee\u0026gt;\u0026lt;font color=\u0026#34; red\u0026#34;\u0026gt;欢迎来踩！ \u0026lt;/font\u0026gt;\u0026lt;/marquee\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;br\u0026gt; \u0026lt;div\u0026gt; \u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;欢迎打赏和提问\u0026lt;/strong\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;img src=\u0026#34;http://www.liabio.cn/img/fee-say2.png\u0026#34; alt=\u0026#34;长按识别提问码 向我提问\u0026#34; --- title=\u0026#34;长按识别提问码 向我提问\u0026#34; height=\u0026#34;100%\u0026#34; width=\u0026#34;100%\u0026#34;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;br\u0026gt; \u0026lt;div\u0026gt; \u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;扫码打赏\u0026lt;/strong\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;img src=\u0026#34;http://www.liabio.cn/img/wechat-zhifubao-QR.png\u0026#34; alt=\u0026#34;长按识别 微信|支付宝打赏通用\u0026#34; --- title=\u0026#34;长按识别 微信|支付宝打赏通用\u0026#34; height=\u0026#34;100%\u0026#34; width=\u0026#34;100%\u0026#34;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; 整体效果 # ","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/csdnvip%E5%A6%82%E4%BD%95%E6%B7%BB%E5%8A%A0%E8%87%AA%E5%AE%9A%E4%B9%89%E6%A0%8F%E7%9B%AE/","section":"Posts","summary":"\u003cp\u003e\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"\" src=\"https://img.hacpai.com/bing/20180806.jpg?imageView2/1/w/960/h/540/interlace/1/q/100\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003e几个月前我也开始在csdn上开了博客，一来给自己加几个少的可怜的流量，再者，让公众号的原创文章获得更多的曝光，让有需要的同学看到。\u003c/p\u003e","title":"CSDN VIP如何添加自定义栏目","type":"posts"},{"content":" readmore来源于：https://openwrite.cn/openwrite/openwrite-readmore/\n博客园接入 readmore 很简单，三步走，2 分钟搞定！\n在 OpenWrite 生成 readmore 脚本\n微信公众号设置关键词回复\n在博客园设置中添加脚本\n第一步， 在 OpenWrite 生成 readmore 脚本\n在 OpenWrite 后台，增长工具 / 博客导流公众号 目录下。点击添加按钮，填写博客和公众号信息，生成 readmore 脚本。\n第二步， 微信公众号设置关键词回复\n保存成功后在列表页中点击使用，根据使用指南设置公众号关键词回复，并复制 readmore 脚本。\n第三步，在博客园设置中添加脚本\n打开博客园，管理 / 设置页面，在最下方 页脚Html代码 中添加第二步中复制的代码，修改代码中的 id 为 cnblogs_post_body 点击保存。\nOK，再打开文章页面看看，文章是否隐藏了部分内容，最后出现了“阅读全文”按钮？\n","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/readmore%E4%B9%8Bcnblogs%E5%8D%9A%E5%AE%A2%E5%9B%AD%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/","section":"Posts","summary":"\u003cp\u003e\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"\" src=\"https://img.hacpai.com/bing/20180330.jpg?imageView2/1/w/960/h/540/interlace/1/q/100\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cp\u003ereadmore来源于：https://openwrite.cn/openwrite/openwrite-readmore/\u003c/p\u003e","title":"ReadMore 之 cnblogs 博客园使用指南","type":"posts"},{"content":" 正文 # Docker常用命令\nrun\ndocker run [OPTIONS] IMAGE [COMMAND] [ARG...] -e设置环境变量；-e username=zhj\n\u0026ndash;name为容器指定一个名称；\u0026ndash;name=zhj\n-p指定端口映射，格式为：主机(宿主)端口:容器端口 -p 80:8080\n-t为容器重新分配一个伪输入终端，通常与 -i 同时使用；\n-i以交互模式运行容器，通常与 -t 同时使用；\n-d后台运行容器，并返回容器ID；\n-v宿主机目录:容器目录。将宿主机目录挂载到容器内。\ndocker cp\n复制容器内的文件到宿主机 docker start\n启动一个或多个已经被停止的容器\ndocker stop\n停止一个运行中的容器\ndocker restart\n重启容器\ndocker rm\n删除容器\ndocker pause\n暂停容器中所有的进程;\ndocker unpause\n恢复容器中所有的进程;\ndocker exec ：\n在运行的容器中执行命令\ndocker exec -it mynginx /bin/sh /root/runoob.sh docker logs\n获取容器的日志;\ndocker ps\n列出UP的容器；docker ps -a列出所有容器。包括Exited等状态的容器；\ndocker top\n查看容器中运行的进程信息，支持 ps 命令参数;\ndocker inspect\n获取容器/镜像的元数据;\ndocker login\n登陆到一个Docker镜像仓库，如果未指定镜像仓库地址，默认为官方仓库 Docker Hub;\ndocker logout\n登出一个Docker镜像仓库，如果未指定镜像仓库地址，默认为官方仓库 Docker Hub;\ndocker tag\n标记本地镜像，将其归入某一仓库;\ndocker push\n将本地的镜像上传到镜像仓库,要先登陆到镜像仓库;\ndocker pull\n从镜像仓库中拉取或者更新指定镜像;\ndocker search\n从Docker Hub查找镜像;\ndocker images\n列出本地镜像;\ndocker rmi\n删除本地一个或多少镜像;\ndocker build\n命令用于使用 Dockerfile 创建镜像。\ndocker build -t runoob/ubuntu:v1 . 会默认使用当前目录的Dockerfile进行编译镜像，编译后的镜像名为runoob/ubuntu:v1\ndocker history\n查看指定镜像的创建历史\ndocker history runoob/ubuntu:v3 docker save\n将指定镜像保存成 tar 归档文件。\ndocker save -o my_ubuntu_v3.tar runoob/ubuntu:v3 docker load\n导入使用 docker save命令导出的镜像。\ndocker load -i my_ubuntu_v3.tar -i参数指定输入的文件。\ndocker info\n显示 Docker 系统信息，包括镜像和容器数。\ndocker version\n显示 Docker 版本信息。\nDocker的存储驱动\nDocker支持AUFS、Btrfs、Device mapper、OverlayFS、ZFS五种存储驱动；\n写时复制（CoW）\n所有驱动都用到的技术——写时复制（CoW）。CoW就是copy-on-write，表示只在需要写时才去复制，这个是针对已有文件的修改场景。比如基于一个image启动多个Container，如果为每个Container都去分配一个image一样的文件系统，那么将会占用大量的磁盘空间。而CoW技术可以让所有的容器共享image的文件系统，所有数据都从image中读取，只有当要对文件进行写操作时，才从image里把要写的文件复制到自己的文件系统进行修改。写操作会在每个容器的文件系统里生成一个复本，每个容器修改的都是自己的复本，相互隔离，相互不影响。使用CoW可以有效的提高磁盘的利用率。\n用时分配（allocate-on-demand）\n而写时分配是用在原本没有这个文件的场景，只有在要新写入一个文件时才分配空间，这样可以提高存储资源的利用率。比如启动一个容器，并不会为这个容器预分配一些磁盘空间，而是当有新文件写入时，才按需分配新空间。\nOverlay VS Device mapper\ndevicemapper将所有的镜像和容器存储在自己的虚拟块设备上，所有的操作都是直接对块进行操作，而不是文件。当要写入一个新文件时，在容器的镜像内为其分配新的块并写入数据，这个叫用时分配。当要修改已有文件时，再使用CoW为容器快照分配块空间，将要修改的数据复制到在容器快照中新的块里再进行修改。\noverlay是基于文件级的存储。只有两层：一个upper文件系统和一个lower文件系统，分别代表Docker的镜像层和容器层。当需要修改一个文件时，使用CoW将文件从只读的lower复制到可写的upper进行修改，结果也保存在upper层。\nOverlay是文件级存储，Device mapper是块级存储，当文件特别大而修改的内容很小，Overlay不管修改的内容大小都会复制整个文件，对大文件进行修改显示要比小文件要消耗更多的时间，而块级无论是大文件还是小文件都只复制需要修改的块，并不是整个文件，在这种场景下，显然device mapper要快一些。因为块级的是直接访问逻辑盘，适合IO密集的场景。而对于程序内部复杂，大并发但少IO的场景，Overlay的性能相对要强一些。\nOverlay VS Overlay2\noverlay驱动只工作在一个lower OverlayFS层之上，因此需要硬链接来实现多层镜像，但overlay2驱动原生地支持多层lowerOverlayFS镜像（最多128层）。因此overlay2驱动在合层相关的命令（如build和commit）中提供了更好的性能，与overlay驱动对比，消耗了更少的inode。\nDocker的网络模式\n可以看：[docker的五种网络模式总结]\nhttps://blog.csdn.net/u010900754/article/details/78526443\n安装 Docker 时，它会自动创建 3 个网络。可以使用 docker network ls命令列出这些网络。\n这 3 个网络包含在 Docker 实现中。运行一个容器时，可以使用 the \u0026ndash;net标志指定您希望在哪个网络上运行该容器。您仍然可以使用这 3 个网络。\nbridge 网络表示所有 Docker 安装中都存在的 docker0 网络。除非使用docker run \u0026ndash;net=选项另行指定，否则 Docker 守护进程默认情况下会将容器连接到此网络。在主机上使用 ifconfig命令，可以看到此网桥是主机的网络堆栈的一部分。\nnone 网络在一个特定于容器的网络堆栈上添加了一个容器。该容器缺少网络接口。\nhost 网络在主机网络堆栈上添加一个容器。容器中的网络配置与主机相同。可以通过主机IP访问，端口也会使用主机端口。所以主机端口不能被占用，否则容器启动会有问题。\nDockerfile知识点\nENV\n设置环境变量指令，用法\nENV WORKPATH /tmp 也可以这样:\nENV abc=bye def=$abc 第一种用法用于设置单个变量(第一个空格前为key，之后都是value,包括后面的空格)，第二种用于同时设置多个变量(空格为分隔符，value中包含空格时可以用双引号把value括起来，或者在空格前加\\反斜线)，当需要同时设置多个环境变量时推荐使用第二种格式。这些环境变量可以通过docker run命令的\u0026ndash;env参数来进行修改。\nENV用法如下：\nENV myName John Doe ENV myDog Rex The Dog ENV myCat fluffy FROM\n设置基础镜像，一个有效的Dockerfile必须有一个FROM指令指定一个基础镜像，这个镜像可以是任何你可以从共用仓库获取到的镜像。执行命令格式\nFROM \u0026lt;image\u0026gt; 或者\nFROM \u0026lt;image\u0026gt;:\u0026lt;tag\u0026gt; 或者\nFROM \u0026lt;image\u0026gt;@\u0026lt;digest\u0026gt; MAINTAINER\n设置创建镜像的作者信息。\nMAINTAINER zhanghaojie@qq.com RUN\n这个指令有两种格式.\n第一种形式：\nRUN chown user2:user2 /home/webapi (以shell形式执行命令，等同于/bin/sh -c); 第二种形式：\nRUN [\u0026#34;executable\u0026#34;,\u0026#34;param1\u0026#34;, \u0026#34;param2\u0026#34;] (等同于exec命令形式)，注意此处必须是双引号(\u0026quot;)，因为这种格式被解析为JSON数组。\nARG\nARG \u0026lt;name\u0026gt;[=\u0026lt;default value\u0026gt;] ARG指令设置一些创建镜像时的参数，这些参数可以在执行docker build命令时通过\u0026ndash;build-arg =设置，如果指定的创建参数在Dockerfile中没有指定，创建时会输出错误信息: One or more build-args were not consumed, failing build.\nDockerfile 作者可以为ARG设置一个默认参数值，当创建镜像时如果没有传入参数就会使用默认值：\nFROM busybox 我们可以使用ARG或者ENV指令来指定RUN指令使用的变量。我们可以使用ENV定义与ARG定义名称相同的变量来覆盖ARG定义的变量值。如下示例，我们执行\ndocker build --build-arg CONT_IMG_VER=v2.0.1 Dockerfile 后将获取到的CONTIMGVER变量值为v1.0.0:\nFROM ubuntu WORKDIR\nWORKDIR /path/to/workdir WORKDIR指令用来设置Dockerfile中任何使用目录的命令的当前工作目录，此目录如果不存在就会被自动创建，即使这个目录不被使用\nVOLUME\nVOLUME [\u0026#34;/data\u0026#34;] (exec格式指令) VOLUME指令创建一个可以从本地主机或其他容器挂载的挂载点。经常用到的是\ndocker run -ti -v /data:/data nginx:1.12 bash 时指定本地路径和容器内路径的映射。\nCOPY\nCOPY指令能够将构建命令所在的主机本地的文件或目录，复制到镜像文件系统。\nexec格式用法（推荐）：\nCOPY [\u0026#34;\u0026lt;src\u0026gt;\u0026#34;,... \u0026#34;\u0026lt;dest\u0026gt;\u0026#34;] 特别适合路径中带有空格的情况。\nshell格式用法：\nCOPY \u0026lt;src\u0026gt;... \u0026lt;dest\u0026gt; ADD\nADD指令不仅能够将构建命令所在的主机本地的文件或目录，而且能够将远程URL所对应的文件或目录，作为资源复制到镜像文件系统。\n所以，可以认为ADD是增强版的COPY，支持将远程URL的资源加入到镜像的文件系统。\nexec格式用法（推荐）：\nADD [\u0026#34;\u0026lt;src\u0026gt;\u0026#34;,... \u0026#34;\u0026lt;dest\u0026gt;\u0026#34;] 特别适合路径中带有空格的情况。\nshell格式用法：\nADD \u0026lt;src\u0026gt;... \u0026lt;dest\u0026gt; 说明，对于从远程URL获取资源的情况，由于ADD指令不支持认证，如果从远程获取资源需要认证，则只能使用RUN wget或RUN curl替代。\n另外，如果源路径的资源发生变化，则该ADD指令将使Docker Cache失效，Dockerfile中后续的所有指令都不能使用缓存。因此尽量将ADD指令放在Dockerfile的后面。\n**参考：**Dockerfile中的COPY和ADD指令详解与比较\nhttps://blog.csdn.net/taiyangdao/article/details/73222601\nEXPOSE指令\nEXPOSE \u0026lt;端口\u0026gt; [\u0026lt;端口\u0026gt;...] 指令用于标明，这个镜像中的应用将会侦听某个端口，并且希望能将这个端口映射到主机的网络界面上。但是，为了安全，docker run命令如果没有带上响应的端口映射参数，docker并不会将端口映射到宿主机。\nCMD 与 ENTRYPOINT\n二者的区别看：[docker CMD ENTRYPOINT 区别 终极解读]\nhttps://blog.csdn.net/u010900754/article/details/78526443\n从根本上说, ENTRYPOINT和CMD都是让用户指定一个可执行程序, 这个可执行程序在container启动后自动启动. 实际上, 如果你想让自己制作的镜像自动运行程序(不需要在docker run后面添加命令行指定运行的命令), 你必须在Dockerfile里面，使用ENTRYPOINT或者CMD命令。在命令行启动docker镜像时, 执行其他命令行参数，覆盖默认的CMD。和CMD类似, 默认的ENTRYPOINT也在docker run时, 也可以被覆盖. 在运行时, 用\u0026ndash;entrypoint覆盖默认的ENTRYPOINT。\ndockerfile中的CMD命令被覆盖：\n***CMD：***提供了容器默认的执行命令。Dockerfile 只允许使用一次 CMD 指令。使用多个 CMD 会抵消之前所有的指令，只有最后一个指令生效。CMD 有三种形式：\nCMD [\u0026#34;executable\u0026#34;,\u0026#34;param1\u0026#34;,\u0026#34;param2\u0026#34;] (exec form, thisis the preferred form) ***ENTRYPOINT：***配置给容器一个可执行的命令，这意味着在每次使用镜像创建容器时一个特定的应用程序可以被设置为默认程序。同时也意味着该镜像每次被调用时仅能运行指定的应用。类似于CMD，Docker只允许一个ENTRYPOINT，多个ENTRYPOINT会抵消之前所有的指令，只执行最后的ENTRYPOINT指令。语法如下：\nENTRYPOINT [\u0026#34;executable\u0026#34;, \u0026#34;param1\u0026#34;,\u0026#34;param2\u0026#34;] ","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%85%A8docker%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%B1%87%E6%80%BB/","section":"Posts","summary":"\u003cp\u003e\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"\" src=\"https://img.hacpai.com/bing/20191002.jpg?imageView2/1/w/960/h/540/interlace/1/q/100\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e\n\n\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eDocker常用命令\u003c/strong\u003e\u003c/p\u003e","title":"史上最全docker基础知识汇总","type":"posts"},{"content":" 正文 # 使用过docker的都知道dockerfile，其用于定义制作镜像的流程，由一系列命令和参数构成的脚本，这些命令应用于基础镜像并最终创建一个新的镜像。可参考往期文章学习：docker基础知识整理\n有时候，我们想在原有镜像基础上修改、增加文件，由于国内网络原因，重新制作镜像会很慢，甚至失败；或者根本不知道镜像的dockerfile长什么样。改动很小情况下，可以用以下方式制作镜像。\n拿k8s负载均衡器组件ingress-nginx:0.24.1版本为例：\n如果我们修改了其源码，并编译生成nginx-ingress-controller二进制文件，可以用以下方式进行制作新镜像。\n首先用命令：\ndocker run -ti --rm k8s-deploy/nginx-ingress-controller:0.24.1 bash 将镜像运行起来。其中-ti表示打开一个交互输入终端；\u0026ndash;rm表示运行停止后自动清理。\n运行后可以看到默认用户为www-data，a298fe62a4f9表示容器id\n我们可以在容器里创建目录：\n重新打开一个shell窗口，用于给容器内复制一个测试文件：\ndocker cp ingressgroup-upstream.tmpl a298fe62a4f9:/etc/nginx/conf.d/include-server-map/ 复制进去后，当要将其移动到其他位置时，报Permission denied权限不足，因为默认为www-data用户，复制到容器内的ingressgroup-upstream.tmpl属主:属组也是root，如果不把root修改为www-data，肯定会报没权限的错。\n通过以下命令重新运行镜像：\ndocker run -ti --rm -u 0 k8s-deploy/nginx-ingress-controller:0.24.1 bash -u 0代表用root用户运行容器，而不是dockerfile里指定的用户，这样运行后可以看到用户为root，记录容器id:ffdc80f3cce7\n重新执行复制操作：\n此时就可以随意移动和修改文件的权限、属组、属主了。\n修改完毕后，执行以下命令将镜像commit到本地仓库：\ndocker commit ffdc80f3cce7 k8s-deploy/nginx-ingress-controller:0.24.1-temp commit后跟的是容器id，最后跟的是新镜像名称。push命令将新镜像推到远程harbor仓库。\n运行新制作的镜像，可以看到我们修改的文件。\n这种方式一般用于测试，弊端是可能会导致镜像越来越大。\n","date":"2019年10月17日","externalUrl":null,"permalink":"/posts/docker%E9%95%9C%E5%83%8F%E5%88%B6%E4%BD%9C%E5%BF%85%E5%A4%87%E6%8A%80%E8%83%BD/","section":"Posts","summary":"\u003cp\u003e\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"\" src=\"https://img.hacpai.com/bing/20180416.jpg?imageView2/1/w/960/h/540/interlace/1/q/100\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e\n\n\u003ch2 class=\"relative group\"\u003e正文 \n    \u003cdiv id=\"正文\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e6%ad%a3%e6%96%87\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e使用过docker的都知道dockerfile，其用于定义制作镜像的流程，由一系列命令和参数构成的脚本，这些命令应用于基础镜像并最终创建一个新的镜像。可参考往期文章学习：\u003ca href=\"https://mp.weixin.qq.com/s/lzFL4eWU8h23sTbFbHEZkg\" target=\"_blank\"\u003edocker基础知识整理\u003c/a\u003e\u003c/p\u003e","title":"docker镜像制作必备技能","type":"posts"},{"content":" kubernetes版本：1.13.2\n接上一节：kubernetes垃圾回收器GarbageCollector Controller源码分析（一）\n主要步骤 # GarbageCollector Controller源码主要分为以下几部分：\nmonitors作为生产者将变化的资源放入graphChanges队列；同时restMapper定期检测集群内资源类型，刷新monitors runProcessGraphChanges从graphChanges队列中取出变化的item，根据情况放入attemptToDelete队列； runProcessGraphChanges从graphChanges队列中取出变化的item，根据情况放入attemptToOrphan队列； runAttemptToDeleteWorker从attemptToDelete队列取出，尝试删除垃圾资源； runAttemptToOrphanWorker从attemptToOrphan队列取出，处理该孤立的资源；\n代码较复杂，便于讲的更清楚，调整了下讲解顺序。上一节分析了第1部分，本节分析第2、3部分。 runProcessGraphChanges处理主流程 # 来到源码k8s.io\\kubernetes\\pkg\\controller\\garbagecollector\\graph_builder.go中，runProcessGraphChanges中一直死循环处理变化的资源对象：\nfunc (gb *GraphBuilder) runProcessGraphChanges() { for gb.processGraphChanges() { } } 一个协程一直循环从graphChanges队列中获取变化的资源对象，更新图形，填充dirty_queue。(graphChanges队列里数据来源于各个资源的monitors监听资源变化回调addFunc、updateFunc、deleteFunc)\n// Dequeueing an event from graphChanges, updating graph, populating dirty_queue. //从graphChanges中获取事件，更新图形，填充dirty_queue。(graphChanges队列里数据来源于各个资源的monitors监听资源变化回调addFunc、updateFunc、deleteFunc) func (gb *GraphBuilder) processGraphChanges() bool { item, quit := gb.graphChanges.Get() if quit { return false } defer gb.graphChanges.Done(item) event, ok := item.(*event) if !ok { utilruntime.HandleError(fmt.Errorf(\u0026#34;expect a *event, got %v\u0026#34;, item)) return true } obj := event.obj //获取该变化资源obj的accessor accessor, err := meta.Accessor(obj) if err != nil { utilruntime.HandleError(fmt.Errorf(\u0026#34;cannot access obj: %v\u0026#34;, err)) return true } klog.V(5).Infof(\u0026#34;GraphBuilder process object: %s/%s, namespace %s, name %s, uid %s, event type %v\u0026#34;, event.gvk.GroupVersion().String(), event.gvk.Kind, accessor.GetNamespace(), accessor.GetName(), string(accessor.GetUID()), event.eventType) // Check if the node already exists // 检查节点是否已存在 //根据该变化资源obj的UID //uidToNode维护着资源对象依赖关系图表结构 existingNode, found := gb.uidToNode.Read(accessor.GetUID()) if found { // this marks the node as having been observed via an informer event // 1. this depends on graphChanges only containing add/update events from the actual informer // 2. this allows things tracking virtual nodes\u0026#39; existence to stop polling and rely on informer events //这标志着节点已经通过informer事件 // 1.进行了观察。这取决于仅包含来自实际informer的添加/更新事件的graphChange // 2.这允许跟踪虚拟节点的存在以停止轮询和依赖informer事件 existingNode.markObserved() } switch { //gc第一次运行时，uidToNode尚且没有初始化资源对象依赖关系图表结构，所以found为false，会新增节点 case (event.eventType == addEvent || event.eventType == updateEvent) \u0026amp;\u0026amp; !found: newNode := \u0026amp;node{ identity: objectReference{ OwnerReference: metav1.OwnerReference{ APIVersion: event.gvk.GroupVersion().String(), Kind: event.gvk.Kind, UID: accessor.GetUID(), Name: accessor.GetName(), }, Namespace: accessor.GetNamespace(), }, dependents: make(map[*node]struct{}), owners: accessor.GetOwnerReferences(), deletingDependents: beingDeleted(accessor) \u0026amp;\u0026amp; hasDeleteDependentsFinalizer(accessor), beingDeleted: beingDeleted(accessor), } gb.insertNode(newNode) // the underlying delta_fifo may combine a creation and a deletion into // one event, so we need to further process the event. //底层delta_fifo可以将创建和删除组合成一个事件，因此我们需要进一步处理事件。 gb.processTransitions(event.oldObj, accessor, newNode) //uidToNode已经初始化资源对象依赖关系图表结构，所以found为true case (event.eventType == addEvent || event.eventType == updateEvent) \u0026amp;\u0026amp; found: // handle changes in ownerReferences //处理ownerReferences中的更改 added, removed, changed := referencesDiffs(existingNode.owners, accessor.GetOwnerReferences()) if len(added) != 0 || len(removed) != 0 || len(changed) != 0 { // check if the changed dependency graph unblock owners that are // waiting for the deletion of their dependents. //检查更改的依赖关系图是否取消阻止等待删除其依赖项的所有者。 gb.addUnblockedOwnersToDeleteQueue(removed, changed) // update the node itself //更新node的owner existingNode.owners = accessor.GetOwnerReferences() // Add the node to its new owners\u0026#39; dependent lists. //给新owner添加依赖资源列表 gb.addDependentToOwners(existingNode, added) // remove the node from the dependent list of node that are no longer in // the node\u0026#39;s owners list. //从不再属于该资源owner列表中删除该节点。 gb.removeDependentFromOwners(existingNode, removed) } // 该对象正在被删除中 if beingDeleted(accessor) { existingNode.markBeingDeleted() } gb.processTransitions(event.oldObj, accessor, existingNode) //处理资源对象被删除的场景，涉及垃圾。比如，owner被删除，其依赖资源（从资源）也需要被删除掉，除非设置了Orphan case event.eventType == deleteEvent: if !found { klog.V(5).Infof(\u0026#34;%v doesn\u0026#39;t exist in the graph, this shouldn\u0026#39;t happen\u0026#34;, accessor.GetUID()) return true } // 从图标中移除item资源，同时遍历owners，移除owner下的item资源 gb.removeNode(existingNode) existingNode.dependentsLock.RLock() defer existingNode.dependentsLock.RUnlock() //如果该资源的从资源数大于0,则将该资源被删除信息加入absentOwnerCache缓存 if len(existingNode.dependents) \u0026gt; 0 { gb.absentOwnerCache.Add(accessor.GetUID()) } //遍历该资源的从资源加到删除队列里 for dep := range existingNode.dependents { gb.attemptToDelete.Add(dep) } for _, owner := range existingNode.owners { ownerNode, found := gb.uidToNode.Read(owner.UID) //owner没发现 或者 owner的从资源不是正在被删除(只有该资源对象的终结器为foregroundDeletion Finalizer时deletingDependents被设为true,因为后台删除owner直接被删除,不会被其从资源block,故这里都不需要去尝试删除owner了) if !found || !ownerNode.isDeletingDependents() { continue } // 这是让attempToDeleteItem检查是否删除了owner的依赖项，如果是，则删除所有者。 gb.attemptToDelete.Add(ownerNode) } } return true } 该方法功能主要将对象、owner、从资源加入到attemptToDelete或attemptToOrphan。\n1、 出队 # 从graphChanges队列取出资源对象，从GraphBuilder.uidToNode中读取该资源节点（uidToNode维护着资源对象依赖关系图表结构），found为true时表示图表存在该资源节点；\n2、switch的第一个case # 如果该资源是新增或者更新触发，且该资源对象不存在于图表中，gb.uidToNode.Write(n)会将其写入图标；\ngb.insertNode(newNode)中的gb.addDependentToOwners(n, n.owners)方法则会遍历该资源的owner，如果其owner不存在于图标中，则新增owner的虚拟节点到图标中，并将该资源和owner产生关联。如果owner不存在时，则尝试将owner加入到attemptToDelete队列中去；\n// addDependentToOwners将n添加到所有者的从属列表中。如果所有者不存在于gb.uidToNode中，则将创建\u0026#34;虚拟\u0026#34;节点以表示 // 所有者。 \u0026#34;虚拟\u0026#34;节点将入队到attemptToDelete，因此 // attemptToDeleteItem()将根据API服务器验证所有者是否存在。 func (gb *GraphBuilder) addDependentToOwners(n *node, owners []metav1.OwnerReference) { //遍历owner for _, owner := range owners { //获取owner node如果不存在于图中,则加虚拟owner节点 ownerNode, ok := gb.uidToNode.Read(owner.UID) if !ok { // Create a \u0026#34;virtual\u0026#34; node in the graph for the owner if it doesn\u0026#39;t // exist in the graph yet. //如果图形中尚未存在，则在图表中为所有者创建“虚拟”节点。 ownerNode = \u0026amp;node{ identity: objectReference{ OwnerReference: owner, Namespace: n.identity.Namespace, }, dependents: make(map[*node]struct{}), virtual: true, } klog.V(5).Infof(\u0026#34;add virtual node.identity: %s\\n\\n\u0026#34;, ownerNode.identity) gb.uidToNode.Write(ownerNode) } //给owner加该资源作为依赖 ownerNode.addDependent(n) //owner不存在于图中时，才往删除队列添加 if !ok { // Enqueue the virtual node into attemptToDelete. // The garbage processor will enqueue a virtual delete // event to delete it from the graph if API server confirms this // owner doesn\u0026#39;t exist. //将虚拟节点排入attemptToDelete。 // 如果API服务器确认owner不存在，垃圾处理器将排队虚拟删除事件以将其从图中删除。 gb.attemptToDelete.Add(ownerNode) } } } gb.processTransitions方法：\n新item正在被删,旧item没开始被删除,且终结器为Orphan Finalizer加入到attemptToOrphan队列；\n新item正在被删,旧item没开始被删除,且终结器为foregroundDeletion Finalizer，则加入到attemptToDelete队列。\nfunc (gb *GraphBuilder) processTransitions(oldObj interface{}, newAccessor metav1.Object, n *node) { //新的正在被删,旧的没开始被删除,且终结器为Orphan Finalizer if startsWaitingForDependentsOrphaned(oldObj, newAccessor) { klog.V(5).Infof(\u0026#34;add %s to the attemptToOrphan\u0026#34;, n.identity) //加入到Orphan队列 gb.attemptToOrphan.Add(n) return } //新的正在被删,旧的没开始被删除,且终结器为foregroundDeletion Finalizer if startsWaitingForDependentsDeleted(oldObj, newAccessor) { klog.V(2).Infof(\u0026#34;add %s to the attemptToDelete, because it\u0026#39;s waiting for its dependents to be deleted\u0026#34;, n.identity) // if the n is added as a \u0026#34;virtual\u0026#34; node, its deletingDependents field is not properly set, so always set it here. n.markDeletingDependents() for dep := range n.dependents { gb.attemptToDelete.Add(dep) } gb.attemptToDelete.Add(n) } } 3、switch的第二个case # 如果该资源是新增或者更新触发，且该资源对象存在于图表中。对比owneReferences是否有变更，referencesDiffs方法里会根据uid对比，added表示新owner里有,旧owner里没有的, removed表示旧owner里有,新owner里没有的, changed表示相同uid的owner不deepEqual的。\nfunc referencesDiffs(old []metav1.OwnerReference, new []metav1.OwnerReference) (added []metav1.OwnerReference, removed []metav1.OwnerReference, changed []ownerRefPair) { //key为uid, value为OwnerReference oldUIDToRef := make(map[string]metav1.OwnerReference) for _, value := range old { oldUIDToRef[string(value.UID)] = value } oldUIDSet := sets.StringKeySet(oldUIDToRef) //key为uid, value为OwnerReference newUIDToRef := make(map[string]metav1.OwnerReference) for _, value := range new { newUIDToRef[string(value.UID)] = value } newUIDSet := sets.StringKeySet(newUIDToRef) //新的里有,旧的里没有的为新增(根据uid判断) addedUID := newUIDSet.Difference(oldUIDSet) //旧的里有,新的里没有的为删除(根据uid判断) removedUID := oldUIDSet.Difference(newUIDSet) //取交集, 旧的和新的里都有的owner(根据uid判断) intersection := oldUIDSet.Intersection(newUIDSet) for uid := range addedUID { added = append(added, newUIDToRef[uid]) } for uid := range removedUID { removed = append(removed, oldUIDToRef[uid]) } //根据uid判断,两个uid相等的OwnerReference是否deepEqual,不等则加到changed for uid := range intersection { if !reflect.DeepEqual(oldUIDToRef[uid], newUIDToRef[uid]) { changed = append(changed, ownerRefPair{oldRef: oldUIDToRef[uid], newRef: newUIDToRef[uid]}) } } return added, removed, changed } 整体来说，owner发生变化，addUnblockedOwnersToDeleteQueue方法会判断：如果阻塞ownerReference指向某个对象被删除，或者设置为BlockOwnerDeletion=false，则将该对象添加到attemptToDelete队列；\n// if an blocking ownerReference points to an object gets removed, or gets set to // \u0026#34;BlockOwnerDeletion=false\u0026#34;, add the object to the attemptToDelete queue. //如果阻塞ownerReference指向某个对象被删除，或者设置为 // \u0026#34;BlockOwnerDeletion = false\u0026#34;，则将该对象添加到attemptToDelete队列。 func (gb *GraphBuilder) addUnblockedOwnersToDeleteQueue(removed []metav1.OwnerReference, changed []ownerRefPair) { for _, ref := range removed { //被移除的OwnersReferences,BlockOwnerDeletion为true if ref.BlockOwnerDeletion != nil \u0026amp;\u0026amp; *ref.BlockOwnerDeletion { //依赖图表中发现,则加入删除队列 node, found := gb.uidToNode.Read(ref.UID) if !found { klog.V(5).Infof(\u0026#34;cannot find %s in uidToNode\u0026#34;, ref.UID) continue } //加入尝试删除队列删除这个owner gb.attemptToDelete.Add(node) } } // Owners存在且发生变化,旧的BlockOwnerDeletion为true, 新的BlockOwnerDeletion为空或者BlockOwnerDeletion为false则删除owner(父节点) for _, c := range changed { wasBlocked := c.oldRef.BlockOwnerDeletion != nil \u0026amp;\u0026amp; *c.oldRef.BlockOwnerDeletion isUnblocked := c.newRef.BlockOwnerDeletion == nil || (c.newRef.BlockOwnerDeletion != nil \u0026amp;\u0026amp; !*c.newRef.BlockOwnerDeletion) if wasBlocked \u0026amp;\u0026amp; isUnblocked { node, found := gb.uidToNode.Read(c.newRef.UID) if !found { klog.V(5).Infof(\u0026#34;cannot find %s in uidToNode\u0026#34;, c.newRef.UID) continue } gb.attemptToDelete.Add(node) } } } 更新node的owner；\n在依赖图表中给新owner添加该node；\n在依赖图表中,被删除的owner列表下删除该节点。\ngb.processTransitions方法：\n新item正在被删,旧item没开始被删除,且终结器为Orphan Finalizer加入到attemptToOrphan队列；\n新item正在被删,旧item没开始被删除,且终结器为foregroundDeletion Finalizer，则加入到attemptToDelete队列。\n4、switch的第三个case # 如果该资源是删除时触发，从图表中移除item资源，同时遍历owners，移除owner下的item资源；\n如果该资源的从资源数大于0,则将该资源被删除信息（uid）加入absentOwnerCache缓存，这样处理该资源的从资源时，就知道owner不存在了。\n遍历该资源的从资源加到删除队列里；\n如果从图表中发现 owner或者 owner的从资源正在被删除，则尝试将owner加入到attemptToDelete队列中，去尝试删除owner。\n整理流程 # 当controllermanager重启时，会全量listwatch一遍所有对象，gc collector维护的uidToNode图表里各个资源对象node是不存在的，此时会走第一个switch case，构建完整关系图表，如果owner不存在则先构建虚拟owner节点，同时加入attemptToDelete队列，尝试去删除这个owner，其实即使加入到attemptToDelete队列，也不一定会被删除，还会进行一系列判断，这个下一节再分析；将正在删除的资源，同时Finalizer为Orphan的加入到attemptToOrphan队列；为foreground的资源以及其从资源加入到attemptToDelete队列，并将deletingDependents设置为true； 添加或者更新事件时，且图表中存在item资源对象时，会走第二个switch case，对item的owner变化进行判断，并维护更新图表；同理将正在删除的资源，同时Finalizer为Orphan的加入到attemptToOrphan队列；Finalizer为foreground的资源以及其从资源加入到attemptToDelete队列，并将deletingDependents设置为true； 如果是删除事件，则会更新图表，并处理和其相关的从资源和其owner加入到attemptToDelete队列。 参考： # k8s官方文档garbage-collection英文版：\nhttps://kubernetes.io/docs/concepts/workloads/controllers/garbage-collection/\n依赖图标生成库gonum Api文档：\nhttps://godoc.org/gonum.org/v1/gonum/graph\ngraphviz下载：\nhttps://graphviz.gitlab.io/_pages/Download/Download_windows.html\n","date":"2019年10月16日","externalUrl":null,"permalink":"/posts/kubernetes%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8garbagecollector%E6%8E%A7%E5%88%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%BA%8C/","section":"Posts","summary":"\u003cp\u003e\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"\" src=\"https://img.hacpai.com/bing/20190103.jpg?imageView2/1/w/960/h/540/interlace/1/q/100\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003ekubernetes版本：1.13.2\u003c/strong\u003e\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003e接上一节：\u003ca href=\"https://liabio.blog.csdn.net/article/details/100081941\" target=\"_blank\"\u003ekubernetes垃圾回收器GarbageCollector Controller源码分析（一）\u003c/a\u003e\u003c/p\u003e","title":"kubernetes垃圾回收器GarbageCollector控制器源码分析（二）","type":"posts"},{"content":" kubernetes版本：1.13.2\n背景 # 由于operator创建的redis集群，在kubernetes apiserver重启后，redis集群被异常删除（包括redis exporter statefulset、redis statefulset）。删除后operator将其重建，重新组建集群，实例IP发生变更（中间件容器化，我们开发了固定IP，当statefulset删除后，IP会被回收），导致创建集群失败，最终集群不可用。\n经多次复现，apiserver重启后，通过查询redis operator日志，并没有发现主动去删除redis集群（redis statefulset）、监控实例（redis exporter）。进一步去查看kube-controller-manager的日志，将其日志级别设置\u0026ndash;v=5，继续复现，最终在kube-controller-manager日志中发现如下日志：\n可以看到是garbage collector触发删除操作的。这个问题在apiserver正常的时候是不存在，要想弄其究竟，就得看看kube-controller-manager内置组件garbage collector这个控制器的逻辑。\n由于内容偏长，分为多节来讲：\nmonitors作为生产者将变化的资源放入graphChanges队列；同时restMapper定期检测集群内资源类型，刷新monitors runProcessGraphChanges从graphChanges队列中取出变化的item，根据情况放入attemptToDelete队列； runProcessGraphChanges从graphChanges队列中取出变化的item，根据情况放入attemptToOrphan队列； runAttemptToDeleteWorker从attemptToDelete队列取出，尝试删除垃圾资源； runAttemptToOrphanWorker从attemptToOrphan队列取出，处理该孤立的资源；\n正文 # 想要启用GC，需要在kube-apiserver和kube-controller-manager的启动参数中都设置--enable-garbage-collector为true,1.13.2版本中默认开启GC。\n需要注意：两组件该参数必须保持同步。\nkube-controller-manager启动入口，app.NewControllerManagerCommand()中加载controller manager默认启动参数，创建* cobra.Command对象：\nfunc main() { rand.Seed(time.Now().UnixNano()) //加载controller manager默认启动参数，创建* cobra.Command对象 command := app.NewControllerManagerCommand() //......省略....... //执行cobra.command，并启动controller-manager if err := command.Execute(); err != nil { fmt.Fprintf(os.Stderr, \u0026#34;%v\\n\u0026#34;, err) os.Exit(1) } } 以下代码处去启动kube-controller-manager：\nNewDefaultComponentConfig(ports.InsecureKubeControllerManagerPort)加载各个控制器的配置：\n//NewKubeControllerManagerOptions使用默认配置创建一个新的KubeControllerManagerOptions func NewKubeControllerManagerOptions() (*KubeControllerManagerOptions, error) { //加载各个控制器的默认配置 componentConfig, err := NewDefaultComponentConfig(ports.InsecureKubeControllerManagerPort) if err != nil { return nil, err } s := KubeControllerManagerOptions{ Generic: cmoptions.NewGenericControllerManagerConfigurationOptions(componentConfig.Generic), //.....省略 GarbageCollectorController: \u0026amp;GarbageCollectorControllerOptions{ ConcurrentGCSyncs: componentConfig.GarbageCollectorController.ConcurrentGCSyncs, EnableGarbageCollector: componentConfig.GarbageCollectorController.EnableGarbageCollector, }, //.....省略 } //gc忽略的资源对象列表 gcIgnoredResources := make([]kubectrlmgrconfig.GroupResource, 0, len(garbagecollector.DefaultIgnoredResources())) for r := range garbagecollector.DefaultIgnoredResources() { gcIgnoredResources = append(gcIgnoredResources, kubectrlmgrconfig.GroupResource{Group: r.Group, Resource: r.Resource}) } s.GarbageCollectorController.GCIgnoredResources = gcIgnoredResources return \u0026amp;s, nil } // NewDefaultComponentConfig返回kube-controller管理器配置对象 func NewDefaultComponentConfig(insecurePort int32) (kubectrlmgrconfig.KubeControllerManagerConfiguration, error) { scheme := runtime.NewScheme() if err := kubectrlmgrschemev1alpha1.AddToScheme(scheme); err != nil { return kubectrlmgrconfig.KubeControllerManagerConfiguration{}, err } if err := kubectrlmgrconfig.AddToScheme(scheme); err != nil { return kubectrlmgrconfig.KubeControllerManagerConfiguration{}, err } versioned := kubectrlmgrconfigv1alpha1.KubeControllerManagerConfiguration{} //加载默认参数 scheme.Default(\u0026amp;versioned) internal := kubectrlmgrconfig.KubeControllerManagerConfiguration{} if err := scheme.Convert(\u0026amp;versioned, \u0026amp;internal, nil); err != nil { return internal, err } internal.Generic.Port = insecurePort return internal, nil } // 根据Object，获取提供的默认参数 func (s *Scheme) Default(src Object) { if fn, ok := s.defaulterFuncs[reflect.TypeOf(src)]; ok { fn(src) } } s.defaulterFuncs类型为map[reflect.Type]func(interface{})，用于根据指针类型获取默认值函数。该map中的数据从哪里来的呢？\n代码位于src\\k8s.io\\kubernetes\\pkg\\controller\\apis\\config\\v1alpha1\\zz_generated.defaults.go\n可以看到默认参数中garbage collector中默认开启gc（EnableGarbageCollector），并发数为20（ConcurrentGCSyncs）\nfunc SetDefaults_GarbageCollectorControllerConfiguration(obj *kubectrlmgrconfigv1alpha1.GarbageCollectorControllerConfiguration) { if obj.EnableGarbageCollector == nil { obj.EnableGarbageCollector = utilpointer.BoolPtr(true) } if obj.ConcurrentGCSyncs == 0 { obj.ConcurrentGCSyncs = 20 } } 回到Run函数，里面调用了NewControllerInitializers启动所有控制器：\n重点来到启动garbage collector的startGarbageCollectorController函数：\nfunc startGarbageCollectorController(ctx ControllerContext) (http.Handler, bool, error) { //k8s 1.13.2中默认为true,可在kube-apiserver和kube-controller-manager的启动参数中加--enable-garbage-conllector=false设置 //需保证这两个组件中参数值一致 if !ctx.ComponentConfig.GarbageCollectorController.EnableGarbageCollector { return nil, false, nil } //k8s各种原生资源对象客户端集合(默认启动参数中用SimpleControllerClientBuilder构建) gcClientset := ctx.ClientBuilder.ClientOrDie(\u0026#34;generic-garbage-collector\u0026#34;) discoveryClient := cacheddiscovery.NewMemCacheClient(gcClientset.Discovery()) //生成rest config config := ctx.ClientBuilder.ConfigOrDie(\u0026#34;generic-garbage-collector\u0026#34;) dynamicClient, err := dynamic.NewForConfig(config) if err != nil { return nil, true, err } // Get an initial set of deletable resources to prime the garbage collector. //获取一组初始可删除资源以填充垃圾收集器。 deletableResources := garbagecollector.GetDeletableResources(discoveryClient) ignoredResources := make(map[schema.GroupResource]struct{}) //忽略gc的资源类型 for _, r := range ctx.ComponentConfig.GarbageCollectorController.GCIgnoredResources { ignoredResources[schema.GroupResource{Group: r.Group, Resource: r.Resource}] = struct{}{} } garbageCollector, err := garbagecollector.NewGarbageCollector( dynamicClient, ctx.RESTMapper, deletableResources, ignoredResources, ctx.InformerFactory, ctx.InformersStarted, ) if err != nil { return nil, true, fmt.Errorf(\u0026#34;Failed to start the generic garbage collector: %v\u0026#34;, err) } // Start the garbage collector. //启动参数中默认是20个协程 workers := int(ctx.ComponentConfig.GarbageCollectorController.ConcurrentGCSyncs) //启动monitors和deleteWorkers、orphanWorkers go garbageCollector.Run(workers, ctx.Stop) // Periodically refresh the RESTMapper with new discovery information and sync // the garbage collector. //使用新的发现信息定期刷新RESTMapper并同步垃圾收集器。 go garbageCollector.Sync(gcClientset.Discovery(), 30*time.Second, ctx.Stop) //gc提供debug dot grap依赖关系图接口 return garbagecollector.NewDebugHandler(garbageCollector), true, nil } 该函数主要作用有：\n1、deletableResources := garbagecollector.GetDeletableResources(discoveryClient)获取集群内所有可删除的资源对象；排除掉忽略的资源对象。\n2、构建garbageCollector结构体对象；\n3、garbageCollector.Run(workers, ctx.Stop)启动一个monitors用来监听资源对象的变化（对应的由runProcessGraphChanges死循环处理），和默认20个deleteWorkers协程处理可删除的资源对象、20个orphanWorkers协程处理孤儿对象。\n4、garbageCollector.Sync(gcClientset.Discovery(), 30*time.Second, ctx.Stop) 定时去获取一个集群内是否有新类型的资源对象的加入，并重新刷新monitors，以监听新类型的资源对象。\n5、garbagecollector.NewDebugHandler(garbageCollector)注册debug接口，用来提供获取dot流程图接口：\ncurl http://127.0.0.1:10252/debug/controllers/garbagecollector/graph?uid=11211212edsaddkqedmk12 使用graphviz提供的dot.exe可以生成svg格式的图，可用google浏览器查看如下：\n// curl http://127.0.0.1:10252/debug/controllers/garbagecollector/graph?uid=11211212edsaddkqedmk12 func (h *debugHTTPHandler) ServeHTTP(w http.ResponseWriter, req *http.Request) { if req.URL.Path != \u0026#34;/graph\u0026#34; { http.Error(w, \u0026#34;\u0026#34;, http.StatusNotFound) return } var graph graph.Directed if uidStrings := req.URL.Query()[\u0026#34;uid\u0026#34;]; len(uidStrings) \u0026gt; 0 { uids := []types.UID{} for _, uidString := range uidStrings { uids = append(uids, types.UID(uidString)) } graph = h.controller.dependencyGraphBuilder.uidToNode.ToGonumGraphForObj(uids...) } else { graph = h.controller.dependencyGraphBuilder.uidToNode.ToGonumGraph() } //生成dot流程图数据,用graphviz工具中的dot.exe工具转换为svg图(用google浏览器打开)或者png图 //API参考:https://godoc.org/gonum.org/v1/gonum/graph //graphviz下载地址:https://graphviz.gitlab.io/_pages/Download/Download_windows.html //dot.exe test.dot -T svg -o test.svg data, err := dot.Marshal(graph, \u0026#34;full\u0026#34;, \u0026#34;\u0026#34;, \u0026#34; \u0026#34;, false) if err != nil { http.Error(w, err.Error(), http.StatusInternalServerError) return } w.Write(data) w.WriteHeader(http.StatusOK) } GarbageCollector通过restMapper定期重置可删除的资源类型，更新GraphBuilder中的monitors，monitors将创建所有资源类型的变更通知回调函数，将变化的资源对象加入到GraphBuilder的graphChanges队列，GraphBuilder的runProcessGraphChanges()会一直从队列中获取变化，构建一个缓存对象之间依赖关系的图形，以及触发dependencyGraphBuilder将可能被垃圾收集的对象排队到attemptToDelete队列，并将其依赖项需要孤立的对象排队到attemptToOrphan队列。GarbageCollector具有使用这两个队列的工作人员runAttemptToDeleteWorker和runAttemptToOrphanWorker死循环，分别从attemptToDelete队列和attemptToOrphan队列取出，向API服务器发送请求以相应地删除更新对象。\n// GarbageCollector运行反射器来监视托管API对象的更改，将结果汇总到单线程dependencyGraphBuilder， // 构建一个缓存对象之间依赖关系的图形。由图变化触发，dependencyGraphBuilder将可能被垃圾收集的对象 // 排队到`attemptToDelete`队列，并将其依赖项需要孤立的对象排队到`attemptToOrphan`队列。 // GarbageCollector具有使用这两个队列的工作人员，向API服务器发送请求以相应地删除更新对象。 // 请注意，让dependencyGraphBuilder通知垃圾收集器确保垃圾收集器使用至少与发送通知一样最新的图形进行操作。 type GarbageCollector struct { // resettableRESTMapper是一个RESTMapper，它能够在discovery资源类型时重置自己 restMapper resettableRESTMapper // dynamicClient提供操作集群内所有资源对象的接口方法,包括k8s内置、CRD生成的自定义资源 dynamicClient dynamic.Interface //垃圾收集器尝试在时间成熟时删除attemptToDelete队列中的item attemptToDelete workqueue.RateLimitingInterface //垃圾收集器尝试孤立attemptToOrphan队列中item的依赖项，然后删除item attemptToOrphan workqueue.RateLimitingInterface dependencyGraphBuilder *GraphBuilder // 有owner的资源对象,才会给absentOwnerCache填充不存在的Owner信息 absentOwnerCache *UIDCache sharedInformers informers.SharedInformerFactory workerLock sync.RWMutex } // GraphBuilder：基于informers提供的事件，GraphBuilder更新 // uidToNode，一个缓存我们所知的依赖关系的图，并将 // 项放入attemptToDelete和attemptToOrphan队列 type GraphBuilder struct { restMapper meta.RESTMapper //每个监视器列表/监视资源，结果汇集到dependencyGraphBuilder monitors monitors monitorLock sync.RWMutex // informersStarted is closed after after all of the controllers have been initialized and are running. // After that it is safe to start them here, before that it is not. // informersStarted在所有控制器初始化并运行后关闭。之后在这里启动它们是安全的，在此之前它不是。 informersStarted \u0026lt;-chan struct{} // stopCh drives shutdown. When a receive from it unblocks, monitors will shut down. // This channel is also protected by monitorLock. // stopCh驱动器关闭当来自它的接收解除阻塞时，监视器将关闭。 此channel也受monitorLock保护。 stopCh \u0026lt;-chan struct{} // running tracks whether Run() has been called. // it is protected by monitorLock. //运行轨道是否已调用Run()它受monitorLock保护。 running bool dynamicClient dynamic.Interface // monitors are the producer of the graphChanges queue, graphBuilder alters // the in-memory graph according to the changes. // monitor是graphChanges队列的生成者，graphBuilder根据更改改变了内存中的图形。 graphChanges workqueue.RateLimitingInterface // uidToNode doesn\u0026#39;t require a lock to protect, because only the // single-threaded GraphBuilder.processGraphChanges() reads/writes it. //uidToNode不需要锁保护，因为只有单线程GraphBuilder.processGraphChanges()读写它。 uidToNode *concurrentUIDToNode // GraphBuilder is the producer of attemptToDelete and attemptToOrphan, GC is the consumer. // GraphBuilder是attemptToDelete和attemptToOrphan的生产者，GC是消费者。 attemptToDelete workqueue.RateLimitingInterface attemptToOrphan workqueue.RateLimitingInterface // GraphBuilder and GC share the absentOwnerCache. Objects that are known to // be non-existent are added to the cached. // GraphBuilder和GC共享absentOwnerCache。已知不存在的对象将添加到缓存中。 absentOwnerCache *UIDCache //所有k8s资源对象集的informer sharedInformers informers.SharedInformerFactory //监视器忽略的资源对象集 ignoredResources map[schema.GroupResource]struct{} } 创建NewGarbageCollector结构体：\nfunc NewGarbageCollector( dynamicClient dynamic.Interface, mapper resettableRESTMapper, deletableResources map[schema.GroupVersionResource]struct{}, ignoredResources map[schema.GroupResource]struct{}, sharedInformers informers.SharedInformerFactory, informersStarted \u0026lt;-chan struct{}, ) (*GarbageCollector, error) { attemptToDelete := workqueue.NewNamedRateLimitingQueue(workqueue.DefaultControllerRateLimiter(), \u0026#34;garbage_collector_attempt_to_delete\u0026#34;) attemptToOrphan := workqueue.NewNamedRateLimitingQueue(workqueue.DefaultControllerRateLimiter(), \u0026#34;garbage_collector_attempt_to_orphan\u0026#34;) absentOwnerCache := NewUIDCache(500) gc := \u0026amp;GarbageCollector{ dynamicClient: dynamicClient, restMapper: mapper, attemptToDelete: attemptToDelete, attemptToOrphan: attemptToOrphan, absentOwnerCache: absentOwnerCache, } gb := \u0026amp;GraphBuilder{ dynamicClient: dynamicClient, informersStarted: informersStarted, restMapper: mapper, graphChanges: workqueue.NewNamedRateLimitingQueue(workqueue.DefaultControllerRateLimiter(), \u0026#34;garbage_collector_graph_changes\u0026#34;), uidToNode: \u0026amp;concurrentUIDToNode{ uidToNode: make(map[types.UID]*node), }, attemptToDelete: attemptToDelete, attemptToOrphan: attemptToOrphan, absentOwnerCache: absentOwnerCache, sharedInformers: sharedInformers, ignoredResources: ignoredResources, } //初始化各个资源对象的monitors，启动各资源对象的监听器，变化时触发回调，将其加入graphChanges 队列 if err := gb.syncMonitors(deletableResources); err != nil { utilruntime.HandleError(fmt.Errorf(\u0026#34;failed to sync all monitors: %v\u0026#34;, err)) } gc.dependencyGraphBuilder = gb return gc, nil } 主要功能：\n1、构建GarbageCollector结构体；\n2、构建依赖结构图维护结构体GraphBuilder，和GarbageCollector共用attemptToDelete和attemptToOrphan队列，GraphBuilder作为生产着将适当资源放到attemptToDelete或者attemptToOrphan队列，供GarbageCollector中的worker进行消费；\n3、初始化各个资源对象的monitors，启动各资源对象的监听器，变化时触发回调，将其加入graphChanges 队列。\ngb.syncMonitors(deletableResources)方法中最主要的是c, s, err := gb.controllerFor(resource, kind)\nfunc (gb *GraphBuilder) controllerFor(resource schema.GroupVersionResource, kind schema.GroupVersionKind) (cache.Controller, cache.Store, error) { handlers := cache.ResourceEventHandlerFuncs{ // add the event to the dependencyGraphBuilder\u0026#39;s graphChanges. // 将事件添加到dependencyGraphBuilder的graphChanges中。 AddFunc: func(obj interface{}) { event := \u0026amp;event{ eventType: addEvent, obj: obj, gvk: kind, } gb.graphChanges.Add(event) }, UpdateFunc: func(oldObj, newObj interface{}) { // TODO: check if there are differences in the ownerRefs, // finalizers, and DeletionTimestamp; if not, ignore the update. //TODO：检查ownerRefs， finalizers和DeletionTimestamp是否存在差异;如果没有，请忽略更新。 event := \u0026amp;event{ eventType: updateEvent, obj: newObj, oldObj: oldObj, gvk: kind, } gb.graphChanges.Add(event) }, DeleteFunc: func(obj interface{}) { // delta fifo may wrap the object in a cache.DeletedFinalStateUnknown, unwrap it // delta fifo可以将对象包装在cache.DeletedFinalStateUnknown中，解包它 if deletedFinalStateUnknown, ok := obj.(cache.DeletedFinalStateUnknown); ok { obj = deletedFinalStateUnknown.Obj } event := \u0026amp;event{ eventType: deleteEvent, obj: obj, gvk: kind, } gb.graphChanges.Add(event) }, } shared, err := gb.sharedInformers.ForResource(resource) if err == nil { klog.V(4).Infof(\u0026#34;using a shared informer for resource %q, kind %q\u0026#34;, resource.String(), kind.String()) // need to clone because it\u0026#39;s from a shared cache shared.Informer().AddEventHandlerWithResyncPeriod(handlers, ResourceResyncTime) return shared.Informer().GetController(), shared.Informer().GetStore(), nil } else { //获取资源对象时出错会到这里,比如非k8s内置RedisCluster、clusterbases、clusters、esclusters、volumeproviders、stsmasters、appapps、mysqlclusters、brokerclusters、clustertemplates; //内置的networkPolicies、apiservices、customresourcedefinitions klog.V(4).Infof(\u0026#34;unable to use a shared informer for resource %q, kind %q: %v\u0026#34;, resource.String(), kind.String(), err) } // TODO: consider store in one storage. // TODO: 考虑存储在一个存储中。 klog.V(5).Infof(\u0026#34;create storage for resource %s\u0026#34;, resource) //上面失败的资源对象的store和controller store, monitor := cache.NewInformer( listWatcher(gb.dynamicClient, resource), nil, ResourceResyncTime, // don\u0026#39;t need to clone because it\u0026#39;s not from shared cache //不需要克隆，因为它不是来自共享缓存 handlers, ) return monitor, store, nil } 该方法主要功能是：\n1、将新增、更改、删除的资源对象构建为event结构体，放入GraphBuilder的graphChanges队列里，最终被runProcessGraphChanges这个worker消费；\n2、构建大多数内置资源的SharedInformerFactory，构建失败的用cache.NewInformer构建（通过CRD定义的对象以及部分k8s内置对象）\n代码继续回到k8s.io\\kubernetes\\cmd\\kube-controller-manager\\app\\core.go中的startGarbageCollectorController中，看 garbageCollector.Run(workers, ctx.Stop)方法：\nfunc (gc *GarbageCollector) Run(workers int, stopCh \u0026lt;-chan struct{}) { defer utilruntime.HandleCrash() defer gc.attemptToDelete.ShutDown() defer gc.attemptToOrphan.ShutDown() defer gc.dependencyGraphBuilder.graphChanges.ShutDown() klog.Infof(\u0026#34;Starting garbage collector controller\u0026#34;) defer klog.Infof(\u0026#34;Shutting down garbage collector controller\u0026#34;) //协程运行生产者monitors go gc.dependencyGraphBuilder.Run(stopCh) //等待dependencyGraphBuilder缓存开始同步 if !controller.WaitForCacheSync(\u0026#34;garbage collector\u0026#34;, stopCh, gc.dependencyGraphBuilder.IsSynced) { return } //垃圾收集器：所有资源监视器都已同步。继续收集垃圾 klog.Infof(\u0026#34;Garbage collector: all resource monitors have synced. Proceeding to collect garbage\u0026#34;) // gc workers //协程运行消费者DeleteWorkers和OrphanWorkers for i := 0; i \u0026lt; workers; i++ { //默认参数为20个并发协程尝试delete worker go wait.Until(gc.runAttemptToDeleteWorker, 1*time.Second, stopCh) //默认参数为20个并发协程尝试orphan worker go wait.Until(gc.runAttemptToOrphanWorker, 1*time.Second, stopCh) } \u0026lt;-stopCh } gc.dependencyGraphBuilder.Run(stopCh)主要功能：\n1、gb.startMonitors()启动监听资源变化的informer；\n2、wait.Until(gb.runProcessGraphChanges, 1*time.Second, stopCh)开启从队列GraphBuilder.graphChanges中消费的worker\n启动20个runAttemptToDeleteWorker和20个runAttemptToOrphanWorker\n参考 # k8s官方文档garbage-collection英文版：\nhttps://kubernetes.io/docs/concepts/workloads/controllers/garbage-collection/\n依赖图标生成库gonum Api文档：\nhttps://godoc.org/gonum.org/v1/gonum/graph\ngraphviz下载：\nhttps://graphviz.gitlab.io/_pages/Download/Download_windows.html\n","date":"2019年10月16日","externalUrl":null,"permalink":"/posts/kubernetes%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8garbagecollector%E6%8E%A7%E5%88%B6%E5%99%A8%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B8%80/","section":"Posts","summary":"\u003cp\u003e\n\n\n\n\n\n\u003cfigure\u003e\n    \u003cimg class=\"my-0 rounded-md\" loading=\"lazy\" alt=\"\" src=\"https://img.hacpai.com/bing/20190604.jpg?imageView2/1/w/960/h/540/interlace/1/q/100\" /\u003e\n\n  \n\u003c/figure\u003e\n\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003ekubernetes版本：1.13.2\u003c/strong\u003e\u003c/p\u003e\u003c/blockquote\u003e\n\n\u003ch2 class=\"relative group\"\u003e背景 \n    \u003cdiv id=\"背景\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%e8%83%8c%e6%99%af\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e由于operator创建的redis集群，在kubernetes apiserver重启后，redis集群被异常删除（包括redis exporter statefulset、redis statefulset）。删除后operator将其重建，重新组建集群，实例IP发生变更（中间件容器化，我们开发了固定IP，当statefulset删除后，IP会被回收），导致创建集群失败，最终集群不可用。\u003c/p\u003e","title":"kubernetes垃圾回收器GarbageCollector控制器源码分析（一）","type":"posts"},{"content":"","date":"2019年10月16日","externalUrl":null,"permalink":"/tags/github/","section":"Tags","summary":"","title":"GitHub","type":"tags"},{"content":"","date":"2019年10月16日","externalUrl":null,"permalink":"/tags/%E5%BC%80%E6%BA%90/","section":"Tags","summary":"","title":"开源","type":"tags"},{"content":" 1. crawler \u0026lt;kbd \u0026mdash; # title=\u0026ldquo;主要编程语言\u0026rdquo;\u0026gt;HTML 🤩0 ⭐️12 🖖6\n2. solo-blog \u0026lt;kbd \u0026mdash; # title=\u0026ldquo;主要编程语言\u0026rdquo;\u0026gt; 🤩1 ⭐️1 🖖0 🏠http://blog.liabio.cn\n小碗汤的个人博客 - 记录精彩的程序人生\n3. liabio.github.io \u0026lt;kbd \u0026mdash; # title=\u0026ldquo;主要编程语言\u0026rdquo;\u0026gt;HTML 🤩0 ⭐️0 🖖0\nBlog\n4. ingressgroup \u0026lt;kbd \u0026mdash; # title=\u0026ldquo;主要编程语言\u0026rdquo;\u0026gt;Go 🤩0 ⭐️0 🖖0\ningressgroup base kubernetes controller informer example\n5. micro-service \u0026lt;kbd \u0026mdash; # title=\u0026ldquo;主要编程语言\u0026rdquo;\u0026gt;Java 🤩0 ⭐️0 🖖0\njava\n6. smallutil \u0026lt;kbd \u0026mdash; # title=\u0026ldquo;主要编程语言\u0026rdquo;\u0026gt;Go 🤩0 ⭐️0 🖖0\n7. java-fecther \u0026lt;kbd \u0026mdash; # title=\u0026ldquo;主要编程语言\u0026rdquo;\u0026gt;Java 🤩0 ⭐️0 🖖0\n8. museumofart \u0026lt;kbd \u0026mdash; # title=\u0026ldquo;主要编程语言\u0026rdquo;\u0026gt;Java 🤩0 ⭐️0 🖖0\n9. ll837448792.github.io \u0026lt;kbd \u0026mdash; # title=\u0026ldquo;主要编程语言\u0026rdquo;\u0026gt;HTML 🤩0 ⭐️0 🖖0\njust firstly try to make a blog of myself\n","date":"2019年10月16日","externalUrl":null,"permalink":"/posts/%E6%88%91%E5%9C%A8github%E4%B8%8A%E7%9A%84%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/","section":"Posts","summary":"\u003c!-- 该页面会被定时任务自动覆盖，所以请勿手工更新 --\u003e\n\u003c!-- 如果你有更漂亮的排版方式，请发 issue 告诉我们 --\u003e\n\n\u003ch3 class=\"relative group\"\u003e1. \u003ca href=\"https://github.com/liabio/crawler\" target=\"_blank\"\u003ecrawler\u003c/a\u003e \u0026lt;kbd \u0026mdash; \n    \u003cdiv id=\"1-crawler-kbd-\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#1-crawler-kbd-\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h3\u003e\n\u003cp\u003etitle=\u0026ldquo;主要编程语言\u0026rdquo;\u0026gt;HTML\u003c/kbd\u003e \u003cspan style=\"font-size: 12px;\"\u003e\u003ca href=\"https://github.com/liabio/crawler/watchers\"title=\"关注数\" target=\"_blank\"\u003e🤩\u003ccode\u003e0\u003c/code\u003e\u003c/a\u003e  \u003ca href=\"https://github.com/liabio/crawler/stargazers\"title=\"收藏数\" target=\"_blank\"\u003e⭐️\u003ccode\u003e12\u003c/code\u003e\u003c/a\u003e  \u003ca href=\"https://github.com/liabio/crawler/network/members\"title=\"分叉数\" target=\"_blank\"\u003e🖖\u003ccode\u003e6\u003c/code\u003e\u003c/a\u003e\u003c/span\u003e\u003c/p\u003e","title":"我在 GitHub 上的开源项目","type":"posts"},{"content":"","externalUrl":null,"permalink":"/en/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/en/go/","section":"Advance into Cloud Native","summary":"","title":"Redirect","type":"go"},{"content":"","externalUrl":null,"permalink":"/en/series/","section":"Series","summary":"","title":"Series","type":"series"}]